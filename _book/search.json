[{"path":"index.html","id":"analyzing-nces-data-using-edsurvey-a-users-guide","chapter":"Analyzing NCES Data Using EdSurvey: A User’s Guide","heading":"Analyzing NCES Data Using EdSurvey: A User’s Guide","text":"","code":""},{"path":"index.html","id":"learning-to-use-edsurvey","chapter":"Analyzing NCES Data Using EdSurvey: A User’s Guide","heading":"0.1 Learning to Use EdSurvey","text":"user’s guide intended skipping around; information ordered sequentially. find help see examples specific function, question mark function allows users get help function. example, R prompt, installing loading EdSurvey, user can get help downloadTIMSS function typing ?downloadTIMSS.","code":""},{"path":"index.html","id":"available-resources","chapter":"Analyzing NCES Data Using EdSurvey: A User’s Guide","heading":"0.1.1 Available Resources","text":"Visit EdSurvey page AIR.org full listing EdSurvey resources.","code":""},{"path":"index.html","id":"trainings","chapter":"Analyzing NCES Data Using EdSurvey: A User’s Guide","heading":"0.1.2 Trainings","text":"EdSurvey development team provides periodic workshops analysis national international education data. learn course offerings,apply NAEP Data Training Workshopexplore available courses American Educational Research Association IEA International Research Conference sites","code":""},{"path":"index.html","id":"contact-and-bug-report","chapter":"Analyzing NCES Data Using EdSurvey: A User’s Guide","heading":"0.1.3 Contact and Bug Report","text":"Please report bugs issues GitHub repository https://github.com/American-Institutes--Research/EdSurvey/issues.","code":""},{"path":"cover-page.html","id":"cover-page","chapter":"Cover Page","heading":"Cover Page","text":"","code":""},{"path":"cover-page.html","id":"analyzing-nces-data-using-edsurvey-a-users-guide-1","chapter":"Cover Page","heading":"Analyzing NCES Data Using EdSurvey: A User’s Guide","text":"February 2025Editors: Paul Bailey, Ting Zhang\nAmerican Institutes ResearchAuthors:book edited Paul Bailey Ting Zhang, chapters following authors:Chapter 1, Introduction: Ting ZhangChapter 2, Installing R EdSurvey Loading Package: Michael LeeChapter 3, Philosophy Analysis: Michael LeeChapter 4, Data Access: Tom FinkChapter 5, Understanding Data: Yuqi LiaoChapter 6, Data Manipulation EdSurvey Base R: Michael Lee Paul BaileyChapter 7, Descriptive Statistics: Eric Buehler Ting ZhangChapter 8, Models: Yuqi Liao, Paul Bailey, Sinan YavuzChapter 9, Analysis Outside EdSurvey: Michael LeeChapter 10, Longitudinal Datasets: Michael LeeChapter 11, Stasistical Methods used EdSurvey: Paul Bailey, Michael Cohen, Sinan YavuzChapter 12, NAEP Linking Error: Paul BaileyChapter 13, EduSurvey SuggestWeights Function: Huade HuoThe content user’s guide commissioned National Center Education Statistics (NCES) conducted American Institutes Research (AIR) Education Statistics Services Institute Network (ESSIN) Task Order 14: Assessment Division Support (Contract . ED-IES-12-D-0002/0004). Task Order 14 supports NCES expert advice technical assistance issues related National Assessment Educational Progress (NAEP).authors responsible contents guide, still development. feedback, corrections, suggestions improvements subsequent versions, please contact us https://github.com/American-Institutes--Research/EdSurvey/issues. Mention trade names, commercial products, organizations imply endorsement U.S. Government.Contact NCESEmmanuel Sikali\nSenior Research Scientist Acting Chief Reporting Dissemination Branch\nNational Center Education Statistics\nU.S. DEPARTMENT EDUCATIONemmanuel.sikali@ed.gov","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Analyzing NCES Data Using EdSurvey: User’s Guide first introductory manual dedicated introducing R package education research community. now, instruction occurred national international conferences scientific journals. EdSurvey introduced research community American Education Research Association (AERA) annual conference Washington, D.C., April 2016. first version optimized analyze NAEP data. Since , significant development continued steady pace. manual based 4.0.8. user downloads package Comprehensive R Archive Network (CRAN), might discover features presented discussed manual. development team strongly suggests using vignettes regularly published addition new feature.team also understands programming might intimidating education researchers. lower entry level programming skills, user’s guide provides comprehensive examples easy follow adaptable many research questions investigations. team assumes users manual basic understanding knowledge programming R software. Experienced R users might find equipped jump specific section interest. knowledge yet, many courses available public domain suffice acquiring prerequisite knowledge.","code":""},{"path":"preface.html","id":"rationale-for-edsurvey","chapter":"Preface","heading":"0.2 Rationale for EdSurvey","text":"EdSurvey conceived streamline access analyses NCES data taking advantage advances computing meeting shifting trend higher education move away using commercial statistical software packages favor open-source software packages, R, Python, Julia. Starting late 1980s, NCES conceived developed approach make data available research community. approach, data distributed CD-ROM DVD formats. magnetic devices, data stored ASCII format dedicated folder, data manuals files enable analyst access data intended NCES.","code":""},{"path":"preface.html","id":"history-of-nces-data-analysis","chapter":"Preface","heading":"0.3 History of NCES Data Analysis","text":"advent EdSurvey, access NCES data, researchers implicitly follow specific steps described later foreword using associated software packages exist solely step. Analysts NCES data carefully execute step; otherwise, mistake meant start .mentioned previously, NCES settled creating one set files stored CD-ROM DVD data set released. set files contained enough information user consumer NCES data, regardless statistical software package used. accessibility, decision made following three steps generally make data available average user, steps still applicable today.\n* allowing analysts first select variables analysis, generating syntax files either SPSS, SAS, sometimes STATA\n* using syntax file generate reduced data file appropriate statistical software previous step, cleaning performing necessary recodes\n* importing data software programs WESVAR testing hypotheses\nWESVAR needed , traditionally, NCES data collected using multistage sampling methodologies. Earlier versions SAS SPSS inadequate analyzing sample data (Cohen & Jiang, 1999).","code":""},{"path":"preface.html","id":"step-1-importing-nces-data-using-the-electronic-code-book","chapter":"Preface","heading":"0.3.1 Step 1: Importing NCES Data Using the Electronic Code Book","text":"NCES data constitute large datasets, several hundred variables thousands cases. memory personal computers gigabytes decade ago, analysts upload data working memory manipulate data investigations. problem still relevant today. example, NAEP mathematics reading assessment Grades 4 8 can 1500 variables close 250,000 cases. decided NCES dataset produced along electronic code book (ECB). ECB allowed analysts explore variables data files, including obtaining frequency distribution category nominal ordinal variable distribution information (min, max, standard deviation, mean) variables interval ratio levels measurement. analyst may determine variables interest reviewing ECB create either SPSS SAS syntax file ECB.Across time, NCES noticed almost every data collection program within NCES created ECB varying unique features. Thus, someone analyze data different program offices learn individual features ECB.","code":""},{"path":"preface.html","id":"step-2-data-cleaning-and-recoding","chapter":"Preface","heading":"0.3.2 Step 2: Data Cleaning and Recoding","text":"step, analyst can use ECB generate final data. step also appropriate place perform data cleaning recoding.","code":""},{"path":"preface.html","id":"step-3-performing-hypotheses-testing-and-variance-estimation","chapter":"Preface","heading":"0.3.3 Step 3: Performing Hypotheses Testing and Variance Estimation","text":"Use WESVAR specify sampling design feature, compute estimates proportions along standard errors, perform hypothesis testing. WESVAR utility tools performing analyses complex samples; traditional statistical software packages. types analyses WESVAR designed perform limited, generate sharable codes. NCES responsive various requests improvement need updates.Analysts must carefully plan analyses, selecting needed variables Step 1 performing data cleaning manipulation Step 2. Step 3, every time mistake originating previous step discovered, analyst must start .WESVAR developed primarily computations variance complex samples estimation group scores using students’ plausible values large-scale assessment datasets. WESVAR generate additional outputs ones incorporated created. also created mostly menu driven allow average analysts comfortably use without requirement writing code.one can see, analyst NCES data needs knowledge described previously accessing data testing hypotheses. Across time, features analysis package remained unchanged budgetary constraints software limitations. NCES data users inquired WESVAR couldn’t offer features, ability share code collaborators advanced data manipulation. 2014, NCES prioritized creating analysis tool seek address issues raised research community.Thus, NCES set create tool incorporate steps listed previously, expanded research community allowing () input analyses functions included tool, (b) analyses functions contributed research community, (c) code sharing. importantly, tool affordable research community. Around time, institutions higher learning moving away traditional software packages favoring open-source packages.","code":""},{"path":"preface.html","id":"development-of-the-edsurvey-r-package","chapter":"Preface","heading":"0.4 Development of the EdSurvey R Package","text":"R programming language software environment statistical computing graphics supported R Foundation Statistical Computing (R Core Team, 2016). R language widely used academia research community developing statistical software statistical analysis, NCES chose language create tool called EdSurvey. R software’s free extensible distribution ecosystem, CRAN, provides access wide variety bundled code computing. Today, EdSurvey, researchers use NCES data additional tool data access analyses.EdSurvey package developed R programming language. callable R programming environment, augments capability R base, thus creating powerful environment analysts. addition augmentation R base EdSurvey, users also add different existing packages, ggplot2—data visualization package written R—create eye-catching graphics share results EdSurvey output audiences. , analysts using EdSurvey access package CRAN. also can create package EdSurvey callable augment functionality.manual guide analysts want analyze data collection choice. expanding EdSurvey’s functionality, next section expand structure NCES datasets.","code":""},{"path":"preface.html","id":"considerations-for-analyzing-nces-data","chapter":"Preface","heading":"0.5 Considerations for Analyzing NCES Data","text":"important remind reader NCES data either samples censuses. Census data collected universe possible entities interest, mostly schools, school districts, postsecondary institutions. Sample data collected using multistage complex sample methodologies, population interest American children students 9 months old postsecondary education, including teachers, principals, schools, school districts. sampled data subset two major groups: cross-sectional longitudinal. Cross-sectional data can partition assessment data nonassessment data. Assessment data NAEP TIMSS cross-sectional, complex, sampled data assessment component. assessment component allows inference student groups’ cognitive performance variety subjects. Thus, manual three major analysis sections: assessment data, longitudinal data, cross-sectional data. sample datasets collected using multistage sample methodologies ensure representativeness population interest.Complex samples require different methodologies compute estimates associated standard errors. methodologies might either require full sample weights replicates stratum variable primary sampling unit. Longitudinal data, also known panel data, collect data individuals across time. familiar econometrics terminology, development team notes NCES panel data unbalanced expensive follow subjects across time. sample sizes decrease time elapses. Assessment data cross-sectional, assessment component measuring students know can reporting research.EdSurvey conceived developed go-analysis tool cross-sectional, assessment, longitudinal datasets produced NCES. package incorporates primary functionalities ECB. researcher starts forming connection survey data access codebook, search variables, perform operations selecting needed variables analysis. package contains functionalities within one piece software, easy researcher research select new variables answer specific research question. user’s guide showcase functions examples different datasets.","code":""},{"path":"preface.html","id":"overview-of-edsurvey-fundamentals","chapter":"Preface","heading":"0.6 Overview of EdSurvey Fundamentals","text":"EdSurvey built-command design perform specific tasks NCES data files. commands can access files data file, codebook . second group commands designed help analyst explore design variables variables plausible values. third group commands designed statistical analyses, including creating summary statistics usually appear NCES reports (e.g., means, standard errors, achievement level, percentile results), correlations, regressions. last group commands allows performance advanced analyses, hierarchical linear modeling direct estimation (Version 2.7). development continues, functions become available subsequent releases.general, built-functions EdSurvey following structure :\\(Command (argument_1, argument_2, … argument_i, option_1, option_2, …)\\)\\(Command\\) action analyst wants perform, $argument_i $ required element must appear particular command. number arguments depends given command, \\(option_i\\): added enhance output command.user installs EdSurvey, next logical thing read built-data files, read data repository, read Restricted-Use D ata received Institute Education Sciences data officer. command read data ReadDATA, data can substituted NAEP, TIMSS, forth. execute command, EdSurvey must know location data file. , argument specifies path folder data file located necessary command run. also important good understanding data interest unleashing command must always aware available resources computer. example, 2015 TIMSS data includes fourth-grade mathematics science assessment results relating students, parents, teachers, schools, curricular background data covering 47 participating countries six benchmarking entities. data available eighth-grade students 39 countries six benchmarking entities. Running command readTIMSS load data working memory:avoid memory overload , development team recommends analysts load data grade country (countries) interest repository, illustrated following example:data loaded, EdSurvey automatically detects design elements needed computing estimates standard errors. case assessment data, standard error two components: sampling error measurement error. elements data file needed computation full sample weight, replicate weights (stratum principal sampling unit variables), well plausible values. One read function unique one study EdSurvey NCES data file structure, data layout variable coding, size. also noted , general, different survey programs use different methodologies compute variances. Read reading survey data Chapter 4.read EdSurvey, next set commands available analyst showCommand, namely, showCodebook, showWeights, showPlausibleValues. following example illustrates usage showPlausibleValues:option verbose = TRUE adds additional descriptions. Please note running analyses plausible values, one needs supply short name set plausible values, found function, “mmat” (mathematics performance scale) “ssci” (science performance scale) TIMSS datasets. EdSurvey uses plausible value calculations correctly accounts imputation variance plausible values (Mislevy et al., 1992).last function described search function. command searchSDF searches survey data frame returns variable names labels meeting criteria specified user. Users can search either variable name labels variables. following examples illustrate several possible implementations search function:One can use Boolean algebra search:Remember TIMSS contains assessment data mathematics science Grades 4 8 well student, parent, teacher, school, curricular background data. One narrow search given background data file.addition option levels = TRUE search function enables close view categorical variable interest. next example showcases different search usage argument levels.Please note estimates weighted. see unweighted frequency table, use option weightVar = NULL:Additional data exploration functions Chapter 5.previous examples give brief introduction EdSurvey commands, look like, purpose. Many commands appear subsequent chapters. commands created based questions, inquiries, suggestions, surveys collected 2 decades training NCES, AERA, National Council Measurement Education interacting analysts data products. researcher pay particular attention commands specific types data apply dataset. users progress manual analyzing data, must always remember () R environment, (b) commands R base available given time, (c) ability augment EdSurvey tools packages CRAN.end manual, Chapters 11 12 detail mathematics used create functions EdSurvey. done purposefully. development team wants user aware even though package makes many computations easily accessible, intensive computations several methodologies either existed developed implemented package. entire EdSurvey package complete still developed. team strongly encourages anyone suggestions methodology added developed add-contact us possible implementation. development team guarantee inclusion give suggestions fair assessment.","code":"\nMydatafile <-   readTIMSS(path = \"~/TIMSS/2015\")\n#Read Grade 4 Denmark 2015 TIMSS survey into the dataframe Dnk2015 \nDnk2015 <- readTIMSS(path = \"~/TIMSS/2015\", countries = \"dnk\", gradeLvl = 4)\nDnk2015#> Found cached Grade 4 data for country code \"dnk: Denmark\".\n#> edsurvey.data.frame data level detail:\n#> |---DataLevel----|----Rows----|--Columns---|---MergeType----|-------MatchedRecords-------|-OK-|\n#> |Student         |        3710|        1196|                |*base level*                | ✓  |\n#> |>School         |        3710|         101|many:one        |3710 of 3710                | ✓  |\n#> |>Teacher        |        5897|         745|one:many        |5897 of 5897                | ✓  |\n#> edsurvey.data.frame for 2015 TIMSS International\n#>   (Mathematics and Science; Grade 4) in Denmark\n#> Dimensions: 5900 rows and 2043 columns.\n#> \n#> There are 4 full sample weights in this\n#>   edsurvey.data.frame:\n#>   'totwgt' with 150 JK replicate weights (the\n#>   default).\n#> \n#>   'tchwgt' with 150 JK replicate weights.\n#> \n#>   'matwgt' with 150 JK replicate weights.\n#> \n#>   'sciwgt' with 150 JK replicate weights.\n#> \n#> \n#> There are 14 subject scale(s) or subscale(s) in this\n#>   edsurvey.data.frame:\n#> 'mmat' subject scale or subscale with 5 plausible\n#>   values (the default).\n#> \n#> 'ssci' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mdat' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mgeo' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mnum' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'sear' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'slif' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'sphy' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mkno' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mapp' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'mrea' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'skno' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'sapp' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'srea' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> \n#> Omitted Levels: 'Multiple', 'NA', 'OMITTED', 'OMITTED\n#>                 OR INVALID', 'OMITTED (BLANK ONLY)',\n#>                 'BLANK(OMITTED)', 'BLANK(MISSING)',\n#>                 'BLANK(MISS)', 'MIS.', 'MISS.', 'N.\n#>                 REA.', 'N.REA.', 'N. ADM.', 'N.\n#>                 ADMIN.', 'NOT ADMIN', 'NOT APPL',\n#>                 'NOT ADMINISTERED', 'NOT REACHED',\n#>                 'NOT ADMIN.', 'NOT APPLICABLE',\n#>                 'LOGICALLY NOT APPLICABLE',\n#>                 'MISSING', and '(Missing)'\n#> Achievement Levels:\n#> Low International Benchmark: 400\n#> Intermediate International Benchmark: 475\n#> High International Benchmark: 550\n#> Advanced International Benchmark: 625\nshowPlausibleValues(data = Dnk2015, verbose=TRUE)\n#> There are 14 subject scale(s) or subscale(s) in this\n#>   edsurvey.data.frame:\n#> 'mmat' subject scale or subscale with 5 plausible\n#>   values (the default).\n#>   The plausible value variables are: 'asmmat01',\n#>   'asmmat02', 'asmmat03', 'asmmat04', and 'asmmat05'\n#> \n#> 'ssci' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asssci01',\n#>   'asssci02', 'asssci03', 'asssci04', and 'asssci05'\n#> \n#> 'mdat' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmdat01',\n#>   'asmdat02', 'asmdat03', 'asmdat04', and 'asmdat05'\n#> \n#> 'mgeo' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmgeo01',\n#>   'asmgeo02', 'asmgeo03', 'asmgeo04', and 'asmgeo05'\n#> \n#> 'mnum' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmnum01',\n#>   'asmnum02', 'asmnum03', 'asmnum04', and 'asmnum05'\n#> \n#> 'sear' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'assear01',\n#>   'assear02', 'assear03', 'assear04', and 'assear05'\n#> \n#> 'slif' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asslif01',\n#>   'asslif02', 'asslif03', 'asslif04', and 'asslif05'\n#> \n#> 'sphy' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'assphy01',\n#>   'assphy02', 'assphy03', 'assphy04', and 'assphy05'\n#> \n#> 'mkno' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmkno01',\n#>   'asmkno02', 'asmkno03', 'asmkno04', and 'asmkno05'\n#> \n#> 'mapp' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmapp01',\n#>   'asmapp02', 'asmapp03', 'asmapp04', and 'asmapp05'\n#> \n#> 'mrea' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asmrea01',\n#>   'asmrea02', 'asmrea03', 'asmrea04', and 'asmrea05'\n#> \n#> 'skno' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'asskno01',\n#>   'asskno02', 'asskno03', 'asskno04', and 'asskno05'\n#> \n#> 'sapp' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'assapp01',\n#>   'assapp02', 'assapp03', 'assapp04', and 'assapp05'\n#> \n#> 'srea' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'assrea01',\n#>   'assrea02', 'assrea03', 'assrea04', and 'assrea05'\n# Search for variables with a name or label that contains “computer”\nsearchSDF(string = \"computer\", data = Dnk2015)\n#>    variableName\n#> 1       asbg05a\n#> 2       asbg05b\n#> 3       asbg10a\n#> 4       asbg10b\n#> 5       asbg10c\n#> 6        acbg11\n#> 7      acbg14ah\n#> 8      acbg14bb\n#> 9      acbg14cb\n#> 10      atbm05a\n#> 11     atbm05ba\n#> 12     atbm05bb\n#> 13     atbm05bc\n#> 14      atbs04a\n#> 15     atbs04ba\n#> 16     atbs04bb\n#> 17     atbs04bc\n#> 18     atbs04ca\n#> 19     atbs04cb\n#> 20     atbs04cc\n#> 21     atbs04cd\n#>                                              Labels\n#> 1            GEN\\\\HOME POSSESS\\\\COMPUTER TABLET OWN\n#> 2         GEN\\\\HOME POSSESS\\\\COMPUTER TABLET SHARED\n#> 3       GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\HOME\n#> 4     GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\SCHOOL\n#> 5      GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\OTHER\n#> 6                       GEN\\\\TOTAL NUMBER COMPUTERS\n#> 7           GEN\\\\SHORTAGE\\\\GEN\\\\COMPUTER TECHNOLOGY\n#> 8             GEN\\\\SHORTAGE\\\\MAT\\\\COMPUTER SOFTWARE\n#> 9             GEN\\\\SHORTAGE\\\\SCI\\\\COMPUTER SOFTWARE\n#> 10    MAT\\\\COMPUTER TABLET AVAILABILITY DURING MATH\n#> 11 MAT\\\\ACCESS TO COMPUTER\\\\EACH STD HAS A COMPUTER\n#> 12     MAT\\\\ACCESS TO COMPUTER\\\\CLASS HAS COMPUTERS\n#> 13    MAT\\\\ACCESS TO COMPUTER\\\\SCHOOL HAS COMPUTERS\n#> 14     SCI\\\\COMPUTER TABLET AVAILABILITY DURING SCI\n#> 15 SCI\\\\ACCESS TO COMPUTER\\\\EACH STD HAS A COMPUTER\n#> 16     SCI\\\\ACCESS TO COMPUTER\\\\CLASS HAS COMPUTERS\n#> 17    SCI\\\\ACCESS TO COMPUTER\\\\SCHOOL HAS COMPUTERS\n#> 18 SCI\\\\COMPUTER TABLET ACTIVITIES\\\\PRACTICE SKILLS\n#> 19   SCI\\\\COMPUTER TABLET ACTIVITIES\\\\LOOK UP IDEAS\n#> 20   SCI\\\\COMPUTER TABLET ACTIVITIES\\\\DO PROCEDURES\n#> 21 SCI\\\\COMPUTER TABLET ACTIVITIES\\\\STUDY PHENOMENA\n#>    fileFormat\n#> 1     Student\n#> 2     Student\n#> 3     Student\n#> 4     Student\n#> 5     Student\n#> 6      School\n#> 7      School\n#> 8      School\n#> 9      School\n#> 10    Teacher\n#> 11    Teacher\n#> 12    Teacher\n#> 13    Teacher\n#> 14    Teacher\n#> 15    Teacher\n#> 16    Teacher\n#> 17    Teacher\n#> 18    Teacher\n#> 19    Teacher\n#> 20    Teacher\n#> 21    Teacher\n# Search for a variable with name or label that contains computer, or    internet, or phone\nsearchSDF(string=\"computer|internet|phone\", data=Dnk2015)\n#>    variableName\n#> 1       m051134\n#> 2       asbg05a\n#> 3       asbg05b\n#> 4       asbg05e\n#> 5       asbg10a\n#> 6       asbg10b\n#> 7       asbg10c\n#> 8       mr51134\n#> 9       mi51134\n#> 10       acbg11\n#> 11     acbg14ah\n#> 12     acbg14bb\n#> 13     acbg14cb\n#> 14      atbm05a\n#> 15     atbm05ba\n#> 16     atbm05bb\n#> 17     atbm05bc\n#> 18      atbs04a\n#> 19     atbs04ba\n#> 20     atbs04bb\n#> 21     atbs04bc\n#> 22     atbs04ca\n#> 23     atbs04cb\n#> 24     atbs04cc\n#> 25     atbs04cd\n#>                                              Labels\n#> 1              MONTHS PETER PAID LESS FOR PHONE (1)\n#> 2            GEN\\\\HOME POSSESS\\\\COMPUTER TABLET OWN\n#> 3         GEN\\\\HOME POSSESS\\\\COMPUTER TABLET SHARED\n#> 4            GEN\\\\HOME POSSESS\\\\INTERNET CONNECTION\n#> 5       GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\HOME\n#> 6     GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\SCHOOL\n#> 7      GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\OTHER\n#> 8              MONTHS PETER PAID LESS FOR PHONE (1)\n#> 9              MONTHS PETER PAID LESS FOR PHONE (1)\n#> 10                      GEN\\\\TOTAL NUMBER COMPUTERS\n#> 11          GEN\\\\SHORTAGE\\\\GEN\\\\COMPUTER TECHNOLOGY\n#> 12            GEN\\\\SHORTAGE\\\\MAT\\\\COMPUTER SOFTWARE\n#> 13            GEN\\\\SHORTAGE\\\\SCI\\\\COMPUTER SOFTWARE\n#> 14    MAT\\\\COMPUTER TABLET AVAILABILITY DURING MATH\n#> 15 MAT\\\\ACCESS TO COMPUTER\\\\EACH STD HAS A COMPUTER\n#> 16     MAT\\\\ACCESS TO COMPUTER\\\\CLASS HAS COMPUTERS\n#> 17    MAT\\\\ACCESS TO COMPUTER\\\\SCHOOL HAS COMPUTERS\n#> 18     SCI\\\\COMPUTER TABLET AVAILABILITY DURING SCI\n#> 19 SCI\\\\ACCESS TO COMPUTER\\\\EACH STD HAS A COMPUTER\n#> 20     SCI\\\\ACCESS TO COMPUTER\\\\CLASS HAS COMPUTERS\n#> 21    SCI\\\\ACCESS TO COMPUTER\\\\SCHOOL HAS COMPUTERS\n#> 22 SCI\\\\COMPUTER TABLET ACTIVITIES\\\\PRACTICE SKILLS\n#> 23   SCI\\\\COMPUTER TABLET ACTIVITIES\\\\LOOK UP IDEAS\n#> 24   SCI\\\\COMPUTER TABLET ACTIVITIES\\\\DO PROCEDURES\n#> 25 SCI\\\\COMPUTER TABLET ACTIVITIES\\\\STUDY PHENOMENA\n#>    fileFormat\n#> 1     Student\n#> 2     Student\n#> 3     Student\n#> 4     Student\n#> 5     Student\n#> 6     Student\n#> 7     Student\n#> 8     Student\n#> 9     Student\n#> 10     School\n#> 11     School\n#> 12     School\n#> 13     School\n#> 14    Teacher\n#> 15    Teacher\n#> 16    Teacher\n#> 17    Teacher\n#> 18    Teacher\n#> 19    Teacher\n#> 20    Teacher\n#> 21    Teacher\n#> 22    Teacher\n#> 23    Teacher\n#> 24    Teacher\n#> 25    Teacher\n#Search a keyword in the student file only\nsearchSDF(string = \"computer\", data = Dnk2015, fileFormat =\"student\")\n#>   variableName\n#> 1      asbg05a\n#> 2      asbg05b\n#> 3      asbg10a\n#> 4      asbg10b\n#> 5      asbg10c\n#>                                          Labels fileFormat\n#> 1        GEN\\\\HOME POSSESS\\\\COMPUTER TABLET OWN    Student\n#> 2     GEN\\\\HOME POSSESS\\\\COMPUTER TABLET SHARED    Student\n#> 3   GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\HOME    Student\n#> 4 GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\SCHOOL    Student\n#> 5  GEN\\\\USE COMPUTER TABLET FOR HOMEWORK\\\\OTHER    Student\n# Search multiple keywords\nsearchSDF(string = c(\"computer\",\"homework\",\"school\"), data = Dnk2015, levels = TRUE)\n#> Variable: asbg10b\n#> Label: GEN\\USE COMPUTER TABLET FOR HOMEWORK\\SCHOOL\n#> Levels (Lowest level first):\n#>      1. EVERY DAY OR ALMOST EVERY DAY\n#>      2. ONCE OR TWICE A WEEK\n#>      3. ONCE OR TWICE A MONTH\n#>      4. NEVER OR ALMOST NEVER\n#>      9. OMITTED OR INVALID\n# Display levels of the variable \"asbg10b\"\nlevelsSDF(varnames = \"asbg10b\", data = Dnk2015)\n#> Levels for Variable 'asbg10b' (Lowest level first):\n#>     1. EVERY DAY OR ALMOST EVERY DAY (n = 840)\n#>     2. ONCE OR TWICE A WEEK (n = 1400)\n#>     3. ONCE OR TWICE A MONTH (n = 670)\n#>     4. NEVER OR ALMOST NEVER (n = 600)\n#>     9. OMITTED OR INVALID* (n = 120)\n#>     NOTE: * indicates an omitted level.\nsummary2(data = Dnk2015, variable = \"asbg10b\", weightVar = NULL)\n#> Estimates are not weighted.\n#>                         asbg10b    N   Percent\n#> 1 EVERY DAY OR ALMOST EVERY DAY  840 22.641509\n#> 2          ONCE OR TWICE A WEEK 1400 36.873315\n#> 3         ONCE OR TWICE A MONTH  670 18.086253\n#> 4         NEVER OR ALMOST NEVER  600 16.253369\n#> 5            OMITTED OR INVALID  120  3.288410\n#> 6                          <NA>  110  2.857143"},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Last edited: February 2022Suggested Citation\nZhang, T. Introduction. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.Large-scale educational assessments—NAEP (National Assessment Educational Progress), TIMSS (Trends International Mathematics Science Study), PISA (Programme International Student Assessment)—collect data related education United States nations. quality quantity inherent information, assessment data valuable assets policymakers, education practitioners, researchers explore understand multiple education-related issues childhood adulthood, schools, homes, neighborhoods. large-scale assessments measure activities outcomes educational systems institutions jurisdictions (e.g., districts, states, countries) address jurisdictions educate children success. gather demographic information contextual data participating students homes, schools, teachers various topics, crucial curricular, instructional, resource-related factors can impact teaching learning process.special sampling testing designs, large-scale educational assessment data allow inference jurisdiction level regarding target sample domains assessed, example, U.S. students’ achievement mathematics Grade 8. Meanwhile, designs implications data analyses. Often, customized statistical analysis modules need properly account designs data analysis.","code":""},{"path":"introduction.html","id":"sampling-design","chapter":"1 Introduction","heading":"1.1 Sampling Design","text":"large-scale assessments employ complex, multistage, clustered sampling design (Johnson & Rust, 1992; LaRoche et al., 2016; OECD, 2018). Initially, schools selected based specified probabilities. second stage, NAEP PISA assessments, students within sampled schools undergo random selection. IEA (International Association Evaluation Educational Achievement) studies, random process selects one two intact classrooms grade; students classrooms assessed. Overall, probability selecting schools students varies depending school size characteristics. data analyses, sampling weights therefore need accommodate fact units, schools students, might unequal probabilities selection process.important considerations NCES survey analysis. Simple random sampling calculating standard errors estimates appropriate large-scale assessment data analyses. Student sampling occurs clusters (e.g., school class) therefore similar characteristics sampled randomly. Although many variance estimation methods exist adjust clustering effects, popular approach used NAEP, IEA studies, OECD studies replication methods. particular, NAEP IEA studies use jackknife repeated replication method; OECD studies PISA employ balanced repeated replication (BRR) method (Johnson & Rust, 1992; Rust & Rao, 1996; Wolter, 2007).","code":""},{"path":"introduction.html","id":"testing-design","chapter":"1 Introduction","heading":"1.2 Testing Design","text":"Large-scale assessments create large item pool provide comprehensive coverage subject. example, NAEP mathematics reading cognitive tests, item number can range 100 200 per subject per grade (Educational Progress, 2018) . unrealistic administer items students, parents schools likely consent. Therefore, large-scale assessments NAEP, TIMSS, PISA use matrix sampling design items sampled student takes portion entire pool test items. design reduces student burden allowing maximum coverage content area student performance. downside, however, increases complexity estimating student performance. Using traditional methods generating student proficiency scores leads biased variance estimates population parameters. Instead, plausible values technique employed proficiency estimates variance estimation (Mislevy et al., 1992; Rutkowski et al., 2010). book summarizes methodology used EdSurvey large-scale assessment data Chapter 8.","code":""},{"path":"introduction.html","id":"why-edsurvey","chapter":"1 Introduction","heading":"1.3 Why EdSurvey","text":"Free tools supplied assessment institutes government agencies allow research community access analyze large-scale datasets, including International Database Analyzer (IDB Analyzer), NCES Electronic Code Books, NAEP Data Explorer, International Data Explorer, WesVar, software. Nevertheless, research analysts use commercially available software packages (e.g., SPSS, SAS, STATA) data merging, cleaning, manipulation importing data tools WesVar account complex sample designs use plausible values. free tools menu-driven software programs create sharable code. tools created average statistical user mind limit types statistical analyses can support.EdSurvey runs R, programming language licensed GNU General Public License widely used academic research communities. package can process analyze large-scale assessment data appropriate procedures. one-stop shop data downloading, processing, manipulating, analyzing survey data. packages R analyze large-scale assessment data, including survey (Lumley, 2004), lavaan.survey (Oberski, 2017), svyPVpack (Manuel & Peterbauer, 2014), BIFIE (Robitzsch & Oberwimmer, 2019), intsvy (Caro & Biecek, 2017) . Among packages, limited data coverage (e.g., tailored international large-scale assessments ), require user input survey design plausible values used. EdSurvey developed analyze large-scale assessments United States participates NCES, complex sampling design plausible value methodology incorporated seamlessly. advantages EdSurvey follows:Allows data manipulation inside outside package.Minimizes memory footprint reading required data.Enables users search names labels variables, view frequencies percentages response categories variables, visualize data.Performs complex sample analysis operations.Computes analyses plausible values.Performs multilevel analyses modeling.Expands functions data supports meet needs analysts various levels expertise.EdSurvey follows methodology used large-scale assessments estimation (Johnson & Rust, 1992; Mislevy et al., 1992). offers three methods variance estimation: jackknife replication method, BRR, Taylor series approximation. See Chapter 8 estimation procedures, including means, percentages, percentiles, achievement levels, regression analysis, variance estimation without presence plausible values.","code":""},{"path":"installation.html","id":"installation","chapter":"2 Installing R and EdSurvey and Loading the Package","heading":"2 Installing R and EdSurvey and Loading the Package","text":"Last edited: February 2022Suggested Citation\nLee, M. Installing R EdSurvey Loading Package. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"installation.html","id":"software-requirements","chapter":"2 Installing R and EdSurvey and Loading the Package","heading":"2.1 Software Requirements","text":"Unless already R version 3.5 later, install latest R version—available online https://cran.r-project.org/. Users also may want install RStudio desktop, interface many find easier follow. RStudio available online https://www.rstudio.com/products/rstudio/download/.","code":""},{"path":"installation.html","id":"installing-and-loading-edsurvey","chapter":"2 Installing R and EdSurvey and Loading the Package","heading":"2.2 Installing and Loading EdSurvey","text":"Inside R, run following command install EdSurvey well package dependencies:package successfully installed, load EdSurvey can loaded following command:","code":"\ninstall.packages(\"EdSurvey\")\nlibrary(EdSurvey)"},{"path":"philosophyOfAnalysis.html","id":"philosophyOfAnalysis","chapter":"3 Philosophy of Analysis","heading":"3 Philosophy of Analysis","text":"Last edited: July 2023Suggested Citation\nLee, M. Philosophy Analysis. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.chapter explains main use cases EdSurvey. facilitate learning process, recommend workflow detailed following infographic:workflow following steps:Install load package.Access data.Understand data.Manipulate data.Run analysis.First, use EdSurvey download publicly available data read data; move understand data, including tasks look search codebook; explore data, including tasks summarizing variables; analyze data either inside EdSurvey R packages.previous chapter detailed installation loading EdSurvey library; chapter explores subsequent steps.","code":""},{"path":"philosophyOfAnalysis.html","id":"download-or-license-data","chapter":"3 Philosophy of Analysis","heading":"3.1 Download or License Data","text":"Although bulk book focus NAEP data, EdSurvey includes family download functions NCES publicly available data files, including following:TIMSS: Trends International Mathematics Science Study TIMSS Advanced (downloadTIMSS, downloadTIMSSAdv)PIRLS: Progress International Reading Literacy Study (downloadPIRLS)ePIRLS: Electronic Progress International Reading Literacy Study (download_ePIRLS)CIVED: Civic Education Study 1999 International Civic Citizenship Study (downloadCivEDICCS)ICILS: International Computer Information Literacy Study (downloadICILS)PISA: Programme International Student Assessment (downloadPISA)PIAAC: Programme International Assessment Adult Competencies (downloadPIAAC)TALIS: Teaching Learning International Survey (downloadTALIS)ECLS: Early Childhood Longitudinal Study (downloadECLS_K)ELS: Education Longitudinal Study (downloadELS)HSLS: High School Longitudinal Study 2009 (downloadHSLS)NHES: National Household Education Surveys (downloadNHES)SSOCS: School Survey Crime Safety (downloadSSOCS)example, downloadTIMSS function download publicly available TIMSS data directory user specifies e.g., \"C:/Data\"). One also can manually download desirable survey data respective websites.restricted datasets NAEP, please follow restricted-use instructions save whole intact data folder directory read data .","code":"\ndownloadTIMSS(years = 2015, root = \"C:/\", cache=FALSE)"},{"path":"philosophyOfAnalysis.html","id":"reading-in-data","chapter":"3 Philosophy of Analysis","heading":"3.2 Reading in Data","text":"data prepared system, read family functions open connection specified data file conduct analysis. read functions follows:TIMSS TIMSS Advanced (readTIMSS, readTIMSSAdv)PIRLS (readPIRLS)ePIRLS (read_ePIRLS)CIVED (readCivEDICCS)ICILS (readICILS)PISA (readPISA)PIAAC (readPIAAC)TALIS (readTALIS)ECLS (readECLS_K2011 readECLS_K1998)ELS: Education Longitudinal Study (readELS)BTLS: Beginning Teacher Longitudinal Study (readBTLS)HSLS (readHSLS)NHES (readNHES)SSOCS (readSSOCS)example, can access 2015 TIMSS data readTIMSS function, selecting data path, vector countries, gradeLvl interest:read function unique given differences across survey designs, functions typically follow standard convention across functions ease use. learn particular read function, refer Chapter 4, use help(package = \"EdSurvey\") find survey interest refer help documentation guidance.","code":"\nTIMSS15 <- readTIMSS(path = \"C:/TIMSS2015/\", countries = c(\"usa\"), gradeLvl = \"4\")"},{"path":"philosophyOfAnalysis.html","id":"vignette-sample-nces-dataset","chapter":"3 Philosophy of Analysis","heading":"3.2.1 Vignette Sample NCES Dataset","text":"follow along vignette, load NAEP Primer dataset M36NT2PM assign name sdf call:command uses somewhat unusual way identifying file path (system.file function). Primer data bundled NAEPprimer package, system.file function finds regardless package installed machine. datasets referred system path.","code":"\nlibrary(EdSurvey)\n#> Loading required package: car\n#> Loading required package: carData\n#> Loading required package: lfactors\n#> lfactors v1.0.4\n#> Loading required package: Dire\n#> Dire v2.2.0\n#> EdSurvey v4.0.8\nsdf <- readNAEP(path = system.file(\"extdata/data\", \"M36NT2PM.dat\", package = \"NAEPprimer\"))"},{"path":"philosophyOfAnalysis.html","id":"nces-dataset","chapter":"3 Philosophy of Analysis","heading":"3.2.2 NCES Dataset","text":"load unique NCES dataset analysis, select pathway DAT file NAEP folder, needs NCES standard folder directory titled /Data:function recognizes naming convention used NCES NAEP file names determine sample design assessment information attached resulting edsurvey.data.frame. readNAEP function transparently accesses necessary sample information silently attaches data.1It possible file pathways special characters local directory cause problems reading data R. Commonly used characters require escapes include single quotation marks ('), double quotation marks (\"), backslashes (\\). general solution resolving issues adding escape (.e., backslash key: \\) character. example, add escape single quote used Nat'l, well backslash copied following hypothetical Windows file directory:alternative option involve using file.choose() function select data file via search window. function opens system’s default file explorer select particular file. file can saved object, example chosenFile, can read using readNAEP:read , student school data NCES dataset can analyzed merged loading data R working environment. readNAEP function built connect student data file, silently holds file formatting school dataset read. details retrieving school variables analysis outlined later chapter getData function.","code":"\nsdf2 <- readNAEP(filepath = '//.../Data/file.dat')# original\n\"C:\\2015 Nat'l Assessment Data\\Data\\file.dat\"\n\n# updated with escapes:\nsdf2 <- readNAEP(filepath = \"C:\\\\2015 Nat\\'l Assessment Data\\\\Data\\\\file.dat\")\nchosenFile <- file.choose()\nsdf2 <- readNAEP(filepath = chosenFile)"},{"path":"philosophyOfAnalysis.html","id":"understand-data","chapter":"3 Philosophy of Analysis","heading":"3.3 Understand Data","text":"Information edsurvey.data.frame can obtained multiple ways. get general data information, simply call print typing name data.frame object (.e., sdf) console.basic functions work data.frame, dim, nrow, ncol, also work edsurvey.data.frame.2 help check dimensions sdf.colnames function can used list variable names data:conduct powerful search NAEP data variables, use searchSDF function, returns variable names labels edsurvey.data.frame based character string. user can specify data source (either “student” “school”) user like search. example, following call searchSDF searches character string \"book\" edsurvey.data.frame specifies fileFormat search student data file:levels labels variable search via searchSDF() also can returned setting levels = TRUE:| () operator can used search several strings simultaneously:vector strings used search variables contain multiple strings, “book” “home”; string present variable label can used filter results:return levels labels particular variable, use levelsSDF():Access full codebook using showCodebook() retrieve variable names, variable labels, value labels survey. function pairs well View() function easily explore dataset:Basic information plausible values weights edsurvey.data.frame can seen print function. variables associated plausible values weights can seen showPlausibleValues showWeights functions, respectively, verbose argument set TRUE:functions getStratumVar getPSUVar return default stratum variable name primary sampling unit (PSU) variable associated weight variable.functions quite useful accessing variables associated weights longitudinal surveys.","code":"\nsdf\n#> edsurvey.data.frame for 2005 NAEP National - Primer\n#>   (Mathematics; Grade 8) in USA\n#> Dimensions: 17606 rows and 303 columns.\n#> \n#> There is 1 full sample weight in this\n#>   edsurvey.data.frame:\n#>   'origwt' with 62 JK replicate weights (the\n#>   default).\n#> \n#> \n#> There are 6 subject scale(s) or subscale(s) in this\n#>   edsurvey.data.frame:\n#> 'num_oper' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'measurement' subject scale or subscale with 5\n#>   plausible values.\n#> \n#> 'geometry' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'data_anal_prob' subject scale or subscale with 5\n#>   plausible values.\n#> \n#> 'algebra' subject scale or subscale with 5 plausible\n#>   values.\n#> \n#> 'composite' subject scale or subscale with 5\n#>   plausible values (the default).\n#> \n#> \n#> Omitted Levels: 'Multiple', 'NA', and 'Omitted'\n#> \n#> Default Conditions:\n#> tolower(rptsamp) == \"reporting sample\"\n#> Achievement Levels:\n#> Mathematics:\n#> Basic: 262.00\n#> Proficient: 299.00\n#> Advanced: 333.00\ndim(x = sdf)\n#> [1] 17606   303\nnrow(x = sdf)\n#> [1] 17606\nncol(x = sdf)\n#> [1] 303\ncolnames(x = sdf)\n#>   [1] \"ROWID\"   \"year\"    \"cohort\"  \"scrpsu\"  \"dsex\"   \n#>   [6] \"iep\"     \"lep\"     \"ell3\"    \"sdracem\" \"pared\"  \n#>  [11] \"b003501\" \"b003601\" \"b013801\" \"b017001\" \"b017101\"\n#>  [16] \"b018101\" \"b018201\" \"b017451\" \"m815401\" \"m815501\"\n#>  [21] \"m815601\" \"m815801\" \"m815701\" \"rptsamp\" \"repgrp1\"\n#>  [26] \"repgrp2\" \"jkunit\"  \"origwt\"  \"srwt01\"  \"srwt02\" \n#>  [31] \"srwt03\"  \"srwt04\"  \"srwt05\"  \"srwt06\"  \"srwt07\" \n#>  [36] \"srwt08\"  \"srwt09\"  \"srwt10\"  \"srwt11\"  \"srwt12\" \n#>  [41] \"srwt13\"  \"srwt14\"  \"srwt15\"  \"srwt16\"  \"srwt17\" \n#>  [46] \"srwt18\"  \"srwt19\"  \"srwt20\"  \"srwt21\"  \"srwt22\" \n#>  [51] \"srwt23\"  \"srwt24\"  \"srwt25\"  \"srwt26\"  \"srwt27\" \n#>  [56] \"srwt28\"  \"srwt29\"  \"srwt30\"  \"srwt31\"  \"srwt32\" \n#>  [61] \"srwt33\"  \"srwt34\"  \"srwt35\"  \"srwt36\"  \"srwt37\" \n#>  [66] \"srwt38\"  \"srwt39\"  \"srwt40\"  \"srwt41\"  \"srwt42\" \n#>  [71] \"srwt43\"  \"srwt44\"  \"srwt45\"  \"srwt46\"  \"srwt47\" \n#>  [76] \"srwt48\"  \"srwt49\"  \"srwt50\"  \"srwt51\"  \"srwt52\" \n#>  [81] \"srwt53\"  \"srwt54\"  \"srwt55\"  \"srwt56\"  \"srwt57\" \n#>  [86] \"srwt58\"  \"srwt59\"  \"srwt60\"  \"srwt61\"  \"srwt62\" \n#>  [91] \"smsrswt\" \"mrps11\"  \"mrps12\"  \"mrps13\"  \"mrps14\" \n#>  [96] \"mrps15\"  \"mrps21\"  \"mrps22\"  \"mrps23\"  \"mrps24\" \n#> [101] \"mrps25\"  \"mrps31\"  \"mrps32\"  \"mrps33\"  \"mrps34\" \n#> [106] \"mrps35\"  \"mrps41\"  \"mrps42\"  \"mrps43\"  \"mrps44\" \n#> [111] \"mrps45\"  \"mrps51\"  \"mrps52\"  \"mrps53\"  \"mrps54\" \n#> [116] \"mrps55\"  \"mrpcm1\"  \"mrpcm2\"  \"mrpcm3\"  \"mrpcm4\" \n#> [121] \"mrpcm5\"  \"m075201\" \"m075401\" \"m075601\" \"m019901\"\n#> [126] \"m066201\" \"m047301\" \"m046201\" \"m066401\" \"m020101\"\n#> [131] \"m067401\" \"m086101\" \"m047701\" \"m067301\" \"m048001\"\n#> [136] \"m093701\" \"m086001\" \"m051901\" \"m076001\" \"m046001\"\n#> [141] \"m046101\" \"m067701\" \"m046701\" \"m046901\" \"m047201\"\n#> [146] \"m046601\" \"m046801\" \"m067801\" \"m066601\" \"m067201\"\n#> [151] \"m068003\" \"m068005\" \"m068008\" \"m068007\" \"m068006\"\n#> [156] \"m093601\" \"m053001\" \"m047801\" \"m086301\" \"m085701\"\n#> [161] \"m085901\" \"m085601\" \"m085501\" \"m085801\" \"m019701\"\n#> [166] \"m020001\" \"m046301\" \"m047001\" \"m046501\" \"m066501\"\n#> [171] \"m047101\" \"m066301\" \"m067901\" \"m019601\" \"m051501\"\n#> [176] \"m047901\" \"m053101\" \"m143601\" \"m143701\" \"m143801\"\n#> [181] \"m143901\" \"m144001\" \"m144101\" \"m144201\" \"m144301\"\n#> [186] \"m144401\" \"m144501\" \"m144601\" \"m144701\" \"m144801\"\n#> [191] \"m144901\" \"m145001\" \"m145101\" \"m013431\" \"m0757cl\"\n#> [196] \"m013131\" \"m091701\" \"m072801\" \"m091501\" \"m091601\"\n#> [201] \"m073501\" \"m052401\" \"m075301\" \"m072901\" \"m013631\"\n#> [206] \"m075801\" \"m013731\" \"m013531\" \"m051801\" \"m093401\"\n#> [211] \"m093801\" \"m142001\" \"m142101\" \"m142201\" \"m142301\"\n#> [216] \"m142401\" \"m142501\" \"m142601\" \"m142701\" \"m142801\"\n#> [221] \"m142901\" \"m143001\" \"m143101\" \"m143201\" \"m143301\"\n#> [226] \"m143401\" \"m143501\" \"m105601\" \"m105801\" \"m105901\"\n#> [231] \"m106001\" \"m106101\" \"m106201\" \"m106301\" \"m106401\"\n#> [236] \"m106501\" \"m106601\" \"m106701\" \"m106801\" \"m106901\"\n#> [241] \"m107001\" \"m107101\" \"m107201\" \"m107401\" \"m107501\"\n#> [246] \"m107601\" \"m109801\" \"m110001\" \"m110101\" \"m110201\"\n#> [251] \"m110301\" \"m110401\" \"m110501\" \"m110601\" \"m110701\"\n#> [256] \"m110801\" \"m110901\" \"m111001\" \"m111201\" \"m111301\"\n#> [261] \"m111401\" \"m111501\" \"m111601\" \"m111801\" \"yrsexp\" \n#> [266] \"yrsmath\" \"t089401\" \"t088001\" \"t090801\" \"t090802\"\n#> [271] \"t090803\" \"t090804\" \"t090805\" \"t090806\" \"t087501\"\n#> [276] \"t088301\" \"t088401\" \"t088501\" \"t088602\" \"t088603\"\n#> [281] \"t088801\" \"t088803\" \"t088804\" \"t088805\" \"t091502\"\n#> [286] \"t091503\" \"t091504\" \"c052801\" \"c052802\" \"c052804\"\n#> [291] \"c052805\" \"c052806\" \"c052807\" \"c052808\" \"c052701\"\n#> [296] \"c046501\" \"c044006\" \"c044007\" \"c052901\" \"c053001\"\n#> [301] \"c053101\" \"sscrpsu\" \"c052601\"\nsearchSDF(string = \"book\", data = sdf, fileFormat = \"student\")\n#>   variableName                                       Labels\n#> 1      b013801                                Books in home\n#> 2      t088804 Computer activities: Use a gradebook program\n#> 3      t091503     G8Math:How often use Geometry sketchbook\n#>   fileFormat\n#> 1    Student\n#> 2    Student\n#> 3    Student\nsearchSDF(string = \"book\", data = sdf, fileFormat = \"student\", levels = TRUE)\n#> Variable: b013801\n#> Label: Books in home\n#> Levels (Lowest level first):\n#>      1. 0-10\n#>      2. 11-25\n#>      3. 26-100\n#>      4. >100\n#>      8. Omitted\n#>      0. Multiple\n#> Variable: t088804\n#> Label: Computer activities: Use a gradebook program\n#> Levels (Lowest level first):\n#>      1. Never or hardly ever\n#>      2. Once or twice/month\n#>      3. Once or twice a week\n#>      4. Almost every day\n#>      8. Omitted\n#>      0. Multiple\n#> Variable: t091503\n#> Label: G8Math:How often use Geometry sketchbook\n#> Levels (Lowest level first):\n#>      1. Never or hardly ever\n#>      2. Once or twice/month\n#>      3. Once or twice a week\n#>      4. Almost every day\n#>      8. Omitted\n#>      0. Multiple\nsearchSDF(string=\"book|home|value\", data=sdf)\n#>    variableName\n#> 1       b013801\n#> 2       b017001\n#> 3       b017101\n#> 4       b018201\n#> 5       b017451\n#> 6       m086101\n#> 7       m020001\n#> 8       m143601\n#> 9       m142301\n#> 10      t088804\n#> 11      t088805\n#> 12      t091503\n#>                                               Labels\n#> 1                                      Books in home\n#> 2                                  Newspaper in home\n#> 3                                   Computer at home\n#> 4         Language other than English spoken in home\n#> 5                         Talk about studies at home\n#> 6                              Read value from graph\n#> 7  Apply place value                            (R1)\n#> 8                       Solve for x given value of n\n#> 9                               Identify place value\n#> 10      Computer activities: Use a gradebook program\n#> 11  Computer activities: Post homework,schedule info\n#> 12          G8Math:How often use Geometry sketchbook\n#>    fileFormat\n#> 1     Student\n#> 2     Student\n#> 3     Student\n#> 4     Student\n#> 5     Student\n#> 6     Student\n#> 7     Student\n#> 8     Student\n#> 9     Student\n#> 10    Student\n#> 11    Student\n#> 12    Student\nsearchSDF(string=c(\"book\",\"home\"), data=sdf)\n#>   variableName        Labels fileFormat\n#> 1      b013801 Books in home    Student\nlevelsSDF(varnames = \"b017451\", data = sdf)\n#> Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever (n = 3837)\n#>     2. Once every few weeks (n = 3147)\n#>     3. About once a week (n = 2853)\n#>     4. 2 or 3 times a week (n = 3362)\n#>     5. Every day (n = 3132)\n#>     8. Omitted* (n = 575)\n#>     0. Multiple* (n = 9)\n#>     NOTE: * indicates an omitted level.\nView(showCodebook(data = sdf))\nshowPlausibleValues(data = sdf, verbose = TRUE)\n#> There are 6 subject scale(s) or subscale(s) in this\n#>   edsurvey.data.frame:\n#> 'num_oper' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps11',\n#>   'mrps12', 'mrps13', 'mrps14', and 'mrps15'\n#> \n#> 'measurement' subject scale or subscale with 5\n#>   plausible values.\n#>   The plausible value variables are: 'mrps21',\n#>   'mrps22', 'mrps23', 'mrps24', and 'mrps25'\n#> \n#> 'geometry' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps31',\n#>   'mrps32', 'mrps33', 'mrps34', and 'mrps35'\n#> \n#> 'data_anal_prob' subject scale or subscale with 5\n#>   plausible values.\n#>   The plausible value variables are: 'mrps41',\n#>   'mrps42', 'mrps43', 'mrps44', and 'mrps45'\n#> \n#> 'algebra' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps51',\n#>   'mrps52', 'mrps53', 'mrps54', and 'mrps55'\n#> \n#> 'composite' subject scale or subscale with 5\n#>   plausible values (the default).\n#>   The plausible value variables are: 'mrpcm1',\n#>   'mrpcm2', 'mrpcm3', 'mrpcm4', and 'mrpcm5'\nshowWeights(data = sdf, verbose = TRUE)\n#> There is 1 full sample weight in this\n#>   edsurvey.data.frame:\n#>   'origwt' with 62 JK replicate weights (the\n#>   default).\n#>     Jackknife replicate weight variables associated\n#>     with the full sample weight 'origwt':\n#>     'srwt01', 'srwt02', 'srwt03', 'srwt04', 'srwt05',\n#>     'srwt06', 'srwt07', 'srwt08', 'srwt09', 'srwt10',\n#>     'srwt11', 'srwt12', 'srwt13', 'srwt14', 'srwt15',\n#>     'srwt16', 'srwt17', 'srwt18', 'srwt19', 'srwt20',\n#>     'srwt21', 'srwt22', 'srwt23', 'srwt24', 'srwt25',\n#>     'srwt26', 'srwt27', 'srwt28', 'srwt29', 'srwt30',\n#>     'srwt31', 'srwt32', 'srwt33', 'srwt34', 'srwt35',\n#>     'srwt36', 'srwt37', 'srwt38', 'srwt39', 'srwt40',\n#>     'srwt41', 'srwt42', 'srwt43', 'srwt44', 'srwt45',\n#>     'srwt46', 'srwt47', 'srwt48', 'srwt49', 'srwt50',\n#>     'srwt51', 'srwt52', 'srwt53', 'srwt54', 'srwt55',\n#>     'srwt56', 'srwt57', 'srwt58', 'srwt59', 'srwt60',\n#>     'srwt61', and 'srwt62'\nEdSurvey:::getStratumVar(data = sdf)\n#>   stratum \n#> \"repgrp1\"\nEdSurvey:::getPSUVar(data = sdf)\n#>      psu \n#> \"jkunit\""},{"path":"philosophyOfAnalysis.html","id":"explore-data","chapter":"3 Philosophy of Analysis","heading":"3.4 Explore Data","text":"","code":""},{"path":"philosophyOfAnalysis.html","id":"subsettingData","chapter":"3 Philosophy of Analysis","heading":"3.4.1 Subsetting the Data","text":"subset dataset can used EdSurvey package functions. example, summary table created edsurveyTable filtering sample include students whose value dsex variable male race (variable sdracem) either values 1 3 (White Hispanic). value levels labels can used EdSurvey package functions.Table 3.1. Summary Table Subset ","code":"\nsdfm <- subset(x = sdf, subset = dsex == \"Male\" & (sdracem == 3 | sdracem == 1))\nes2 <- edsurveyTable(formula = composite ~ dsex + sdracem, data = sdfm)\nes2"},{"path":"philosophyOfAnalysis.html","id":"explore-variable-distributions-with-summary2","chapter":"3 Philosophy of Analysis","heading":"3.4.2 Explore Variable Distributions With summary2","text":"summary2 function produces weighted unweighted descriptive statistics variable. functionality quite useful gathering response information survey variables conducting data exploration. NAEP data datasets default weight variable, summary2 produces weighted statistics default. specified variable set plausible values, weightVar option non-NULL, summary2 statistics account plausible values pooling weighting.specifying weightVar = NULL, function prints unweighted descriptive statistics selected variable plausible values:categorical variable, summary2 function returns weighted number cases, weighted percent, weighted standard error. example, variable b017451 (frequency students talking \nstudies home) returns following output:Note default, summary2 function includes omitted levels; remove , set dropOmittedLevels = TRUE:","code":"\nsummary2(data = sdf, variable = \"composite\")\n#> Estimates are weighted using the weight variable 'origwt'\n#>    Variable     N Weighted N   Min.  1st Qu.   Median\n#> 1 composite 16915   16932.46 126.11 251.9626 277.4784\n#>       Mean  3rd Qu.    Max.      SD NA's Zero weights\n#> 1 275.8892 301.1827 404.184 36.5713    0            0\nsummary2(data = sdf, variable = \"composite\", weightVar = NULL)\n#> Estimates are not weighted.\n#>   Variable     N   Min.  1st Qu. Median     Mean  3rd Qu.\n#> 1   mrpcm1 16915 130.53 252.0600 277.33 275.8606 300.7200\n#> 2   mrpcm2 16915 124.16 252.2100 277.33 275.6399 300.6900\n#> 3   mrpcm3 16915 115.09 252.0017 277.19 275.6570 300.5600\n#> 4   mrpcm4 16915 137.19 252.4717 277.44 275.7451 300.5767\n#> 5   mrpcm5 16915 123.58 252.4900 277.16 275.6965 300.5000\n#>     Max.       SD NA's\n#> 1 410.80 35.89864    0\n#> 2 408.58 36.08483    0\n#> 3 398.17 36.09278    0\n#> 4 407.41 35.91078    0\n#> 5 395.96 36.10905    0\nsummary2(data = sdf, variable = \"b017451\")\n#> Estimates are weighted using the weight variable 'origwt'\n#>                b017451    N Weighted N Weighted Percent\n#> 1 Never or hardly ever 3837  3952.4529      23.34245648\n#> 2 Once every few weeks 3147  3190.8945      18.84483329\n#> 3    About once a week 2853  2937.7148      17.34960077\n#> 4  2 or 3 times a week 3362  3425.8950      20.23270282\n#> 5            Every day 3132  3223.8074      19.03921080\n#> 6              Omitted  575   194.3312       1.14768416\n#> 7             Multiple    9     7.3676       0.04351168\n#>   Weighted Percent SE\n#> 1           0.4318975\n#> 2           0.3740648\n#> 3           0.3414566\n#> 4           0.3156289\n#> 5           0.4442216\n#> 6           0.1272462\n#> 7           0.0191187\nsummary2(data = sdf, variable = \"b017451\", dropOmittedLevels = TRUE)\n#> Estimates are weighted using the weight variable 'origwt'\n#>                b017451    N Weighted N Weighted Percent\n#> 1 Never or hardly ever 3837   3952.453         23.62386\n#> 2 Once every few weeks 3147   3190.894         19.07202\n#> 3    About once a week 2853   2937.715         17.55876\n#> 4  2 or 3 times a week 3362   3425.895         20.47662\n#> 5            Every day 3132   3223.807         19.26874\n#>   Weighted Percent SE\n#> 1           0.4367548\n#> 2           0.3749868\n#> 3           0.3486008\n#> 4           0.3196719\n#> 5           0.4467063"},{"path":"philosophyOfAnalysis.html","id":"read-in-for-analysis-in-edsurvey","chapter":"3 Philosophy of Analysis","heading":"3.5 Read in for Analysis in EdSurvey","text":"","code":""},{"path":"philosophyOfAnalysis.html","id":"retrieving-data-for-further-manipulation-with-getdata","chapter":"3 Philosophy of Analysis","heading":"3.5.1 Retrieving Data for Further Manipulation With getData","text":"Users can extract manipulate data using function getData. function takes edsurvey.data.frame returns light.edsurvey.data.frame containing requested variables either specifying set variable names varnames entering formula formula.3To access manipulate data dsex b017451 variables sdf, call getData. following code, head function reveals first rows resulting data:default, setting dropOmittedLevels TRUE removes special values multiple entries NAs. getData tries help dropping levels factors regression, tables, correlations typically included analysis.","code":"\ngddat <- getData(data = sdf, varnames = c(\"dsex\",\"b017451\"),\n                 dropOmittedLevels = TRUE)\nhead(gddat)\n#>     dsex              b017451\n#> 1   Male            Every day\n#> 2 Female    About once a week\n#> 3 Female            Every day\n#> 4   Male            Every day\n#> 6 Female Once every few weeks\n#> 7   Male  2 or 3 times a week"},{"path":"philosophyOfAnalysis.html","id":"retrieving-all-variables-in-a-dataset","chapter":"3 Philosophy of Analysis","heading":"3.5.2 Retrieving All Variables in a Dataset","text":"extract data edsurvey.data.frame, define varnames argument colnames(x = sdf), query variables. Setting arguments dropOmittedLevels defaultConditions FALSE ensures values normally removed included:retrieved, dataset can used EdSurvey functions.","code":"\nlsdf0 <- getData(data = sdf, varnames = colnames(sdf), addAttributes = TRUE,\n                 dropOmittedLevels = FALSE, defaultConditions = FALSE)\ndim(x = lsdf0) # excludes the one school variable in the sdf\ndim(x = sdf)"},{"path":"philosophyOfAnalysis.html","id":"read-in-for-analysis-outside-edsurvey","chapter":"3 Philosophy of Analysis","heading":"3.6 Read in for Analysis Outside EdSurvey","text":"","code":""},{"path":"philosophyOfAnalysis.html","id":"applying-rebindattributes-to-use-edsurvey-functions-with-manipulated-data-frames","chapter":"3 Philosophy of Analysis","heading":"3.6.1 Applying rebindAttributes to Use EdSurvey Functions With Manipulated Data Frames","text":"helper function pairs well getData rebindAttributes. function allows users reassign attributes survey dataset data frame might attributes stripped manipulation process. rebinding attributes, variables—including outside original dataset—available use EdSurvey analytical functions.example, user might want run linear model using composite, default weight origwt, variable dsex, categorical variable b017451 recoded binary variable. , can return portion sdf survey data gddat object. Next, use base R function ifelse conditionally recode variable b017451 collapsing levels \"Never hardly ever\" \"every weeks\" one level (\"Rarely\") levels \"least week\"., apply rebindAttributes attribute data sdf manipulated data frame gddat. new variables now available use EdSurvey analytical functions:","code":"\ngddat <- getData(data = sdf, varnames = c(\"dsex\", \"b017451\", \"origwt\", \"composite\"),\n                 dropOmittedLevels = TRUE)\ngddat$studyTalk <- ifelse(gddat$b017451 %in% c(\"Never or hardly ever\",\n                                               \"Once every few weeks\"),\n                          \"Rarely\", \"At least once a week\")\ngddat <- rebindAttributes(data = gddat, attributeData = sdf)\nlm2 <- lm.sdf(formula = composite ~ dsex + studyTalk, data = gddat)\nsummary(object = lm2)\n#> \n#> Formula: composite ~ dsex + studyTalk\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17606\n#> n used: 16331\n#> \n#> Coefficients:\n#>                      coef        se        t    dof\n#> (Intercept)     281.69030   0.96690 291.3349 39.915\n#> dsexFemale       -2.89797   0.59549  -4.8665 52.433\n#> studyTalkRarely  -9.41418   0.79620 -11.8239 53.205\n#>                  Pr(>|t|)    \n#> (Intercept)     < 2.2e-16 ***\n#> dsexFemale      1.081e-05 ***\n#> studyTalkRarely < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0168"},{"path":"dataAccess.html","id":"dataAccess","chapter":"4 Data Access","heading":"4 Data Access","text":"Last edited: July 2023Suggested Citation\nFink, T. Data Access. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.obtain read different types assessment data, section chapter shows information licensing, downloading, simple examples. processing NCES datasets EdSurvey, review available study documentation familiarize unique study.good practice keep source data structured folder scheme. EdSurvey recommend one root data folder, subfolders study, year/group folders within study subfolder. example, C:/EdSurveyData root folder. C:/EdSurveyData/TIMSS TIMSS study folder. Lastly, year TIMSS data another subfolder C:/EdSurveyData/TIMSS/2015. structure helps organize data method used download functions.","code":""},{"path":"dataAccess.html","id":"naep-national-assessment-of-educational-progress","chapter":"4 Data Access","heading":"4.1 NAEP: National Assessment of Educational Progress","text":"NAEP measure used study U.S. student achievement urban districts, states, nation many subjects, including reading, mathematics, science, writing, subjects Grades 4, 8, 12. assessments sponsored NCES within U.S. Department Education Institute Education Sciences (IES). study information can found NAEP Webpage. NAEP datasets restricted-use files NCES; however, publicly available sample dataset called NAEP Primer can accessed R package NAEPprimer.NAEP study files primarily used analyze student performance usually include school-level data, automatically handled readNAEP function. Additional arguments readNAEP include defaultWeight, defaultPvs, dropOmittedLevels, frPath. arguments modified default values rare situations. Consult readNAEP function documentation details use.beginning analyze NAEP data, sure read provided user guide documentation provided NCES familiarize study apply guidance analysis.readNAEP function called, locates specified ASCII fixed-width data file (.dat) supplied path argument. readNAEP function scans data files (.dat) associated layout file (.fr2) located Select/Parms folder contains information needed parsing data file. Lastly, readNAEP function scans folder associated school-level data file. main student-level files naming scheme xxxxTxxx.dat, whereas school-level files naming scheme xxxxCxxx.dat. data read fly, EdSurvey stores file connection information, associated meta-data without load entire dataset memory.","code":""},{"path":"dataAccess.html","id":"reading-naep-data","chapter":"4 Data Access","heading":"4.1.1 Reading NAEP Data","text":"","code":"\n#reading in the NAEP Primer data using the package NAEPprimer\nnaep.1 <- readNAEP(path = system.file(\"extdata/data\", \"M36NT2PM.dat\", package = \"NAEPprimer\"))\n\n#pointing to a NAEP restricted-use file directly by path\nnaep.2 <- readNAEP(path = \"C:/RUD_DATA/NAEP/M36NT2PM.dat\")"},{"path":"dataAccess.html","id":"ECLS-data","chapter":"4 Data Access","heading":"4.2 ECLS: Early Childhood Longitudinal Study","text":"ECLS includes three U.S. longitudinal studies. Two public-use datasets feature students beginning kindergarten level known ECLS-K studies. first began sample kindergarten students beginning 1998 followed grade 8 (.e., ECLS-K). second study group kindergarten students beginning 2011 grade 5 (.e., ECLS-K:2011). final ECLS study known ECLS-B followed children ages 9 months preschool level. ECLS-B restricted-use dataset . three studies sponsored NCES. study information can found NCES ECLS Study webpage.beginning analyze ECLS data, sure read published user guides documentation provided NCES familiarize study apply guidance analysis. advised large number weight variables, care must used select appropriate weight analysis.readECLS_K1998, readECLS_K2011, readECLS_B call first used read data, process data prepare EdSurvey first read call. step take significant time, large size data files. preparation involves parsing SPSS (.sps) script file gather relevant data variable information outputting fixed-width data (.txt) file suitable use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.downloadECLS function downloads extracts ECLS data NCES Online Codebook ECLS-K 1998 study. ECLS-K 2011 study, files downloaded NCES ECLS Study Data Products webpage. ECLS-B study, files restricted-use must obtained IES restricted-use data license. Additional specifics files required detailed within specific section study.","code":""},{"path":"dataAccess.html","id":"ecls-k","chapter":"4 Data Access","heading":"4.2.1 ECLS-K","text":"ECLS-K study mainly comprises public-use study data student/child level. also files school data, teacher data gathered throughout study. student, school, teacher data analyzed separately; data joined/merged together.downloadECLS function downloads ECLS-K data NCES Online Codebook. format required readECLS_K1998 function fixed-width data file (.dat), along NCES formatted text layout file (.txt) includes relevant details data file.","code":""},{"path":"dataAccess.html","id":"obtaining-ecls-k-data","chapter":"4 Data Access","heading":"4.2.1.1 Obtaining ECLS-K Data","text":"","code":"\n#download ECLS-K data to the root folder\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 1998)\n\n#if cache = TRUE, it will perform the data caching step now \n#instead of the first readECLS_K2011 call\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 1998, cache = TRUE)\n\n#for no console (silent) output, you can set verbose = FALSE\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 1998, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-ecls-k-data","chapter":"4 Data Access","heading":"4.2.1.2 Reading ECLS-K Data","text":"","code":"\n#read in the student/child data file, specifying the files directly\neclsk98.1 <- readECLS_K1998(path = \"C:/EdSurveyData/ECLS_K/1998\",\n                            filename = \"eclsk_98_99_k8_child_v1_0.dat\",\n                            layoutFilename = \"Layout_k8_child.txt\")\n\n#by default, the filename is specified as 'eclsk_98_99_k8_child_v1_0.dat',\n#and the default layoutFilename as 'Layout_k8_child.txt',\n#so you can omit the filename and layoutFilename argument when using default filenames.\neclsk98.2 <- readECLS_K1998(path = \"C:/EdSurveyData/ECLS_K/1998\")\n\n#read in the teacher data file, specifying the filename and its associated layout file\neclsk98.3 <- readECLS_K1998(path = \"C:/EdSurveyData/ECLS_K/1998\",\n                            filename = \"ECLSK_98_99_K8_TCH_v1_0.dat\",\n                            layoutFilename = \"Layout_k8_tch.txt\")\n\n#setting verbose = FALSE stops console message output (silent) of the function.\neclsk98.4 <- readECLS_K1998(path = \"C:/EdSurveyData/ECLS_K/1998\", verbose = FALSE)"},{"path":"dataAccess.html","id":"ecls-k2011","chapter":"4 Data Access","heading":"4.2.2 ECLS-K:2011","text":"ECLS-K:2011 study mainly comprises public-use study data student/child level. additional data files school teacher levels.downloadECLS function downloads ECLS-K:2011 data NCES ECLS Study Data Products webpage. format required readECLS_K2011 function fixed-width data file (.dat), along SPSS script syntax file (.sps), includes relevant details fixed-width data file. NCES formatted data layout file currently available ECLS-K 2011, users use SPSS script syntax file.","code":""},{"path":"dataAccess.html","id":"obtaining-ecls-k2011-data","chapter":"4 Data Access","heading":"4.2.2.1 Obtaining ECLS-K:2011 Data","text":"","code":"\n#download ECLS-K 2011 data to the root folder\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 2011)\n\n#if cache = TRUE, it will perform the data caching step now \n#instead of the first readECLS_K2011 call\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 2011, cache = TRUE)\n\n#for no console (silent) output, you can set verbose = FALSE\ndownloadECLS_K(root = \"C:/EdSurveyData\", years = 2011, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-ecls-k2011-data","chapter":"4 Data Access","heading":"4.2.2.2 Reading ECLS-K:2011 Data","text":"","code":"\n#read in the student/child data, file specifying the files directly\neclsk11.1 <- readECLS_K2011(path = \"C:/EdSurveyData/ECLS_K/2011\",\n                            filename = \"childK5p.dat\",\n                            layoutFilename = \"ECLSK2011_K5PUF.sps\")\n\n#by default, the filename is specified as 'childK5p.dat',\n#and the default layoutFilename as 'ECLSK2011_K5PUF.sps',\n#so you can omit the filename and layoutFilename argument when using default filenames\neclsk11.2 <- readECLS_K2011(path = \"C:/EdSurveyData/ECLS_K/2011\")\n\n#setting verbose = FALSE stops console message output (silent) of the function\neclsk11.3 <- readECLS_K2011(path = \"C:/EdSurveyData/ECLS_K/2011\", verbose = FALSE)"},{"path":"dataAccess.html","id":"ecls-b","chapter":"4 Data Access","heading":"4.2.3 ECLS-B","text":"ECLS-B study comprises restricted-use study data child level. format required readECLS_B function fixed-width data file (.dat), along SPSS script syntax file (.sps), includes relevant details fixed-width data file. SPSS script syntax (.sps) file must generated using ECLS-B supplied electronic codebook (ECB) program included ECLS-B restricted-use data. Using ECB program can select variables generate SPSS script (.sps) syntax file tool.","code":""},{"path":"dataAccess.html","id":"reading-ecls_b-data","chapter":"4 Data Access","heading":"4.2.3.1 Reading ECLS_B Data","text":"","code":"\n#read in the ECLS-B data\neclsb.1 <- readECLS_B(path = \"C:/RUD_DATA/ECLS_B\",\n                      filename = \"ChildK07.dat\",\n                      layoutFilename = \"eclsb.sps\")"},{"path":"dataAccess.html","id":"els-education-longitudinal-study-of-2002","chapter":"4 Data Access","heading":"4.3 ELS: Education Longitudinal Study of 2002","text":"ELS:2002 study U.S. longitudinal study designed follow high school sophomores (Grade 10) fall 2002 school year follow-ups every 2 years high school college/adult paths. Follow-ups conducted 2004, 2006, 2012. NCES sponsored study. study information can found NCES ELS Study webpage.beginning analyze ELS data, sure read published user guides documentation provided NCES familiarize study apply guidance analysis. advised large number weight variables, care must used select appropriate weight analysis.data ELS comprises two large student-level files (one student data file plus one file weight replicates), contain available variables across data collections, well three school-level data files different study periods. student school data files merged joined analysis.readELS call first used read data, perform process data prepare EdSurvey first read call. step take significant time, large size data files. preparation involves parsing SPSS (.sav) files gather relevant data variable information, outputting fixed-width (.txt) data file suitable use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.downloadELS function downloads extracts ELS data NCES Online Codebook SPSS data file format specified root folder.","code":""},{"path":"dataAccess.html","id":"obtaining-els-data","chapter":"4 Data Access","heading":"4.3.1 Obtaining ELS Data","text":"","code":"\n#download ELS:2002 data to the root folder\ndownloadELS(root = \"C:/EdSurveyData\", years = 2002)\n\n#if cache = TRUE, it will perform the data caching step now\n#instead of the first readELS call\ndownloadELS(root = \"C:/EdSurveyData\", years = 2002, cache = TRUE)\n\n#for no console (silent) output, you can set verbose = FALSE\ndownloadELS(root = \"C:/EdSurveyData\", years = 2002, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-els-data","chapter":"4 Data Access","heading":"4.3.2 Reading ELS Data","text":"","code":"\n#reading in the ELS student data file\nels.1 <- readELS(path = \"C:/EdSurveyData/ELS/2002\",\n                 filename = \"els_02_12_byf3pststu_v1_0.sav\",\n                 wgtFilename = \"els_02_12_byf3stubrr_v1_0.sav\")\n\n#by default the filename is specified as 'els_02_12_byf3pststu_v1_0.sav',\n#and the default wgtFilename as 'els_02_12_byf3stubrr_v1_0.sav,'\n#so you can omit the filename and wgtFilename argument when using default filenames\nels.2 <- readELS(path = \"C:/EdSurveyData/ELS/2002\")\n\n#to read in a school data file\n#wgtFilename can either be omitted or set to 'NA' value as it's not applicable\nels.3 <- readELS(path = \"C:/EdSurveyData/ELS/2002\",\n                 filename = \"els_02_12_byf1sch_v1_0.sav\",\n                 wgtFilename = NA)\n\n#setting verbose = FALSE stops console message output (silent) of the function.\nels.4 <- readELS(path = \"C:/EdSurveyData/ELS/2002\", verbose = FALSE)"},{"path":"dataAccess.html","id":"hsls-high-school-longitudinal-study-of-2009","chapter":"4 Data Access","heading":"4.4 HSLS: High School Longitudinal Study of 2009","text":"HSLS:09 study U.S. longitudinal study designed follow high school freshman (Grade 9) fall 2009 school year high school adult roles. study four additional follow-data collections. first follow-occurred 2012 students high school juniors (Grade 11). next collection done 2013 students high school seniors (Grade 12). Another collection completed 3 years high school graduation 2016. final collection 2017, 4 years high school graduation, data yet released. NCES sponsored study. study information found NCES HSLS Study webpage.beginning analyze HSLS data, sure read published user guides documentation provided NCES familiarize study apply guidance analysis. advised large number weight variables HSLS, care must used select appropriate weight analysis.data HSLS comprises one large student-level file, contains available variables across data collections, well school-level data file. student school data files meant merged, joined, analysis.readHSLS call first used read data, process data prepare EdSurvey package first read call. step take significant time, large size HSLS data files. preparation involves parsing SPSS (.sav) files gather relevant data variable information outputting fixed-width (.txt) data file suitable use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.downloadHSLS function downloads extracts HSLS data NCES Online Codebook SPSS data file format specified root folder.","code":""},{"path":"dataAccess.html","id":"obtaining-hsls-data","chapter":"4 Data Access","heading":"4.4.1 Obtaining HSLS Data","text":"","code":"\n#download HSLS:09 data to the root folder\ndownloadHSLS(root = \"C:/EdSurveyData\", years = 2009)\n\n#if cache = TRUE, it will perform the data caching step now\n#instead of the first readHSLS call\ndownloadHSLS(root = \"C:/EdSurveyData\", years = 2009, cache = TRUE)\n\n#for no console (silent) output, you can set verbose = FALSE\ndownloadHSLS(root = \"C:/EdSurveyData\", years = 2009, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-hsls-data","chapter":"4 Data Access","heading":"4.4.2 Reading HSLS Data","text":"","code":"\n#reading in the HSLS student data file\nhsls.1 <- readHSLS(path = \"C:/EdSurveyData/HSLS/2009\", \n                   filename = \"hsls_16_student_v1_0.sav\")\n\n#by default the filename is specified as 'hsls_16_student_v1_0.sav', \n#so you can omit the filename argument.\nhsls.2 <- readHSLS(path = \"C:/EdSurveyData/HSLS/2009\")\n\n#to read in the school data file\nhsls.3 <- readHSLS(path = \"C:/EdSurveyData/HSLS/2009\", \n                   filename = \"hsls_09_school_v1_0.sav\")\n\n#in rare instances (such as using restricted-use data),\n#you also may need to specify a `weight` file \n#that contains the study replicate weight variables\nhsls.4 <- readHSLS(path = \"C:/EdSurveyData/HSLS/2009\", \n                   filename = \"student.sav\", \n                   wgtFilename = \"student_weight.sav\")\n\n#setting verbose = FALSE stops console message output (silent) of the function.\nhsls.5 <- readHSLS(path = \"C:/EdSurveyData/HSLS/2009\", verbose = FALSE)"},{"path":"dataAccess.html","id":"iccs-and-cived-international-civic-and-citizen-education-study-and-civic-education-study-1999","chapter":"4 Data Access","heading":"4.5 ICCS and CivED: International Civic and Citizen Education Study and Civic Education Study 1999","text":"ICCS CivED combined set data functions, involve civic education. CivED study conducted 1999 IEA (International Association Evaluation Educational Achievement) Humboldt University Berlin. CivED study comprised primarily Grade 8 students also Grade 12 student component. Grade 8 dataset included school teacher information, well ability link student data teacher school level data. Grade 12 data student-level information .ICCS study first implemented 2009 follow-cycle 2016 one progress 2022. EdSurvey currently supports read-analysis 2009 2016 data. ICCS study coordinated many partners, including, IEA (International Association Evaluation Educational Achievement), ACER (Australian Council Educational Research), LPS (Laboratorio di Pedagogia Sperimentale) Roma Tre University, many national centers. ICCS study target population students primarily Grade 8, along data students Grade 9. Also available school- teacher-level data. Unlike IEA datasets, ICCS study link student-level data teacher-level data, user must specify dataSet wish analyze readCivEDICCS function argument.beginning analyze CivED/ICCS data, sure read published user guides documentation provided IEA familiarize study apply guidance analysis. user guide identifies International Organization Standardization (ISO) three-digit country codes used arguments readCivEDICCS function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia.readCivEDICCS call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer. preparation involves parsing SPSS files (.sav) gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.downloadCivEDICCS function provides user instructions downloading datasets IEA Data Repository CivED ICCS studies.readCivEDICCS function supports datasets study data, although care must taken correctly specify correct parameters.","code":""},{"path":"dataAccess.html","id":"obtaining-cived-data","chapter":"4 Data Access","heading":"4.5.1 Obtaining CivED Data","text":"","code":"\n#View instructions for obtaining the CivED Study files from the IEA Data Repository\ndownloadCivEDICCS(years = 1999)"},{"path":"dataAccess.html","id":"obtaining-iccs-data","chapter":"4 Data Access","heading":"4.5.2 Obtaining ICCS Data","text":"","code":"\n#View instructions for obtaining the ICCS Study files from the IEA Data Repository\ndownloadCivEDICCS(years = 2009)"},{"path":"dataAccess.html","id":"reading-cived-data","chapter":"4 Data Access","heading":"4.5.3 Reading CivED Data","text":"","code":"\n#reading in a single country for a single year for 8th-grade student data\n#having dataSet = \"student\", includes School-, Student-, and Teacher-level \n#information (because they can be merged).\n#returns a single edsurvey.data.frame\ncived.1 <- readCivEDICCS(path = \"C:/EdSurveyData/CivED/1999\",\n                         countries = \"deu\",\n                         dataSet = \"student\",\n                         gradeLvl = 8)\n\n#reading in multiple countries for a single year for 8th-grade student data\n#returns an edsurvey.data.frame.list\ncived.2 <- readCivEDICCS(path = \"C:/EdSurveyData/CivED/1999\",\n                         countries = c(\"deu\", \"cze\"),\n                         dataSet = \"student\",\n                         gradeLvl = 8)\n\n#use the wildcard to search for all available countries in the path\n#specifying the dataSet= \"teacher\", includes the Teacher and School levels only \n#(because they can be merged)\ncived.3 <- readCivEDICCS(path = \"C:/EdSurveyData/CivED/1999\",\n                         countries = \"*\",\n                         dataSet = \"teacher\",\n                         gradeLvl = 8)\n\n#for CivED there is a grade 12 dataset with only student-level data\n#returns an edsurvey.data.frame.list\ncived.4 <- readCivEDICCS(path = \"C:/EdSurveyData/CivED/1999\",\n                         countries = c(\"cze\", \"est\"),\n                         dataSet = \"student\",\n                         gradeLvl = 12)"},{"path":"dataAccess.html","id":"reading-iccs-data","chapter":"4 Data Access","heading":"4.5.4 Reading ICCS Data","text":"","code":"\n#reading in a single country for a single year for 8th-grade student data\n#having dataSet = \"student\", includes School- and Student-level data\n#(they can be merged together).\n#returns a single edsurvey.data.frame\niccs.1 <- readCivEDICCS(path = \"C:/EdSurveyData/ICCS/2009\",\n                        countries = \"kor\",\n                        dataSet = \"student\",\n                        gradeLvl = 8)\n\n#reading in a single country for a single year for 8th-grade teacher data\n#having dataSet = \"teacher\", includes School- and Teacher-level data\n#(they can be merged together).\n#returns a single edsurvey.data.frame\niccs.2 <- readCivEDICCS(path = \"C:/EdSurveyData/ICCS/2009\",\n                        countries = \"kor\",\n                        dataSet = \"teacher\",\n                        gradeLvl = 8)\n\n#use the wildcard to search for all available countries in the path. \n#you must still specify the dataSet and gradeLvl arguments\n#for the correct dataset to analyze\niccs.3 <- readCivEDICCS(path = \"C:/EdSurveyData/ICCS/2009\",\n                        countries = \"*\",\n                        dataSet = \"student\",\n                        gradeLvl = 8)\n\n#for ICCS there is a grade 9 dataset with only student-level data\n#returns an edsurvey.data.frame.list\niccs.4 <- readCivEDICCS(path = \"C:/EdSurveyData/ICCS/2009\",\n                        countries = c(\"swe\", \"nor\"),\n                        dataSet = \"student\",\n                        gradeLvl = 9)"},{"path":"dataAccess.html","id":"icils-international-computer-and-information-literacy-study","chapter":"4 Data Access","heading":"4.6 ICILS: International Computer and Information Literacy Study","text":"ICILS study global study focuses target populations Grade 8 students help understand aspects computer use information literacy. study two cycles public-use datasets 2013 2018. study partners IEA (International Association Evaluation Educational Achievement) ACER (Australian Council Educational Research). addition student-level data, data collected school teacher levels. Student-level data directly joined teacher-level data part study design.downloadICILS function provides instructions obtaining ICILS data IEA Data Repository. readICILS function supports SPSS (.sav) data file format.beginning analyze ICILS data, sure read published user guides documentation provided IEA/ACER familiarize study apply guidance analysis. user guide also identifies ISO three-digit country codes used arguments readICILS function read specific countries. three-digit ISO country codes can found using various online resources, including Wikipedia.readICILS call first used read data, process data prepare EdSurvey. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS (.sav) files gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.edsurvey.data.frame ICILS data handle necessary merging/linking school data student- teacher-level data behind scenes user. dataSet argument must specified either student teacher indicate set data wish analyze. student teacher datasets can merged school level data, available user automatically.","code":""},{"path":"dataAccess.html","id":"obtaining-icils-data","chapter":"4 Data Access","heading":"4.6.1 Obtaining ICILS Data","text":"","code":"\n#the downloadICILS function will display instructions for\n#downloading the ICILS data from the IEA Data Repository\ndownloadICILS(years = 2013)"},{"path":"dataAccess.html","id":"reading-icils-data","chapter":"4 Data Access","heading":"4.6.2 Reading ICILS Data","text":"","code":"\n#reading in a single country for ICILS 2013 student data\n#returns a single edsurvey.data.frame\nicils.1 <- readICILS(path = \"C:/EdSurveyData/ICILS/2013\",\n                     countries = \"chl\",\n                     dataSet = \"student\")\n\n#reading in multiple countries for a single year for teacher level data\n#returns an edsurvey.data.frame.list\nicils.2 <- readICILS(path = \"C:/EdSurveyData/ICILS/2013\",\n                     countries = c(\"pol\", \"svk\", \"svn\"),\n                     dataSet = \"teacher\")\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list of all found countries\nicils.3 <- readICILS(path = \"C:/EdSurveyData/ICILS/2013\",\n                     countries = \"*\",\n                     dataSet = \"student\")\n\n#specify multiple paths if wishing to read in multiple years.\n#returns an edsurvey.data.frame.list\nicils.4 <- readICILS(path = c(\"C:/EdSurveyData/ICILS/2013\", \n                              \"C:/EdSurveyData/ICILS/2018\"), \n                     countries = c(\"deu\", \"dnk\"),\n                     dataSet = \"student\")"},{"path":"dataAccess.html","id":"timss-trends-in-international-mathematics-and-science-study","chapter":"4 Data Access","heading":"4.7 TIMSS: Trends in International Mathematics and Science Study","text":"TIMSS global study focusing target populations Grade 4 Grade 8 students. study began 1995 release cycles every 4 years comprising public-use datasets 1995, 1999, 2003, 2007, 2011, 2015, 2019 released conjunction Boston College Lynch School Education IEA. addition student assessment data, database includes student, teacher, school, curricular background data grades.downloadTIMSS function downloads unzips data hosted Boston College TIMSS PIRLS Database following years: 2003, 2007, 2011, 2015, 2019. data also can found manually downloaded IEA Data Repository. required data format used readTIMSS function SPSS (.sav) file format version. Use IEA Data Repository wish obtain analyze 1995 1999 data Boston College TIMSS Database provide SPSS (.sav) files study years.beginning analyze TIMSS data, sure read studies published user guides documentation provided Boston College IEA familiarize study apply guidance analysis. user guide identifies ISO three-digit country codes used arguments readTIMSS function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. TIMSS data include jurisdictions subgroups countries, published TIMSS documentation include specific codes needed wish analyze well. readTIMSS function also supports wildcard character * countries parameter, scan specified path directories available countries.readTIMSS call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS (.sav) files gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.edsurvey.data.frame TIMSS data handle necessary merging/linking school- teacher-level data behind scenes user, based variables requested function. Grade 8 data files, teacher surveys math science component. variable names duplicated modified indicate math science adding .math .sci end variable name. example btbg05e variable common math science teacher questionnaire. variable renamed within EdSurvey btbg05e.math btbg05e.sci indicate teacher questionnaire type aid users analysis.2015, countries less-developed education systems opportunity participate TIMSS Numeracy, included items lower difficulty. TIMSS Numeracy data automatically included readTIMSS 2015 data, gradeLvl = 4 specified.","code":""},{"path":"dataAccess.html","id":"obtaining-timss-data","chapter":"4 Data Access","heading":"4.7.1 Obtaining TIMSS Data","text":"","code":"\n#obtain the data to analyze for both 2011 and 2015 study years\ndownloadTIMSS(root = \"C:/EdSurveyData\", years = c(2011, 2015), cache = FALSE, verbose = TRUE)\n\n#if you wish to prepare to analyze all countries to have them ready for analysis,\n#set the cache argument to TRUE (cache = TRUE).  Be prepared that this may take some time.\n#setting the verbose argument to TRUE will keep you informed of the progress in the console\ndownloadTIMSS(root = \"C:/EdSurveyData\", years = c(2011, 2015), cache = TRUE, verbose = TRUE)\n\n#for silent output with no message output set the verbose argument to FALSE (verbose = FALSE).\n#setting verbose to FALSE is not recommended if cache is set to TRUE \n#because you won't see the progress.\ndownloadTIMSS(root = \"C:/EdSurveyData\", years = c(2011, 2015), cache = FALSE, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-timss-data","chapter":"4 Data Access","heading":"4.7.2 Reading TIMSS Data","text":"","code":"\n#reading in a single country for a single year for 4th grade\n#returns a single edsurvey.data.frame\ntimss.1<- readTIMSS(path = \"C:/EdSurveyData/TIMSS/2015\", countries = \"usa\", gradeLvl = 4)\n\n#reading in multiple countries for a single year for 8th grade\n#returns an edsurvey.data.frame.list\ntimss.2 <- readTIMSS(path = \"C:/EdSurveyData/TIMSS/2015\",\n                     countries = c(\"aus\", \"swe\", \"nor\"),\n                     gradeLvl = 8)\n\n#use the wildcard to search for all available countries in the path. \n#returns an edsurvey.data.frame.list\ntimss.3 <- readTIMSS(path = \"C:/EdSurveyData/TIMSS/2015\", \n                     countries = \"*\", \n                     gradeLvl = 4)\n\n#specify multiple paths if wishing to read in multiple years.\n#returns an edsurvey.data.frame.list\ntimss.4 <- readTIMSS(path = c(\"C:/EdSurveyData/TIMSS/2015\", \n                              \"C:/EdSurveyData/TIMSS/2011\"), \n                     countries = c(\"usa\", \"swe\"),\n                     gradeLvl = 4)"},{"path":"dataAccess.html","id":"timss-advanced-trends-in-international-mathematics-and-science-study","chapter":"4 Data Access","heading":"4.8 TIMSS Advanced: Trends in International Mathematics and Science Study","text":"TIMSS Advanced study global study focuses target populations secondary school students final year, targeting progress advanced mathematics advanced physics. first study conducted 1995, varying release years public-use datasets 1995, 2008, 2015. studies conducted conjunction Boston College Lynch School Education IEA. addition student assessments home questionnaires, data includes school questionnaire teacher-level questionnaires math physics datasets.downloadTIMSSAdv function downloads unzips data hosted Boston College TIMSS PIRLS Database following years: 1995, 2008, 2015. data also can found manually downloaded IEA Data Repository. required data format used readTIMSSAdv function SPSS (.sav) file format version.beginning analyze TIMSS Advanced data, sure read published user guides documentation provided Boston College IEA familiarize study apply guidance analysis. user guide also identifies ISO three-digit country codes used arguments readTIMSSAdv function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. TIMSS Advanced data include jurisdictions subgroups countries, published TIMSS Advanced documentation includes specific codes needed wish analyze well. readTIMSSAdv function also supports wildcard character * countries parameter, scan specified path directories available countries.readTIMSSAdv call first used read data, process data prepare EdSurvey package first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS (.sav) files gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.edsurvey.data.frame TIMSS data handle necessary merging/linking school- teacher-level data behind scenes user, based variables requested function. Specify subject wish analyze using subject argument select either math physics analysis.","code":""},{"path":"dataAccess.html","id":"obtaining-timss-advanced-data","chapter":"4 Data Access","heading":"4.8.1 Obtaining TIMSS Advanced Data","text":"","code":"\n#obtain the data to analyze for both 2008 and 2015 study years\ndownloadTIMSSAdv(root = \"C:/EdSurveyData\", years = c(2008, 2015), \n                 cache = FALSE, verbose = TRUE)\n\n#if you wish to prepare to analyze all countries to have them ready for analysis,\n#set the cache argument to TRUE (cache = TRUE).  Be prepared that this may take some time.\n#setting the verbose argument to TRUE will keep you informed of the progress in the console.\ndownloadTIMSSAdv(root = \"C:/EdSurveyData\", years = c(2008, 2015),\n                 cache = TRUE, verbose = TRUE)\n\n#for silent output with no message output, set the verbose argument to FALSE (verbose = FALSE).\n#setting verbose to FALSE is not recommended if cache is set to TRUE, \n#because you won't see the progress.\ndownloadTIMSSAdv(root = \"C:/EdSurveyData\", years = c(2008, 2015),\n                 cache = FALSE, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-timss-advanced-data","chapter":"4 Data Access","heading":"4.8.2 Reading TIMSS Advanced Data","text":"","code":"\n#reading in a single country for a single year for the 'math' subject data\n#returns a single edsurvey.data.frame\ntimssadv.1 <- readTIMSSAdv(path = \"C:/EdSurveyData/TIMSSAdv/2015\",\n                           countries = \"usa\", subject = \"math\")\n\n#reading in multiple countries for a single year\n#returns an edsurvey.data.frame.list\ntimssadv.2 <- readTIMSSAdv(path = \"C:/EdSurveyData/TIMSSAdv/2015\",\n                           countries = c(\"fra\", \"ita\", \"svn\"),\n                           subject = \"physics\")\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\ntimssadv.3 <- readTIMSSAdv(path = \"C:/EdSurveyData/TIMSSAdv/2015\",\n                           countries = \"*\",\n                           subject = \"math\")\n\n#specify multiple paths if wishing to read in multiple years.\n#returns an edsurvey.data.frame.list\ntimssadv.4 <- readTIMSSAdv(path = c(\"C:/EdSurveyData/TIMSSAdv/2015\", \n                                    \"C:/EdSurveyData/TIMSSAdv/2008\"),\n                           countries = c(\"nor\", \"swe\"),\n                           subject = \"physics\")"},{"path":"dataAccess.html","id":"piaac-program-for-the-international-assessment-of-adult-competencies","chapter":"4 Data Access","heading":"4.9 PIAAC: Program for the International Assessment of Adult Competencies","text":"PIAAC global study focuseson assessing adult skill competency. study one cycle three data collection rounds. first round conducted 2011–2012 24 countries. second round conducted 2014–2015 nine countries. third round conducted 2017 six countries. United States two rounds collection (round 1 round 3). study conducted Organization Economic Co-operation Development (OECD), study information can found PIAAC website.downloadPIAAC function downloads unzips data hosted OECD cycle one PIAAC study. data also can found manually downloaded PIAAC website. required data format used readPIAAC function comma seperated values (.csv) file format version. addition, readPIAAC function requires provided Microsoft Excel International Codebook file gather necessary details files variables.beginning analyze PIAAC data, sure read published user guides documentation provided OECD familiarize study apply guidance analysis. user guide identifies ISO three-digit country codes used arguments readPIAAC function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. readPIAAC function also supports wildcard character * countries parameter, scan specified path directories available countries.readPIAAC call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing CSV (.csv) files codebook gather relevant data variable information, merging necessary files, outputting CSV (.txt) data file use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.","code":""},{"path":"dataAccess.html","id":"obtaining-piaac-data","chapter":"4 Data Access","heading":"4.9.1 Obtaining PIAAC Data","text":"","code":"\n#obtain the data to analyze cycle 1 data.\ndownloadPIAAC(root = \"C:/EdSurveyData\", cycle = 1, cache = FALSE, verbose = TRUE)\n\n#if you wish to prepare to analyze all countries to have them ready for analysis,\n#set the cache argument to TRUE (cache = TRUE).  Be prepared that this may take some time.\n#setting the verbose argument to TRUE will keep you informed of the progress in the console\ndownloadPIAAC(root = \"C:/EdSurveyData\", cycle = 1, cache = TRUE, verbose = TRUE)\n\n#for silent output with no message output, set the verbose argument \n#to FALSE (verbose = FALSE).\n#setting verbose to FALSE is not recommended if cache is set to TRUE, \n#because you won't see the progress\ndownloadPIAAC(root = \"C:/EdSurveyData\", cycle = 1, cache = FALSE, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-piaac-data","chapter":"4 Data Access","heading":"4.9.2 Reading PIAAC Data","text":"","code":"\n#reading in a single country\n#returns a single edsurvey.data.frame\npiaac.1 <- readPIAAC(path = \"C:/EdSurveyData/PIAAC/Cycle 1/\", countries = \"pol\")\n\n#reading in multiple countries\n#returns an edsurvey.data.frame.list\npiaac.2 <- readPIAAC(path = \"C:/EdSurveyData/PIAAC/Cycle 1/\", \n                     countries = c(\"pol\", \"ltu\", \"tur\"))\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\npiaac.3 <- readPIAAC(path = \"C:/EdSurveyData/PIAAC/Cycle 1/\", countries = \"*\")\n\n#setting verbose to FALSE (verbose = FALSE) suppresses console message output.\n#returns an edsurvey.data.frame.list\npiaac.4 <- readPIAAC(path = \"C:/EdSurveyData/PIAAC/Cycle 1/\", \n                     countries = \"*\", verbose = FALSE)"},{"path":"dataAccess.html","id":"pirls-and-epirls-progress-in-international-reading-literacy-study","chapter":"4 Data Access","heading":"4.10 PIRLS and ePIRLS: Progress in International Reading Literacy Study","text":"","code":""},{"path":"dataAccess.html","id":"pirls","chapter":"4 Data Access","heading":"4.10.1 PIRLS","text":"PIRLS study global study focuses target population Grade 4 students. study began 2001 release cycles every 5 years containing public-use datasets 2001, 2006, 2011, 2016, released conjunction Boston College Lynch School Education IEA. addition student assessments, dataset includes teacher, school, home questionnaires Grade 4.downloadPIRLS function downloads unzips data hosted Boston College TIMSS PIRLS Database following years: 2001, 2006, 2011, 2016. data also can found manually downloaded IEA Data Repository. required data format used readPIRLS function SPSS (.sav) file format version.beginning analyze PIRLS data, sure read published user guides documentation provided Boston College IEA familiarize study, apply guidance analysis. user guides also identify ISO three-digit country codes used arguments readPIRLS function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. PIRLS data include jurisdictions subgroups countries, published PIRLS documentation include specific codes needed wish analyze well. readPIRLS function also supports wildcard character * countries parameter, scan specified path directories available countries.readPIRLS call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS (.sav) files gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.edsurvey.data.frame PIRLS data handle necessary merging/linking school- teacher-level data behind scenes user, based variables requested function.2016, countries less-developed education systems opportunity participate PIRLS Literacy, included passages items lower difficulty. PIRLS Literacy data automatically included readPIRLS 2016 dataset specified.","code":""},{"path":"dataAccess.html","id":"obtaining-pirls-data","chapter":"4 Data Access","heading":"4.10.1.1 Obtaining PIRLS Data","text":"","code":"\n#obtain the data to analyze for both 2011 and 2016 study years\ndownloadPIRLS(root = \"C:/EdSurveyData\", years = c(2011, 2016), \n              cache = FALSE, verbose = TRUE)\n\n#if you wish to prepare to analyze all countries\n#to have them ready for analysis,\n#set the cache argument to TRUE (cache = TRUE).  \n#Be prepared that this may take some time.\n#setting the verbose argument to TRUE will keep you informed \n#of the progress in the console.\ndownloadPIRLS(root = \"C:/EdSurveyData\", years = c(2011, 2016), \n              cache = TRUE, verbose = TRUE)\n\n#for silent output with no message output, set the verbose \n#argument to FALSE (verbose = FALSE).\n#setting verbose to FALSE is not recommended if cache is set to TRUE, \n#because you won't see the progress.\ndownloadPIRLS(root = \"C:/EdSurveyData\", years = c(2011, 2016),\n              cache = FALSE, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-pirls-data","chapter":"4 Data Access","heading":"4.10.1.2 Reading PIRLS Data","text":"","code":"\n#reading in a single country for a single year\npirls.1 <- readPIRLS(path = \"C:/EdSurveyData/PIRLS/2016\", countries = \"usa\")\n\n#reading in multiple countries for a single year\n#returns an edsurvey.data.frame.list\npirls.2 <- readPIRLS(path = \"C:/EdSurveyData/PIRLS/2016\",\n                     countries = c(\"fin\", \"swe\", \"nor\"))\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\npirls.3 <- readPIRLS(path = \"C:/EdSurveyData/PIRLS/2016\", \n                     countries = \"*\")\n\n#specify multiple paths if wishing to read in multiple years.\n#returns an edsurvey.data.frame.list\npirls.4 <- readPIRLS(path = c(\"C:/EdSurveyData/PIRLS/2016\", \n                              \"C:/EdSurveyData/PIRLS/2011\"), \n                     countries = c(\"usa\", \"swe\"))"},{"path":"dataAccess.html","id":"epirls","chapter":"4 Data Access","heading":"4.10.2 ePIRLS","text":"ePIRLS computer-based extension PIRLS study designed assess students’ comprehension online information. ePIRLS study release coincided 2016 PIRLS one public-use dataset available 2016. ePIRLS released conjunction Boston College Lynch School Education IEA. addition student assessments, dataset includes teacher, school, home questionnaires Grade 4.download_ePIRLS function downloads unzips data hosted Boston College TIMSS PIRLS Database 2016 . data also can found manually downloaded IEA Data Repository. required data format used readPIRLS function SPSS (.sav) file format version.beginning analyze ePIRLS data, sure read published user guides documentation provided Boston College IEA familiarize study apply guidance analysis. user guide identifies ISO three-digit country codes used arguments read_ePIRLS function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. ePIRLS data includes jurisdictions subgroups countries, published ePIRLS documentation include specific codes needed wish analyze well. read_ePIRLS function also supports wildcard character * countries parameter, scan specified path directories available countries.read_ePIRLS call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS (.sav) files gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.edsurvey.data.frame ePIRLS data handle necessary merging/linking school- teacher-level data behind scenes user, based variables requested function.","code":""},{"path":"dataAccess.html","id":"obtaining-epirls-data","chapter":"4 Data Access","heading":"4.10.2.1 Obtaining ePIRLS Data","text":"","code":"\n#obtain the data to analyze 2016 study year\ndownload_ePIRLS(root = \"C:/EdSurveyData\", years = 2016, cache = FALSE, verbose = TRUE)\n\n#if you wish to prepare to analyze all countries to have them ready for analysis,\n#set the cache argument to TRUE (cache = TRUE).  Be prepared that this may take some time.\n#setting the verbose argument to TRUE will keep you informed of the progress in the console.\ndownload_ePIRLS(root = \"C:/EdSurveyData\", years = 2016, cache = TRUE, verbose = TRUE)\n\n#for silent output with no message output \n#set the verbose argument to FALSE (verbose = FALSE).\n#setting verbose to FALSE is not recommended if cache is set to TRUE, \n#because you won't see the progress.\ndownload_ePIRLS(root = \"C:/EdSurveyData\", years = 2016, cache = FALSE, verbose = FALSE)"},{"path":"dataAccess.html","id":"reading-epirls-data","chapter":"4 Data Access","heading":"4.10.2.2 Reading ePIRLS Data","text":"","code":"\n#reading in a single country for a single year\n#returns a single edsurvey.data.frame\nepirls.1 <- read_ePIRLS(path = \"C:/EdSurveyData/ePIRLS/2016\", countries = \"irl\")\n\n#reading in multiple countries for a single year\n#returns an edsurvey.data.frame.list\nepirls.2 <- read_ePIRLS(path = \"C:/EdSurveyData/ePIRLS/2016\",\n                        countries = c(\"twn\", \"sgp\"))\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\nepirls.3 <- read_ePIRLS(path = \"C:/EdSurveyData/ePIRLS/2016\", \n                        countries = \"*\")"},{"path":"dataAccess.html","id":"pisa-programme-for-international-student-assessment","chapter":"4 Data Access","heading":"4.11 PISA: Programme for International Student Assessment","text":"PISA global study focuses progress 15-year-old students reading, mathematics, science. study currently seven data collection years: 2000, 2003, 2006, 2009, 2012, 2015, 2018. study conducted OECD, study information can found PISA website.readPISA function argument database, default value int specify international database. PISA 2012, also cba (computer-based database) fin (financial literacy) database available 2012 2018. PISA 2015, financial literacy data included within int database.readPISA function also cognitive argument accepts values none, score (default), response applicable years 2006, 2009, 2012. See ?readPISA documentation additional details.downloadPISA function downloads PISA international data files OECD data products. years 2000 2012, data files consist fixed-width (.txt) data files accompanied SPSS script (.sps) syntax files used parse data files. 2015 2018 datasets, data format required SPSS data (.sav) files.beginning analyze PISA data, sure read studies published user guides documentation provided OECD familiarize study apply guidance analysis. user guides, also identifies ISO three-digit country codes used arguments readPISA function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. readPISA function also supports wildcard character * countries parameter, scan specified path directories available countries.PISA 2000 study, study weights subject specific. weight different adjustment factors reading, mathematics, science based original subject source file. example, w_fstuwt_read weight associated reading subject data file. Special case must used select correct weight based specific analysis. See OECD documentation details. Use showWeights function see three student-level subject weights:w_fstuwt_read = Reading (default)w_fstuwt_scie = Sciencew_fstuwt_math = MathematicsWhen readPISA call first used read data, process data prepare EdSurvey package first read call. step generally takes minutes one country. However, analyzing countries , processing can take much longer initially. preparation involves parsing SPSS data (.sav) (fixed-width data files depending year) codebook gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.","code":""},{"path":"dataAccess.html","id":"obtaining-pisa-data","chapter":"4 Data Access","heading":"4.11.1 Obtaining PISA Data","text":"","code":"\n#download the PISA data for 2018\ndownloadPISA(root = \"C:/EdSurveyData/\", years = 2018)\n\n#download both 2018 and 2015 data\ndownloadPISA(root = \"C:/EdSurveyData/\", years = c(2015, 2018))\n\n#setting cache = TRUE will process all the PISA data and have it ready for EdSurvey\n#this can take some time for all countries\ndownloadPISA(root = \"C:/EdSurveyData/\", years = 2018, cache = TRUE)"},{"path":"dataAccess.html","id":"reading-pisa-data","chapter":"4 Data Access","heading":"4.11.2 Reading PISA Data","text":"","code":"\n#reading in a single country with default values specified\n#returns a single edsurvey.data.frame\npisa.1 <- readPISA(path = \"C:/EdSurveyData/PISA/2018\", database = \"INT\", \n                   countries = \"nzl\", cognitive = \"score\")\n\n#reading in a two countries\n#returns edsurvey.data.frame.list\npisa.2 <- readPISA(path = \"C:/EdSurveyData/PISA/2018\", database = \"INT\",\n                   countries = c(\"nzl\", \"aus\"), cognitive = \"score\")\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\npisa.3 <- readPISA(path = \"C:/EdSurveyData/PISA/2015\", database = \"INT\",\n                   countries = \"*\", cognitive = \"score\")\n\n#reading in PISA 2012 CBA database specifying cognitive = \"none\"\n#returns an edsurvey.data.frame.list\npisa.4 <- readPISA(path = \"C:/EdSurveyData/PISA/2012\", database = \"CBA\",\n                   countries = c(\"bel\", \"bra\"), cognitive = \"none\")\n\n#can set multiple paths to read in many years of data\npisa.5 <- readPISA(path = c(\"C:/EdSurveyData/PISA/2009\",\n                            \"C:/EdSurveyData/PISA/2012\",\n                            \"C:/EdSurveyData/PISA/2015\",\n                            \"C:/EdSurveyData/PISA/2018\"),\n                   database = \"INT\", countries = \"usa\", cognitive = \"score\")\n\n#setting verbose = FALSE suppresses console message output\npisa.6 <- readPISA(path = \"C:/EdSurveyData/PISA/2018\", database = \"INT\", \n                   countries = \"usa\", cognitive = \"score\", verbose = FALSE)"},{"path":"dataAccess.html","id":"pisa-yafs-programme-for-international-student-assessment-young-adult-follow-up-study","chapter":"4 Data Access","heading":"4.12 PISA YAFS: Programme for International Student Assessment Young Adult Follow-up Study","text":"PISA YAFS U.S. study concluded 2016. purpose follow participants PISA 2012 U.S. cohort help reevaluate skills mathematics reading transition college, workforce, adulthood. study used online study instrument designed OECD PIAAC study gather additional information computer Internet usage.EdSurvey supports analyzing PISA YAFS data stand-alone dataset provides ability link U.S. PISA 2012 data PISA YAFS data advanced analysis. example merge provided can found readPISA_YAFS documentation.downloadPISA_YAFS function provides instructions download PISA YAFS data files documentation.readPISA_YAFS function requires data file fixed-width (.dat) file requires SPSS script file (.sps) parse data file. esdf_PISA2012_USA parameter also can specified, pointing edsurvey.data.frame object U.S. PISA 2012 data return merged edsurvey.data.frame.","code":""},{"path":"dataAccess.html","id":"obtaining-pisa-yafs-data","chapter":"4 Data Access","heading":"4.12.1 Obtaining PISA YAFS Data","text":"","code":"\n#View instructions for obtaining PISA YAFS data\ndownloadPISA_YAFS(years = 2016)"},{"path":"dataAccess.html","id":"reading-pisa-yafs-data","chapter":"4 Data Access","heading":"4.12.2 Reading PISA YAFS Data","text":"","code":"\n#Return an edsurvey.data.frame for only the PISA YAFS dataset.\n#Either omit or set the esdf_PISA2012_USA to a NULL value.\nyafs <- readPISA_YAFS(datPath = \"C:/EdSurveyData/PISA YAFS/2016/PISA_YAFS2016_Data.dat\",\n                      spsPath = \"C:/EdSurveyData/PISA YAFS/2016/PISA_YAFS2016_SPSS.sps\",\n                      esdf_PISA2012_USA = NULL)"},{"path":"dataAccess.html","id":"link-pisa-yafs-data-to-pisa-2012","chapter":"4 Data Access","heading":"4.12.3 Link PISA YAFS Data to PISA 2012","text":"","code":"\n#If wanting to analyze the PISA YAFS dataset with the PISA 2012 \n#U.S dataset, it should be read in first to an edsurvey.data.frame.\n#Then pass the resulting edsurvey.data.frame as a parameter for the\n#esdf_PISA2012_USA argument. No other edsurvey.data.frames are supported.\nusa2012 <- readPISA(\"C:/EdSurveyData/PISA/2012\", database = \"INT\", countries = \"usa\")\n\nyafs <- readPISA_YAFS(datPath = \"C:/EdSurveyData/PISA YAFS/2016/PISA_YAFS2016_Data.dat\",\n                      spsPath = \"C:/EdSurveyData/PISA YAFS/2016/PISA_YAFS2016_SPSS.sps\",\n                      esdf_PISA2012_USA = usa2012)"},{"path":"dataAccess.html","id":"talis-teaching-and-learning-international-survey","chapter":"4 Data Access","heading":"4.13 TALIS: Teaching and Learning International Survey","text":"TALIS survey global study focuses school teachers leaders working conditions learning environments schools. study currently three data collection years: 2008, 2013, 2018. study conducted OECD study information can found TALIS website.TALIS datasets three isced levels , b, c. level corresponds Primary Level. b level corresponds Lower Secondary Level, c level Upper Secondary Level. countries may data isced levels. addition, dataSet argument allows specify teacher (default) school depending specific data wish analyze. teacher level includes school level data handles automatically, base unit analysis teacher. Setting dataSet argument school causes ignore teacher data school data base unit analysis.downloadTALIS function provides instructions downloading datasets OECD. data also can found manually downloaded TALIS website data section. required data format used readTALIS function SPSS data (.sav) file format version.beginning analyze TALIS data, sure read published user guides documentation provided OECD familiarize study apply guidance analysis. user guides, also identifies ISO three-digit country codes used arguments readTALIS function read specific countries. three-digit ISO country codes also can found using various online resources, including Wikipedia. readTALIS function also supports wildcard character * countries parameter, scan specified path directories available countries.readTALIS call first used read data, process data prepare EdSurvey first read call. step generally takes minutes one country. However, ’re analyzing countries , processing can take much longer initially. preparation involves parsing SPSS data (.sav) files codebook gather relevant data variable information, merging necessary files, outputting fixed-width (.txt) data file use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.","code":""},{"path":"dataAccess.html","id":"obtaining-talis-data","chapter":"4 Data Access","heading":"4.13.1 Obtaining TALIS Data","text":"","code":"\n#view instructions for obtaining TALIS 2008 data\ndownloadTALIS(years = 2008)\n\n#view instructions for obtaining TALIS 2013 data\ndownloadTALIS(years = 2013)"},{"path":"dataAccess.html","id":"reading-talis-data","chapter":"4 Data Access","heading":"4.13.2 Reading TALIS Data","text":"","code":"\n#reading in a single country for isced='b' and dataLevel='teacher'\n#returns a single edsurvey.data.frame\ntalis.1 <- readTALIS(path = \"C:/EdSurveyData/TALIS/2008\", \n                     countries = \"bra\", isced = \"b\", \n                     dataLevel = \"teacher\")\n\n#reading in a two countries for isced='c' and dataLevel='school'\n#returns edsurvey.data.frame.list\ntalis.2 <- readTALIS(path = \"C:/EdSurveyData/TALIS/2013\", \n                     countries = c(\"aus\", \"mex\"), isced = \"c\", \n                     dataLevel = \"school\")\n\n#use the wildcard to search for all available countries in the path. \n#returns edsurvey.data.frame.list\ntalis.3 <- readTALIS(path = \"C:/EdSurveyData/TALIS/2013\", \n                     countries = \"*\", isced = \"a\", \n                     dataLevel = \"teacher\")\n\n#reading in countries from multiple file paths\n#returns an edsurvey.data.frame.list\ntalis.4 <- readTALIS(path = c(\"C:/EdSurveyData/TALIS/2008\", \n                              \"C:/EdSurveyData/TALIS/2013\"),\n                     countries = c(\"esp\", \"ita\"), isced = \"b\", \n                     dataLevel = \"teacher\")\n\n#isced defaults to a value of 'b' and dataLevel defaults to 'teacher'.\n#setting verbose = FALSE suppresses console message output.\ntalis.5 <- readTALIS(path = \"C:/EdSurveyData/TALIS/2013\", \n                     countries = \"*\", verbose = FALSE)"},{"path":"dataAccess.html","id":"nhes-national-household-education-surveys","chapter":"4 Data Access","heading":"4.14 NHES: National Household Education Surveys","text":"NHES program series surveys conducted United States focus education topics children families. Topics include adult education, civic involvement, early childhood program participation, parent family involvement education. surveys conducted every years, topics covered vary year. Detailed information NHES program can found NHES website. NHES conducted 1991, 1993, 1995, 1996, 1999, 2001, 2003, 2005, 2007, 2012, 2016, 2019.downloadNHES function provides instructions downloading datasets NCES Online Codebook. required data format used readNHES function SPSS data (.sav) file format version. readNHES function designed work Online Codebook public-use files. Data obtained sources require SPSS format generally require setting surveyCode parameter function. Users can use getNHES_SurveyInfo function retrieve survey information/codes data.frame viewNHES_SurveyCodes function print survey codes descriptions console.beginning analyze NHES data, sure read published user guides documentation provided NCES familiarize study apply guidance analysis found NHES website.readNHES call first run, process data prepare EdSurvey preparing cached version data. step generally takes minutes one survey. However, analyzing survey data files , processing can take much longer. cache preparation involves parsing SPSS data (.sav) files codebook gather relevant data variable information, outputting fixed-width (.txt) data file use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.","code":""},{"path":"dataAccess.html","id":"obtaining-nhes-data","chapter":"4 Data Access","heading":"4.14.1 Obtaining NHES Data","text":"","code":"\n#view instructions for obtaining NHES data\ndownloadNHES()"},{"path":"dataAccess.html","id":"reading-nhes-data","chapter":"4 Data Access","heading":"4.14.2 Reading NHES Data","text":"","code":"\n#reading in a single file for Early Childhood Program Participation\n#file obtained from Online Codebook, so surveyCode = \"auto\" works (the default)\n#returns a single edsurvey.data.frame\nnhes.1 <- readNHES(savFiles = \"C:/EdSurveyData/NHES/2019/nhes_19_ecpp_v1_0.sav\", \n                   surveyCode = \"auto\")\n\n#reading in a two files across two years (2019 and 2016 ECCP)\n#returns edsurvey.data.frame.list\nimportFiles <- c(\"C:/EdSurveyData/NHES/2019/nhes_19_ecpp_v1_0.sav\",\n                 \"C:/EdSurveyData/NHES/2016/nhes_16_ecpp_v1_0.sav\")\nnhes.2 <- readNHES(savFiles = importFiles, \n                   surveyCode = \"auto\")\n\n#setting the 'surveyCode' parameter explicitly if 'auto' fails.\n#returns edsurvey.data.frame\nviewNHES_SurveyCodes() \nnhes.3 <- readNHES(savFiles = \"C:/EdSurveyData/NHES/2019/nhes_19_ecpp_v1_0.sav\", \n                   surveyCode = \"ECPP_2019\")\n\n#reading multiple files with explicit 'surveyCode' parameter\n#returns an edsurvey.data.frame.list\nimportFiles <- c(\"C:/EdSurveyData/NHES/2019/nhes_19_ecpp_v1_0.sav\",\n                 \"C:/EdSurveyData/NHES/2016/nhes_16_ecpp_v1_0.sav\")\nnhes.4 <- readNHES(savFiles = importFiles,\n                   surveyCode = c(\"ECPP_2019\", \"ECPP_2016\"))"},{"path":"dataAccess.html","id":"ssocs-school-survey-on-crime-and-safety","chapter":"4 Data Access","heading":"4.15 SSOCS: School Survey on Crime and Safety","text":"SSOCS set surveys conducted United States school level involving crime safety topics. surveys conducted every years. Detailed information SSOCS program can found SSOCS website. SSOCS conducted 2000 (1999–2000), 2004 (2003–2004), 2006 (2005–2006), 2008 (2007–2008), 2010 (2009–2010), 2016 (2015–2016), 2018 (2017–2018).downloadSSOCS function provides instructions downloading datasets SSOCS Data Product webpage. required data format used readSSOCS function SAS data (.sas7bdat) file format version. readSSOCS function designed work public-use files, EdSurvey stores required meta data SSOCS data within package based year parameter.beginning analyze using SSOCS data, sure read published user guides documentation provided NCES familiarize study apply guidance analysis found SSOCS website.readSSOCS call first run, process data prepare EdSurvey preparing cached version data. step generally takes minutes one survey. However, analyzing survey data files , processing can take much longer. preparation involves parsing SAS data (.sas7bdat) files gather relevant data variable information, outputting fixed-width (.txt) data file use EdSurvey. using data caching technique, EdSurvey can load required data demand, keeps minimal memory footprint.","code":""},{"path":"dataAccess.html","id":"obtaining-ssocs-data","chapter":"4 Data Access","heading":"4.15.1 Obtaining SSOCS Data","text":"","code":"\n#view instructions for obtaining SSOCS data\ndownloadSSOCS()"},{"path":"dataAccess.html","id":"reading-ssocs-data","chapter":"4 Data Access","heading":"4.15.2 Reading SSOCS Data","text":"","code":"\n#reading in a single file for 2018 survey\n#returns a single edsurvey.data.frame\nssocs.1 <- readSSOCS(sasDataFiles = \"C:/EdSurveyData/SSOCS/2018/pu_ssocs18.sas7bdat\", \n                     years = \"2018\")\n\n#reading in a two files across two years (2018 and 2016)\n#returns edsurvey.data.frame.list\nimportFiles <- c(\"C:/EdSurveyData/SSOCS/2018/pu_ssocs18.sas7bdat\",\n                 \"C:/EdSurveyData/SSOCS/2016/pu_ssocs16.sas7bdat\")\nssocs.2 <- readSSOCS(sasDataFiles = importFiles, \n                     years = c(\"2018\", \"2016\"))\n\n#setting the 'verbose = FALSE' parameter for silent output.\n#returns edsurvey.data.frame\nssocs.3 <- readSSOCS(sasDataFiles = \"C:/EdSurveyData/SSOCS/2018/pu_ssocs18.sas7bdat\", \n                     years = \"2018\",\n                     verbose = FALSE)"},{"path":"understandingData.html","id":"understandingData","chapter":"5 Understanding Data","heading":"5 Understanding Data","text":"Last edited: July 2023Suggested Citation\nLiao, Y. Understanding Data. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.data successfully read (see EdSurvey supports reading-data study Chapter 4), users can use commands following sections understand data.follow along chapter, load NAEP Primer dataset M36NT2PM assign name sdf following call:","code":"\nsdf <- readNAEP(path = system.file(\"extdata/data\", \"M36NT2PM.dat\", package = \"NAEPprimer\"))"},{"path":"understandingData.html","id":"searching-variables","chapter":"5 Understanding Data","heading":"5.1 Searching Variables","text":"colnames() function list variable names data:conduct powerful search NAEP data variables, use searchSDF() function, returns variable names labels edsurvey.data.frame based character string. user can specify data source (either “student” “school”) search. example, following call searchSDF() searches character string \"book\" edsurvey.data.frame specifies fileFormat search student data file:levels labels variable searched via searchSDF() also can returned setting levels = TRUE:| () operator search several strings simultaneously:vector strings search variables contain multiple strings, “book” “home”; string present variable label can used filter results:dive particular variable, use levelsSDF(). returns levels, corresponding sample size, label level.","code":"\ncolnames(x = sdf)\n#>   [1] \"ROWID\"   \"year\"    \"cohort\"  \"scrpsu\"  \"dsex\"   \n#>   [6] \"iep\"     \"lep\"     \"ell3\"    \"sdracem\" \"pared\"  \n#>  [11] \"b003501\" \"b003601\" \"b013801\" \"b017001\" \"b017101\"\n#>  [16] \"b018101\" \"b018201\" \"b017451\" \"m815401\" \"m815501\"\n#>  [21] \"m815601\" \"m815801\" \"m815701\" \"rptsamp\" \"repgrp1\"\n#>  [26] \"repgrp2\" \"jkunit\"  \"origwt\"  \"srwt01\"  \"srwt02\" \n#>  [31] \"srwt03\"  \"srwt04\"  \"srwt05\"  \"srwt06\"  \"srwt07\" \n#>  [36] \"srwt08\"  \"srwt09\"  \"srwt10\"  \"srwt11\"  \"srwt12\" \n#>  [41] \"srwt13\"  \"srwt14\"  \"srwt15\"  \"srwt16\"  \"srwt17\" \n#>  [46] \"srwt18\"  \"srwt19\"  \"srwt20\"  \"srwt21\"  \"srwt22\" \n#>  [51] \"srwt23\"  \"srwt24\"  \"srwt25\"  \"srwt26\"  \"srwt27\" \n#>  [56] \"srwt28\"  \"srwt29\"  \"srwt30\"  \"srwt31\"  \"srwt32\" \n#>  [61] \"srwt33\"  \"srwt34\"  \"srwt35\"  \"srwt36\"  \"srwt37\" \n#>  [66] \"srwt38\"  \"srwt39\"  \"srwt40\"  \"srwt41\"  \"srwt42\" \n#>  [71] \"srwt43\"  \"srwt44\"  \"srwt45\"  \"srwt46\"  \"srwt47\" \n#>  [76] \"srwt48\"  \"srwt49\"  \"srwt50\"  \"srwt51\"  \"srwt52\" \n#>  [81] \"srwt53\"  \"srwt54\"  \"srwt55\"  \"srwt56\"  \"srwt57\" \n#>  [86] \"srwt58\"  \"srwt59\"  \"srwt60\"  \"srwt61\"  \"srwt62\" \n#>  [91] \"smsrswt\" \"mrps11\"  \"mrps12\"  \"mrps13\"  \"mrps14\" \n#>  [96] \"mrps15\"  \"mrps21\"  \"mrps22\"  \"mrps23\"  \"mrps24\" \n#> [101] \"mrps25\"  \"mrps31\"  \"mrps32\"  \"mrps33\"  \"mrps34\" \n#> [106] \"mrps35\"  \"mrps41\"  \"mrps42\"  \"mrps43\"  \"mrps44\" \n#> [111] \"mrps45\"  \"mrps51\"  \"mrps52\"  \"mrps53\"  \"mrps54\" \n#> [116] \"mrps55\"  \"mrpcm1\"  \"mrpcm2\"  \"mrpcm3\"  \"mrpcm4\" \n#> [121] \"mrpcm5\"  \"m075201\" \"m075401\" \"m075601\" \"m019901\"\n#> [126] \"m066201\" \"m047301\" \"m046201\" \"m066401\" \"m020101\"\n#> [131] \"m067401\" \"m086101\" \"m047701\" \"m067301\" \"m048001\"\n#> [136] \"m093701\" \"m086001\" \"m051901\" \"m076001\" \"m046001\"\n#> [141] \"m046101\" \"m067701\" \"m046701\" \"m046901\" \"m047201\"\n#> [146] \"m046601\" \"m046801\" \"m067801\" \"m066601\" \"m067201\"\n#> [151] \"m068003\" \"m068005\" \"m068008\" \"m068007\" \"m068006\"\n#> [156] \"m093601\" \"m053001\" \"m047801\" \"m086301\" \"m085701\"\n#> [161] \"m085901\" \"m085601\" \"m085501\" \"m085801\" \"m019701\"\n#> [166] \"m020001\" \"m046301\" \"m047001\" \"m046501\" \"m066501\"\n#> [171] \"m047101\" \"m066301\" \"m067901\" \"m019601\" \"m051501\"\n#> [176] \"m047901\" \"m053101\" \"m143601\" \"m143701\" \"m143801\"\n#> [181] \"m143901\" \"m144001\" \"m144101\" \"m144201\" \"m144301\"\n#> [186] \"m144401\" \"m144501\" \"m144601\" \"m144701\" \"m144801\"\n#> [191] \"m144901\" \"m145001\" \"m145101\" \"m013431\" \"m0757cl\"\n#> [196] \"m013131\" \"m091701\" \"m072801\" \"m091501\" \"m091601\"\n#> [201] \"m073501\" \"m052401\" \"m075301\" \"m072901\" \"m013631\"\n#> [206] \"m075801\" \"m013731\" \"m013531\" \"m051801\" \"m093401\"\n#> [211] \"m093801\" \"m142001\" \"m142101\" \"m142201\" \"m142301\"\n#> [216] \"m142401\" \"m142501\" \"m142601\" \"m142701\" \"m142801\"\n#> [221] \"m142901\" \"m143001\" \"m143101\" \"m143201\" \"m143301\"\n#> [226] \"m143401\" \"m143501\" \"m105601\" \"m105801\" \"m105901\"\n#> [231] \"m106001\" \"m106101\" \"m106201\" \"m106301\" \"m106401\"\n#> [236] \"m106501\" \"m106601\" \"m106701\" \"m106801\" \"m106901\"\n#> [241] \"m107001\" \"m107101\" \"m107201\" \"m107401\" \"m107501\"\n#> [246] \"m107601\" \"m109801\" \"m110001\" \"m110101\" \"m110201\"\n#> [251] \"m110301\" \"m110401\" \"m110501\" \"m110601\" \"m110701\"\n#> [256] \"m110801\" \"m110901\" \"m111001\" \"m111201\" \"m111301\"\n#> [261] \"m111401\" \"m111501\" \"m111601\" \"m111801\" \"yrsexp\" \n#> [266] \"yrsmath\" \"t089401\" \"t088001\" \"t090801\" \"t090802\"\n#> [271] \"t090803\" \"t090804\" \"t090805\" \"t090806\" \"t087501\"\n#> [276] \"t088301\" \"t088401\" \"t088501\" \"t088602\" \"t088603\"\n#> [281] \"t088801\" \"t088803\" \"t088804\" \"t088805\" \"t091502\"\n#> [286] \"t091503\" \"t091504\" \"c052801\" \"c052802\" \"c052804\"\n#> [291] \"c052805\" \"c052806\" \"c052807\" \"c052808\" \"c052701\"\n#> [296] \"c046501\" \"c044006\" \"c044007\" \"c052901\" \"c053001\"\n#> [301] \"c053101\" \"sscrpsu\" \"c052601\"\nsearchSDF(string = \"book\", data = sdf, fileFormat = \"student\")\n#>   variableName                                       Labels\n#> 1      b013801                                Books in home\n#> 2      t088804 Computer activities: Use a gradebook program\n#> 3      t091503     G8Math:How often use Geometry sketchbook\n#>   fileFormat\n#> 1    Student\n#> 2    Student\n#> 3    Student\nsearchSDF(string = \"book\", data = sdf, fileFormat = \"student\", levels = TRUE)\n#> Variable: b013801\n#> Label: Books in home\n#> Levels (Lowest level first):\n#>      1. 0-10\n#>      2. 11-25\n#>      3. 26-100\n#>      4. >100\n#>      8. Omitted\n#>      0. Multiple\n#> Variable: t088804\n#> Label: Computer activities: Use a gradebook program\n#> Levels (Lowest level first):\n#>      1. Never or hardly ever\n#>      2. Once or twice/month\n#>      3. Once or twice a week\n#>      4. Almost every day\n#>      8. Omitted\n#>      0. Multiple\n#> Variable: t091503\n#> Label: G8Math:How often use Geometry sketchbook\n#> Levels (Lowest level first):\n#>      1. Never or hardly ever\n#>      2. Once or twice/month\n#>      3. Once or twice a week\n#>      4. Almost every day\n#>      8. Omitted\n#>      0. Multiple\nsearchSDF(string=\"book|home|value\", data=sdf)\n#>    variableName\n#> 1       b013801\n#> 2       b017001\n#> 3       b017101\n#> 4       b018201\n#> 5       b017451\n#> 6       m086101\n#> 7       m020001\n#> 8       m143601\n#> 9       m142301\n#> 10      t088804\n#> 11      t088805\n#> 12      t091503\n#>                                               Labels\n#> 1                                      Books in home\n#> 2                                  Newspaper in home\n#> 3                                   Computer at home\n#> 4         Language other than English spoken in home\n#> 5                         Talk about studies at home\n#> 6                              Read value from graph\n#> 7  Apply place value                            (R1)\n#> 8                       Solve for x given value of n\n#> 9                               Identify place value\n#> 10      Computer activities: Use a gradebook program\n#> 11  Computer activities: Post homework,schedule info\n#> 12          G8Math:How often use Geometry sketchbook\n#>    fileFormat\n#> 1     Student\n#> 2     Student\n#> 3     Student\n#> 4     Student\n#> 5     Student\n#> 6     Student\n#> 7     Student\n#> 8     Student\n#> 9     Student\n#> 10    Student\n#> 11    Student\n#> 12    Student\nsearchSDF(string=c(\"book\",\"home\"), data=sdf)\n#>   variableName        Labels fileFormat\n#> 1      b013801 Books in home    Student\nlevelsSDF(varnames = \"b017451\", data = sdf)\n#> Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever (n = 3837)\n#>     2. Once every few weeks (n = 3147)\n#>     3. About once a week (n = 2853)\n#>     4. 2 or 3 times a week (n = 3362)\n#>     5. Every day (n = 3132)\n#>     8. Omitted* (n = 575)\n#>     0. Multiple* (n = 9)\n#>     NOTE: * indicates an omitted level."},{"path":"understandingData.html","id":"displaying-basic-information","chapter":"5 Understanding Data","heading":"5.2 Displaying Basic Information","text":"basic functions work data.frame, dim, nrow, ncol, also work edsurvey.data.frame. help check dimensions sdf.Basic information plausible values weights edsurvey.data.frame can seen print function. variables associated plausible values weights can seen showPlausibleValues showWeights functions, respectively, setting verbose argument TRUE:functions getStratumVar getPSUVar return default stratum variable name PSU variable associated weight variable.","code":"\ndim(x = sdf)\n#> [1] 17606   303\nnrow(x = sdf)\n#> [1] 17606\nncol(x = sdf)\n#> [1] 303\nshowPlausibleValues(data = sdf, verbose = TRUE)\n#> There are 6 subject scale(s) or subscale(s) in this\n#>   edsurvey.data.frame:\n#> 'num_oper' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps11',\n#>   'mrps12', 'mrps13', 'mrps14', and 'mrps15'\n#> \n#> 'measurement' subject scale or subscale with 5\n#>   plausible values.\n#>   The plausible value variables are: 'mrps21',\n#>   'mrps22', 'mrps23', 'mrps24', and 'mrps25'\n#> \n#> 'geometry' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps31',\n#>   'mrps32', 'mrps33', 'mrps34', and 'mrps35'\n#> \n#> 'data_anal_prob' subject scale or subscale with 5\n#>   plausible values.\n#>   The plausible value variables are: 'mrps41',\n#>   'mrps42', 'mrps43', 'mrps44', and 'mrps45'\n#> \n#> 'algebra' subject scale or subscale with 5 plausible\n#>   values.\n#>   The plausible value variables are: 'mrps51',\n#>   'mrps52', 'mrps53', 'mrps54', and 'mrps55'\n#> \n#> 'composite' subject scale or subscale with 5\n#>   plausible values (the default).\n#>   The plausible value variables are: 'mrpcm1',\n#>   'mrpcm2', 'mrpcm3', 'mrpcm4', and 'mrpcm5'\nshowWeights(data = sdf, verbose = TRUE)\n#> There is 1 full sample weight in this\n#>   edsurvey.data.frame:\n#>   'origwt' with 62 JK replicate weights (the\n#>   default).\n#>     Jackknife replicate weight variables associated\n#>     with the full sample weight 'origwt':\n#>     'srwt01', 'srwt02', 'srwt03', 'srwt04', 'srwt05',\n#>     'srwt06', 'srwt07', 'srwt08', 'srwt09', 'srwt10',\n#>     'srwt11', 'srwt12', 'srwt13', 'srwt14', 'srwt15',\n#>     'srwt16', 'srwt17', 'srwt18', 'srwt19', 'srwt20',\n#>     'srwt21', 'srwt22', 'srwt23', 'srwt24', 'srwt25',\n#>     'srwt26', 'srwt27', 'srwt28', 'srwt29', 'srwt30',\n#>     'srwt31', 'srwt32', 'srwt33', 'srwt34', 'srwt35',\n#>     'srwt36', 'srwt37', 'srwt38', 'srwt39', 'srwt40',\n#>     'srwt41', 'srwt42', 'srwt43', 'srwt44', 'srwt45',\n#>     'srwt46', 'srwt47', 'srwt48', 'srwt49', 'srwt50',\n#>     'srwt51', 'srwt52', 'srwt53', 'srwt54', 'srwt55',\n#>     'srwt56', 'srwt57', 'srwt58', 'srwt59', 'srwt60',\n#>     'srwt61', and 'srwt62'\ngetStratumVar(data = sdf, weightVar = \"origwt\")\n#>   stratum \n#> \"repgrp1\"\ngetPSUVar(data = sdf, weightVar = \"origwt\")\n#>      psu \n#> \"jkunit\""},{"path":"understandingData.html","id":"keeping-or-removing-omitted-levels","chapter":"5 Understanding Data","heading":"5.3 Keeping or Removing Omitted Levels","text":"EdSurvey uses listwise deletion remove special values analyses default. example, NAEP Primer data, omitted levels returned print(sdf) called: Omitted Levels: 'Multiple', 'NA', 'Omitted'. default, levels excluded via listwise deletion EdSurvey analytical functions. use different method, pairwise deletion, set defaultConditions = FALSE running analysis.","code":""},{"path":"understandingData.html","id":"exploring-data","chapter":"5 Understanding Data","heading":"5.4 Exploring Data","text":"section introduces three basic R functions (EdSurvey non-EdSurvey) commonly used data exploration step, follows:summary2() produces weighted unweighted descriptive statistics variable.summary2() produces weighted unweighted descriptive statistics variable.edsurveyTable() produces cross-tabulation statistics.edsurveyTable() produces cross-tabulation statistics.ggplot2 produces variety exploratory data analysis (EDA) plots.ggplot2 produces variety exploratory data analysis (EDA) plots.","code":""},{"path":"understandingData.html","id":"summary2","chapter":"5 Understanding Data","heading":"5.4.1 summary2()","text":"summary2() takes following four arguments order:data: EdSurvey object.variable: Name variable want produce statistics .weightVar: name weight variable NULL users want produce unweighted statistics.dropOmittedLevels: TRUE, function remove omitted levels specified variable producing descriptive statistics. FALSE, function include omitted levels output statistics.summary2 function produces weighted unweighted descriptive statistics variable. functionality quite useful gathering response information survey variables conducting data exploration. NAEP data datasets default weight variable, summary2 produces weighted statistics default. specified variable set plausible values, weightVar option non-NULL, summary2 statistics account plausible values pooling weighting.specifying weightVar = NULL, function prints unweighted descriptive statistics selected variable plausible values:categorical variable, summary2 function returns weighted number cases, weighted percentage, weighted standard error (SE). example, variable b017451 (frequency students talking studies home) returns following output:default, summary2 function includes omitted levels; remove levels, set dropOmittedLevels = TRUE:","code":"\nsummary2(data = sdf, variable = \"composite\")\n#> Estimates are weighted using the weight variable 'origwt'\n#>    Variable     N Weighted N   Min.  1st Qu.   Median\n#> 1 composite 16915   16932.46 126.11 251.9626 277.4784\n#>       Mean  3rd Qu.    Max.      SD NA's Zero weights\n#> 1 275.8892 301.1827 404.184 36.5713    0            0\nsummary2(data = sdf, variable = \"composite\", weightVar = NULL)\n#> Estimates are not weighted.\n#>   Variable     N   Min.  1st Qu. Median     Mean  3rd Qu.\n#> 1   mrpcm1 16915 130.53 252.0600 277.33 275.8606 300.7200\n#> 2   mrpcm2 16915 124.16 252.2100 277.33 275.6399 300.6900\n#> 3   mrpcm3 16915 115.09 252.0017 277.19 275.6570 300.5600\n#> 4   mrpcm4 16915 137.19 252.4717 277.44 275.7451 300.5767\n#> 5   mrpcm5 16915 123.58 252.4900 277.16 275.6965 300.5000\n#>     Max.       SD NA's\n#> 1 410.80 35.89864    0\n#> 2 408.58 36.08483    0\n#> 3 398.17 36.09278    0\n#> 4 407.41 35.91078    0\n#> 5 395.96 36.10905    0\nsummary2(data = sdf, variable = \"b017451\")\n#> Estimates are weighted using the weight variable 'origwt'\n#>                b017451    N Weighted N Weighted Percent\n#> 1 Never or hardly ever 3837  3952.4529      23.34245648\n#> 2 Once every few weeks 3147  3190.8945      18.84483329\n#> 3    About once a week 2853  2937.7148      17.34960077\n#> 4  2 or 3 times a week 3362  3425.8950      20.23270282\n#> 5            Every day 3132  3223.8074      19.03921080\n#> 6              Omitted  575   194.3312       1.14768416\n#> 7             Multiple    9     7.3676       0.04351168\n#>   Weighted Percent SE\n#> 1           0.4318975\n#> 2           0.3740648\n#> 3           0.3414566\n#> 4           0.3156289\n#> 5           0.4442216\n#> 6           0.1272462\n#> 7           0.0191187\nsummary2(data = sdf, variable = \"b017451\", dropOmittedLevels = TRUE)\n#> Estimates are weighted using the weight variable 'origwt'\n#>                b017451    N Weighted N Weighted Percent\n#> 1 Never or hardly ever 3837   3952.453         23.62386\n#> 2 Once every few weeks 3147   3190.894         19.07202\n#> 3    About once a week 2853   2937.715         17.55876\n#> 4  2 or 3 times a week 3362   3425.895         20.47662\n#> 5            Every day 3132   3223.807         19.26874\n#>   Weighted Percent SE\n#> 1           0.4367548\n#> 2           0.3749868\n#> 3           0.3486008\n#> 4           0.3196719\n#> 5           0.4467063"},{"path":"understandingData.html","id":"edsurveytable","chapter":"5 Understanding Data","heading":"5.4.2 edsurveyTable()","text":"edsurveyTable() creates summary table outcome categorical variables. three important arguments follows:formula: Typically written ~ b + c, following meanings:\ncontinuous variable (optional) function return weighted mean.\nb c categorical variables function run cross-tabulations; multiple crosstab\ncategorical variables can separated using + symbol.\ncontinuous variable (optional) function return weighted mean.b c categorical variables function run cross-tabulations; multiple crosstab\ncategorical variables can separated using + symbol.data: EdSurvey object.pctAggregationLevel: numeric value (.e., 0, 1, 2) indicates level aggregation cross-tabulation result’s percentage column.following call uses edsurveyTable() create summary table NAEP composite mathematics performance scale scores (composite) 8th-grade students two student factors:\n- dsex: gender\n- b017451: frequency talk studies homepctAggregationLevel default set NULL (1). , PCT column adds 100 within level first categorical variable dsex.\nTable 5.1. Summary Data Tables EdSurvey\nspecifying pctAggregationLevel = 0, following call, PCT column adds 100 across entire sample.\nTable 5.2. Summary Data Tables EdSurvey, Setting pctAggregationLevel = 0\n","code":"\nes1 <- edsurveyTable(formula = composite ~ dsex + b017451, data = sdf, pctAggregationLevel = NULL)\nes2 <- edsurveyTable(formula = composite ~ dsex + b017451, data = sdf, pctAggregationLevel = 0)"},{"path":"understandingData.html","id":"ggplot2","chapter":"5 Understanding Data","heading":"5.4.3 ggplot2","text":"ggplot2 important R package used EdSurvey conduct EDA.basic steps using ggplot2 follows. learn use ggplot2(), visit official website.Start ggplot().Supply dataset aesthetic mapping aes().Add layers comprising one following functions. address examples talicized functions.Geometries: geom_bar(), geom_histogram(), geom_boxplot()Scales: scale_colour_brewer(), scale_x_date()Facets: facet_grid(), facet_wrap()Statistical transformations: stat_summary(), stat_density()Coordinate systems: coord_flip(), coord_map()chapter, find “quick dirty” approach (.e., application weights; applicable, one set plausible values used) EDA using ggplot2 EdSurvey functions. learn conducting EDA NCES data, read Exploratory Data Analysis NCES DataThis section uses following gddat object:geom_bar() uses height rectangles represent data values. Figure 1 shows bar chart counts variable b017451 category, fill = dsex used color portions selected x variable.geom_histogram() uses binning visualize distribution continuous variables. Figure 2 basic histogram uses first plausible value composite, giving unbiased (unweighted) estimate frequencies bin.Figure 3 extends Figure 2, faceted categorical variable dsex, output two histograms common axes.geom_boxplot() shows distribution single variable quartiles. Figure 4 shows distribution six levels sdracem variable first plausible value composite.Figure 5 extends Figure 4 using stat_summary() add another statistic top: mean mrpcm1 sdracem, represented diamond-shaped symbol (shape = 23). Figure 5 also adds coordinate flip via coord_flip().","code":"\n# load the ggplot2 library\nlibrary(ggplot2)\ngddat <- getData(data = sdf, varnames = c('dsex', 'sdracem', 'b018201', 'b017451',\n                                   'composite', 'geometry', 'origwt'),\n              addAttributes = TRUE, dropOmittedLevels = FALSE)\nbar1 <- ggplot(data = gddat, aes(x = b017451)) +\n  geom_bar(aes(fill = dsex)) +\n  coord_flip() +\n  labs(title = \"Figure 1\")\nbar1\nhist1 <- ggplot(gddat, aes(x = mrpcm1)) +\n    geom_histogram() + \n    labs(title = \"Figure 2\") \nhist1\nhist2 <- ggplot(gddat, aes(x = mrpcm1)) +\n  geom_histogram(color = \"black\", fill = \"white\")+\n  facet_grid(dsex ~ .) +\n  labs(title = \"Figure 3\") \nhist2\n#> Warning: Combining variables of class <lfactor> and <factor> was\n#> deprecated in ggplot2 3.4.0.\n#> ℹ Please ensure your variables are compatible before\n#>   plotting (location: `join_keys()`)\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_lifecycle_warnings()` to see where\n#> this warning was generated.\nbox1 <- ggplot(gddat, aes(x = sdracem, y = mrpcm1)) + \n  geom_boxplot() +\n  labs(title = \"Figure 4\") \nbox1\n\nbox2 <- box1 + stat_summary(fun.y = mean, geom = \"point\", shape = 23, size = 4) +\n  coord_flip() +\n  labs(title = \"Figure 5\") \nbox2"},{"path":"dataManipulation.html","id":"dataManipulation","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6 Data Manipulation in EdSurvey and Base R","text":"Last edited: July 2023Suggested Citation\nLee, M. & Bailey, P. Data Manipulation EdSurvey Base R. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.EdSurvey gives users functions efficiently analyze education survey data. mentioned Chapter 3, EdSurvey flexible conducting data manipulation preparing survey analysis. allows rudimentary data manipulation analysis EdSurvey base R functions edit data processing. Also, calling function getData(), one can extract light.edsurvey.data.frame manipulate similarly data.frame objects R packages. concept detailed Chapter 9analysisOutsideEdSurvey).","code":""},{"path":"dataManipulation.html","id":"subsetting-the-data","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.1 Subsetting the Data","text":"Analysts can directly use subset dataset EdSurvey functions. example, summary table created edsurveyTable filtering sample include students whose value dsex variable male race (variable sdracem) either 1 3 (White Hispanic). value levels labels can used EdSurvey functions.Table 6.1. Subsetting Data ","code":"\nsdf <- readNAEP(path = system.file(\"extdata/data\", \"M36NT2PM.dat\", package = \"NAEPprimer\"))\nsdfm <- subset(x = sdf, subset = dsex == \"Male\" & (sdracem == 3 | sdracem == 1))\nes1 <- edsurveyTable(formula = composite ~ dsex + sdracem, data = sdfm)\nes1"},{"path":"dataManipulation.html","id":"recoding-variable-names-and-levels-using-recode.sdf-and-rename.sdf","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.2 Recoding Variable Names and Levels Using recode.sdf and rename.sdf","text":"assist process standardizing data edsurvey.data.frame, light.edsurvey.data.frame, edsurvey.data.frame.list, functions recode.sdf() rename.sdf() handy.recode.sdf() function accepts levels variable vector current values newly recoded value. example, changing lowest level b017451 \"Never hardly ever\" \"Infrequently\" highest level \"Every day\" \"Frequently\", recode levels variable connection sdf:addition, can change name variables using rename.sdf(). recoded variable \"b017451\" can changed value effectively describes contents, \"studytalkfrequency\":EdSurvey analytical functions allow user recode variable levels recode argument, including, example, cor.sdf(), lm.sdf(), edsurveyTable(). Reference function’s documentation page details.also important note EdSurvey functions (function arguments) permanently overwrite variable information data source; recode current connection data R. original file formatting can retrieved reconnecting data source via readNAEP().","code":"\nsdf2 <- recode.sdf(sdf, recode = list(\n  b017451 = list(from = c(\"Never or hardly ever\"),\n               to = c(\"Infrequently\")),\n  b017451 = list(from = c(\"Every day\"),\n               to = c (\"Frequently\"))\n  )\n)\nsearchSDF(string = \"b017451\", data = sdf2, levels = TRUE)                              \n#> Variable: b017451\n#> Label: Talk about studies at home\n#> Levels (Lowest level first):\n#>      2. Once every few weeks\n#>      3. About once a week\n#>      4. 2 or 3 times a week\n#>      8. Omitted\n#>      0. Multiple\n#>      9. Infrequently\n#>      10. Frequently\nsdf2 <- rename.sdf(x = sdf2, oldnames = \"b017451\", newnames = \"studytalkfrequency\")\nsearchSDF(string = \"studytalkfrequency\", data = sdf2, levels = TRUE)\n#> Variable: studytalkfrequency\n#> Label: Talk about studies at home\n#> Levels (Lowest level first):\n#>      2. Once every few weeks\n#>      3. About once a week\n#>      4. 2 or 3 times a week\n#>      8. Omitted\n#>      0. Multiple\n#>      9. Infrequently\n#>      10. Frequently"},{"path":"dataManipulation.html","id":"retrieving-data-for-further-manipulation-with-getdata-1","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.3 Retrieving Data for Further Manipulation With getData","text":"Data can extracted manipulated using function getData. function getData takes edsurvey.data.frame returns light.edsurvey.data.frame containing requested variables either specifying set variable names varnames entering formula formula.4 plausible values weights, names main scale/subscale weight variable need included necessary supplementary variables automatically included.access manipulate data dsex b017451 variables num_oper subject scale sdf, call getData. following code, head function used, reveals first rows resulting data:default, setting dropOmittedLevels TRUE removes special values multiple entries instances NA. getData tries help dropping levels factors regression, tables, correlations typically included analysis.","code":"\ngddat <- getData(data = sdf, varnames = c(\"dsex\",\"b017451\", \"num_oper\"),\n                 dropOmittedLevels = TRUE)\nhead(gddat)\n#>     dsex              b017451 mrps11 mrps12 mrps13 mrps14\n#> 1   Male            Every day 321.57 299.37 306.94 310.63\n#> 2 Female    About once a week 283.79 273.33 285.96 284.48\n#> 3 Female            Every day 334.42 323.01 316.28 361.03\n#> 4   Male            Every day 337.25 315.84 316.92 319.00\n#> 6 Female Once every few weeks 253.99 248.50 260.63 270.22\n#> 7   Male  2 or 3 times a week 313.27 329.85 315.97 313.91\n#>   mrps15\n#> 1 308.04\n#> 2 281.61\n#> 3 321.40\n#> 4 323.68\n#> 6 267.75\n#> 7 311.69"},{"path":"dataManipulation.html","id":"retrievingAllVariablesInADataset","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.4 Retrieving All Variables in a Dataset","text":"extract data edsurvey.data.frame, define varnames argument colnames(sdf), query variables. Setting arguments dropOmittedLevels defaultConditions FALSE ensures values normally removed included:retrieved, dataset can used EdSurvey functions.","code":"\nlsdf0 <- getData(data = sdf, varnames = colnames(sdf), addAttributes = TRUE,\n                 dropOmittedLevels = FALSE, defaultConditions = FALSE)\ndim(x = lsdf0) # excludes the one school variable in the sdf\ndim(x = sdf)"},{"path":"dataManipulation.html","id":"using-edsurvey-functions-on-a-unique-light.edsurvey.data.frame","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.5 Using EdSurvey Functions on a Unique light.edsurvey.data.frame","text":"manipulating data, can use light.edsurvey.data.frame EdSurvey function. notably, light.edsurvey.data.frame can create tables using edsurveyTable run regressions lm.sdf function.","code":""},{"path":"dataManipulation.html","id":"edsurveytable-1","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.5.1 edsurveyTable","text":"following example creates edsurveyTable using manipulated light.edsurvey.data.frame (named gddat), variables dsex b017451, five plausible values composite, default weight origwt:5Table 6.2. Using EdSurvey Functions light.edsurvey.data.frame ","code":"\ngddat <- getData(data = sdf, varnames = c(\"composite\", \"dsex\", \"b017451\",\n                                          \"c052601\",\"origwt\"), addAttributes = TRUE)\nes2 <- edsurveyTable(formula = composite ~ dsex + b017451,\n                     weightVar = \"origwt\", data = gddat)"},{"path":"dataManipulation.html","id":"lm.sdf","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.5.2 lm.sdf","text":"generate linear model using light.edsurvey.data.frame, included arguments previous example, well weight origwt, passed lm.sdf function:6Contrasts treatment groups also can omitted linear model stating variable name relevels argument. example, values dsex = \"Female\" withheld regression. Use base R function summary view details linear model.","code":"\nlm2 <- lm.sdf(formula = composite ~ dsex + b017451, weightVar = \"origwt\", data = gddat)\nsummary(object = lm2)\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17606\n#> n used: 15144\n#> \n#> Coefficients:\n#>                                  coef        se        t\n#> (Intercept)                 270.40708   1.05390 256.5768\n#> dsexFemale                   -2.92147   0.61554  -4.7462\n#> b017451Once every few weeks   4.68200   1.16792   4.0088\n#> b017451About once a week     11.57319   1.26477   9.1504\n#> b0174512 or 3 times a week   14.88024   1.23890  12.0108\n#> b017451Every day              7.93104   1.28155   6.1886\n#>                                dof  Pr(>|t|)    \n#> (Intercept)                 51.496 < 2.2e-16 ***\n#> dsexFemale                  53.963 1.565e-05 ***\n#> b017451Once every few weeks 55.188 0.0001848 ***\n#> b017451About once a week    49.005 3.519e-12 ***\n#> b0174512 or 3 times a week  77.130 < 2.2e-16 ***\n#> b017451Every day            50.501 1.074e-07 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0224\nlm3 <- lm.sdf(formula = composite ~ dsex + b017451, data = gddat,\n              relevels = list(dsex = \"Female\"))\nsummary(object = lm3)\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17606\n#> n used: 15144\n#> \n#> Coefficients:\n#>                                  coef        se        t\n#> (Intercept)                 267.48561   1.11204 240.5350\n#> dsexMale                      2.92147   0.61554   4.7462\n#> b017451Once every few weeks   4.68200   1.16792   4.0088\n#> b017451About once a week     11.57319   1.26477   9.1504\n#> b0174512 or 3 times a week   14.88024   1.23890  12.0108\n#> b017451Every day              7.93104   1.28155   6.1886\n#>                                dof  Pr(>|t|)    \n#> (Intercept)                 65.757 < 2.2e-16 ***\n#> dsexMale                    53.963 1.565e-05 ***\n#> b017451Once every few weeks 55.188 0.0001848 ***\n#> b017451About once a week    49.005 3.519e-12 ***\n#> b0174512 or 3 times a week  77.130 < 2.2e-16 ***\n#> b017451Every day            50.501 1.074e-07 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0224"},{"path":"dataManipulation.html","id":"cor.sdf","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.5.3 cor.sdf","text":"Users might want generate correlation explore manipulated light.edsurvey.data.frame. marginal correlation coefficient among plausible values subject scales subscales can calculated light.edsurvey.data.frame object eddat using cor.sdf function Pearson method. example, variable dsex == \"Female\" subsets light.edsurvey.data.frame calculate correlation subject subscales num_oper algebra using default weight origwt:7","code":"\neddat <- getData(data = sdf, varnames = c(\"num_oper\",\"algebra\",\"dsex\", 'origwt'),\n                addAttributes = TRUE, dropOmittedLevels = FALSE)\neddat <- subset(eddat,dsex == \"Female\")\ncor2 <- cor.sdf(x = \"num_oper\", y = \"algebra\", weightVar = \"origwt\",\n                data = eddat, method = \"Pearson\")\ncor2\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 8429\n#> \n#> Correlation: 0.8917132\n#> Standard Error: 0.006153243\n#> Confidence Interval: [0.8785106, 0.9035547]"},{"path":"dataManipulation.html","id":"applying-rebindattributes-to-use-edsurvey-functions-with-manipulated-data-frames-1","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.6 Applying rebindAttributes to Use EdSurvey Functions With Manipulated Data Frames","text":"helper function pairs well getData rebindAttributes. function allows users reassign attributes survey dataset data frame might attributes stripped manipulation process. attributes rebinded, variables—including outside original dataset—available use EdSurvey analytical functions.instance, sdf object contains following attributes:attributes lost variables retrieved via getData(). example, user might want run linear model using composite, default weight origwt, variable dsex, categorical variable b017451 recoded binary variable. , can return portion sdf survey data gddat object. Next, use base R function ifelse conditionally recode variable b017451 collapsing levels \"Never hardly ever\" \"every weeks\" one level (\"Rarely\") levels \"least week\"., apply rebindAttributes attribute data sdf manipulated data frame gddat. new variables now available use EdSurvey analytical functions:Additional details features getData function appear vignette titled Using getData Function EdSurvey.","code":"\nattributes(sdf)\n#> $names\n#>  [1] \"userConditions\"       \"defaultConditions\"   \n#>  [3] \"dataList\"             \"weights\"             \n#>  [5] \"pvvars\"               \"subject\"             \n#>  [7] \"year\"                 \"assessmentCode\"      \n#>  [9] \"dataType\"             \"gradeLevel\"          \n#> [11] \"achievementLevels\"    \"omittedLevels\"       \n#> [13] \"survey\"               \"country\"             \n#> [15] \"psuVar\"               \"stratumVar\"          \n#> [17] \"jkSumMultiplier\"      \"recodes\"             \n#> [19] \"dim0\"                 \"validateFactorLabels\"\n#> [21] \"cacheDataLevelName\"   \"reqDecimalConversion\"\n#> [23] \"fr2Path\"              \"dichotParamTab\"      \n#> [25] \"polyParamTab\"         \"adjustedData\"        \n#> [27] \"testData\"             \"scoreCard\"           \n#> [29] \"scoreDict\"            \"scoreFunction\"       \n#> [31] \"cache\"               \n#> \n#> $class\n#> [1] \"edsurvey.data.frame\" \"edsurvey.data\"\ngddat <- getData(data = sdf, varnames = c(\"dsex\", \"b017451\", \"origwt\", \"composite\"),\n                 dropOmittedLevels = TRUE)\ngddat$studyTalk <- ifelse(gddat$b017451 %in% c(\"Never or hardly ever\",\n                                               \"Once every few weeks\"),\n                          \"Rarely\", \"At least once a week\")\ngddat <- rebindAttributes(data = gddat, attributeData = sdf)\nlm2 <- lm.sdf(formula = composite ~ dsex + studyTalk, data = gddat)\nsummary(object = lm2)\n#> \n#> Formula: composite ~ dsex + studyTalk\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17606\n#> n used: 16331\n#> \n#> Coefficients:\n#>                      coef        se        t    dof\n#> (Intercept)     281.69030   0.96690 291.3349 39.915\n#> dsexFemale       -2.89797   0.59549  -4.8665 52.433\n#> studyTalkRarely  -9.41418   0.79620 -11.8239 53.205\n#>                  Pr(>|t|)    \n#> (Intercept)     < 2.2e-16 ***\n#> dsexFemale      1.081e-05 ***\n#> studyTalkRarely < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0168"},{"path":"dataManipulation.html","id":"important-data-manipulation-notes","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.7 Important Data Manipulation Notes","text":"","code":""},{"path":"dataManipulation.html","id":"memory-usage","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.7.1 Memory Usage","text":"many NCES databases hundreds columns millions rows, EdSurvey allows users analyze data without storing global environment. Alternatively, getData function retrieves light.edsurvey.data.frame global environment, can costlier memory usage. base R function object.size estimates memory used store R object. Computations using objects stored global environment markedly costlier memory made directly EdSurvey database:Although manipulated light.edsurvey.data.frame requires nearly 10 MB working memory store light.edsurvey.data.frame regression model object (lm7), resulting object computation made directly EdSurvey database (lm8) holds 5–7 kB. good practice remove unnecessary values saved global environment. stored many large data objects, let’s remove moving .operating systems continue hold memory usage even removing object. R clean global environment automatically, forced garbage cleanup also can employed:","code":"\nobject.size(gddat <- getData(data = sdf,\n                             varnames = c('composite', 'dsex', 'b017451', 'origwt'),\n                             addAttributes = TRUE, dropOmittedLevels = FALSE))\n#> 9675824 bytes\nobject.size(lm7 <- lm.sdf(formula = composite ~ dsex + b017451,\n                          weightVar='origwt', data = gddat))\n#> 7168568 bytes\nobject.size(lm8 <- lm.sdf(formula = composite ~ dsex + b017451,\n                          weightVar='origwt', data = sdf))\n#> 2518768 bytes\nrm(df,gddat,eddat)\n#> Warning in rm(df, gddat, eddat): object 'df' not found\ngc()"},{"path":"dataManipulation.html","id":"forgetting-to-include-a-column-variable","chapter":"6 Data Manipulation in EdSurvey and Base R","heading":"6.7.2 Forgetting to Include a Column Variable","text":"creating summary table running regression, EdSurvey give warning column missing:solution simple: Edit call getData include variable rerun linear model.","code":"\ngddat <- getData(data = sdf, \n                 varnames = c(all.vars(composite ~ lep + dsex + iep), \"origwt\"), \n                 addAttributes = TRUE, dropOmittedLevels = FALSE)\nlm9 <- lm.sdf(formula = composite ~ lep + dsex + iep + b017451, data = gddat)\n## Using default weight variable 'origwt'\n## Error in getData(sdf, c(all.vars(formula), wgt), ..., includeNaLabel = TRUE)\n  ## The following variable names are required for this call \n  ## and are not on the incoming data 'b017451'.\ngddat <- getData(data = sdf,\n                 varnames = c(all.vars(composite ~ lep + dsex + iep + b017451),\"origwt\"), \n                 addAttributes = TRUE, dropOmittedLevels = FALSE)\nlm9 <- lm.sdf(formula = composite ~ lep + dsex + iep + b017451, data = gddat)\nlm9\n#>                 (Intercept)                       lepNo \n#>                  207.356989                   35.278034 \n#>                  dsexFemale                       iepNo \n#>                   -5.285498                   36.170641 \n#> b017451Once every few weeks    b017451About once a week \n#>                    3.254744                    9.210189 \n#>  b0174512 or 3 times a week            b017451Every day \n#>                   12.659496                    6.808825"},{"path":"descriptive-statistics.html","id":"descriptive-statistics","chapter":"7 Descriptive Statistics","heading":"7 Descriptive Statistics","text":"Last edited: July 2023Suggested Citation\nBuehler, E. & Zhang, T. Descriptive Statistics. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"descriptive-statistics.html","id":"computing-the-percentages-of-students-with-achievementlevels","chapter":"7 Descriptive Statistics","heading":"7.1 Computing the Percentages of Students With achievementLevels","text":"achievementLevels function computes percentages students’ achievement levels benchmarks defined assessment, including NAEP, TIMSS, PISA. Take NAEP example: NAEP dataset’s unique set cut points achievement levels (defined Basic, Proficient, Advanced) EdSurvey. Analysts can access cut points using showCutPoints function:achievementLevels function applies appropriate weights variance estimation method edsurvey.data.frame, several arguments customizing aggregation output analysis results. Namely, using optional arguments, users can choose generate percentage students performing achievement level (discrete) achievement level (cumulative), calculate percentage distribution students achievement levels (discrete cumulative) selected characteristics (specified aggregateBy), compute percentage distribution students selected characteristics within specific achievement level.achievementLevels function can produce statistics discrete cumulative achievement levels. default, achievementLevels function produces results discrete achievement levels; setting returnCumulative argument TRUE, function generates results discrete cumulative achievement levels.compute overall results achievement levels, use NCES dataset’s default plausible values achievementVars argument; using NAEP, example, five 20 plausible values subject composite scale.next example, plausible values composite variable dsex used calculate achievement levels, aggregated variable dsex using aggregateBy.level dsex variable aggregates 100 results discrete achievement levels. object aLev1 created call achievementLevels list two data.frames: one discrete results cumulative results. previously described code, aLev1$discrete shows discrete levels. show cumulative results, change specified data.frame. example,aggregateBy argument sums percentage students discrete achievement level 100 disaggregated level specified analytical variables determines order aggregation. example, using dsex iep analysis, aggregateBy = c(\"dsex\", \"iep\") aggregateBy = c(\"iep\", \"dsex\") produce percentage arrange results different ways depending order argument. using aggregateBy = c(\"iep\", \"dsex\"), percentages add 100 within category dsex category iep, respectively:unique value pair two variables (.e., Yes + Male + Female) sums 100 aggregateBy.NOTE: appropriate aggregate results one variable one variable used analysis. variables used analysis also need used argument aggregateBy(), order can changed obtain desired results.achievementLevels function also can compute percentage students selected characteristics within specific achievement level. object aLev2 presents percentage students sex within achievement level (.e., within discrete cumulative level).percentage students within specific achievement level can aggregated one variables. example, percentage students classified English learners (lep) aggregated dsex within achievement level:Users can set unique cut points override standard values achievementLevels function using cut points argument. example follows, aLev4 uses customized cut points 267, 299, 333. object aLev1 uses standard cut points c(262, 299, 333). values Proficient Advanced unchanged across objects, whereas higher threshold reach Basic category aLev4 resulted higher percentage male female students categorized Basic.","code":"\nshowCutPoints(data = sdf)\n#> Achievement Levels:\n#>   Mathematics:  262, 299, 333\naLev0 <- achievementLevels(achievementVars = c(\"composite\"),\n                           data = sdf, returnCumulative = TRUE)\naLev0$discrete\n#>   composite_Level      N      wtdN   Percent StandardError\n#> 1     Below Basic 5731.2 5779.5052 34.132690     0.9744207\n#> 2        At Basic 6695.6 6580.2181 38.861552     0.7115633\n#> 3   At Proficient 3666.0 3694.7565 21.820549     0.6342187\n#> 4     At Advanced  822.2  877.9837  5.185209     0.4007991\naLev1 <- achievementLevels(achievementVars = c(\"composite\", \"dsex\"), aggregateBy = \"dsex\",\n                  data = sdf, returnCumulative = TRUE)\naLev1$discrete\n#>   composite_Level   dsex      N      wtdN   Percent\n#> 1     Below Basic   Male 2880.8 2865.6455 33.666050\n#> 2        At Basic   Male 3266.2 3236.4034 38.021772\n#> 3   At Proficient   Male 1877.2 1910.7861 22.448213\n#> 4     At Advanced   Male  461.8  499.1392  5.863965\n#> 5     Below Basic Female 2850.4 2913.8597 34.604399\n#> 6        At Basic Female 3429.4 3343.8146 39.710456\n#> 7   At Proficient Female 1788.8 1783.9704 21.186066\n#> 8     At Advanced Female  360.4  378.8444  4.499079\n#>   StandardError\n#> 1     1.0951825\n#> 2     0.9537470\n#> 3     0.7257305\n#> 4     0.5081607\n#> 5     1.1154848\n#> 6     0.8650729\n#> 7     0.8148916\n#> 8     0.3888590\naLev1$cumulative\n#>          composite_Level   dsex      N      wtdN   Percent\n#> 1            Below Basic   Male 2880.8 2865.6455 33.666050\n#> 2      At or Above Basic   Male 5605.2 5646.3287 66.333950\n#> 3 At or Above Proficient   Male 2339.0 2409.9253 28.312178\n#> 4            At Advanced   Male  461.8  499.1392  5.863965\n#> 5            Below Basic Female 2850.4 2913.8597 34.604399\n#> 6      At or Above Basic Female 5578.6 5506.6295 65.395601\n#> 7 At or Above Proficient Female 2149.2 2162.8149 25.685145\n#> 8            At Advanced Female  360.4  378.8444  4.499079\n#>   StandardError\n#> 1     1.0951825\n#> 2     1.0951825\n#> 3     0.8635866\n#> 4     0.5081607\n#> 5     1.1154848\n#> 6     1.1154848\n#> 7     1.0073379\n#> 8     0.3888590\nachievementLevels(achievementVars = c(\"composite\", \"dsex\", \"iep\"),\n                  aggregateBy = c(\"iep\", \"dsex\"), data = sdf)\n#> \n#> AchievementVars: composite, dsex, iep\n#> aggregateBy: iep, dsex\n#> \n#> Achievement Level Cutpoints:\n#> 262 299 333 \n#> \n#> Plausible values: 5\n#> jrrIMax: 1\n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> full data n: 17606\n#> n used: 16907\n#> \n#> \n#> Discrete\n#>  composite_Level   dsex iep      N       wtdN    Percent\n#>      Below Basic   Male Yes  810.2  753.47862 66.4635116\n#>         At Basic   Male Yes  281.6  282.52828 24.9215056\n#>    At Proficient   Male Yes   72.8   85.69544  7.5590995\n#>      At Advanced   Male Yes    9.4   11.97026  1.0558833\n#>      Below Basic Female Yes  471.2  465.33346 76.4954517\n#>         At Basic Female Yes  108.8  106.71734 17.5430994\n#>    At Proficient Female Yes   31.2   34.36986  5.6500084\n#>      At Advanced Female Yes    2.8    1.89454  0.3114405\n#>      Below Basic   Male  No 2067.6 2111.69806 28.6261355\n#>         At Basic   Male  No 2982.6 2952.86086 40.0289211\n#>    At Proficient   Male  No 1804.4 1825.09062 24.7408909\n#>      At Advanced   Male  No  452.4  487.16896  6.6040524\n#>      Below Basic Female  No 2379.0 2448.49754 31.3451478\n#>         At Basic Female  No 3318.8 3236.55190 41.4336531\n#>    At Proficient Female  No 1757.4 1749.56228 22.3975264\n#>      At Advanced Female  No  356.8  376.79678  4.8236727\n#>  StandardError\n#>      2.0061208\n#>      2.0783210\n#>      1.4614600\n#>      0.7673700\n#>      2.9245271\n#>      2.0864253\n#>      1.6430596\n#>      0.2601418\n#>      1.0630715\n#>      1.0125447\n#>      0.7840337\n#>      0.5558956\n#>      1.2051321\n#>      0.9207178\n#>      0.8954779\n#>      0.4233201\naLev2 <- achievementLevels(achievementVars = c(\"composite\", \"dsex\"),\n                           aggregateBy = \"composite\",\n                           data = sdf, returnCumulative = TRUE)\naLev2$discrete\n#>   composite_Level   dsex      N      wtdN  Percent\n#> 1     Below Basic   Male 2880.8 2865.6455 49.58289\n#> 2        At Basic   Male 3266.2 3236.4034 49.18383\n#> 3   At Proficient   Male 1877.2 1910.7861 51.71616\n#> 4     At Advanced   Male  461.8  499.1392 56.85063\n#> 5     Below Basic Female 2850.4 2913.8597 50.41711\n#> 6        At Basic Female 3429.4 3343.8146 50.81617\n#> 7   At Proficient Female 1788.8 1783.9704 48.28384\n#> 8     At Advanced Female  360.4  378.8444 43.14937\n#>   StandardError\n#> 1     0.9486797\n#> 2     0.8020508\n#> 3     1.1913055\n#> 4     2.0076502\n#> 5     0.9486797\n#> 6     0.8020508\n#> 7     1.1913055\n#> 8     2.0076502\naLev2$cumulative\n#>          composite_Level   dsex      N      wtdN  Percent\n#> 1            Below Basic   Male 2880.8 2865.6455 49.58289\n#> 2      At or Above Basic   Male 5605.2 5646.3287 50.62629\n#> 3 At or Above Proficient   Male 2339.0 2409.9253 52.70200\n#> 4            At Advanced   Male  461.8  499.1392 56.85063\n#> 5            Below Basic Female 2850.4 2913.8597 50.41711\n#> 6      At or Above Basic Female 5578.6 5506.6295 49.37371\n#> 7 At or Above Proficient Female 2149.2 2162.8149 47.29800\n#> 8            At Advanced Female  360.4  378.8444 43.14937\n#>   StandardError\n#> 1     0.9486797\n#> 2     0.6131937\n#> 3     1.0576369\n#> 4     2.0076502\n#> 5     0.9486797\n#> 6     0.6131937\n#> 7     1.0576369\n#> 8     2.0076502\naLev3 <- achievementLevels(achievementVars = c(\"composite\", \"dsex\", \"lep\"),\n                           aggregateBy = c(\"dsex\", \"composite\"),\n                           data = sdf, returnCumulative = TRUE)\naLev3$discrete\n#>    composite_Level   dsex lep      N       wtdN    Percent\n#> 1      Below Basic   Male Yes  355.8  436.03778 15.2177175\n#> 2         At Basic   Male Yes  138.4  156.75146  4.8455620\n#> 3    At Proficient   Male Yes   27.6   31.75786  1.6620312\n#> 4      At Advanced   Male Yes    1.2    0.75590  0.1514407\n#> 5      Below Basic Female Yes  334.2  422.06640 14.4853587\n#> 6         At Basic Female Yes   96.4  102.80364  3.0744683\n#> 7    At Proficient Female Yes   19.2   22.69640  1.2722408\n#> 8      At Advanced Female Yes    1.2    1.80846  0.4773622\n#> 9      Below Basic   Male  No 2523.8 2429.29192 84.7822825\n#> 10        At Basic   Male  No 3125.0 3078.19756 95.1544380\n#> 11   At Proficient   Male  No 1849.6 1879.02820 98.3379688\n#> 12     At Advanced   Male  No  460.6  498.38332 99.8485593\n#> 13     Below Basic Female  No 2515.4 2491.67850 85.5146413\n#> 14        At Basic Female  No 3332.8 3240.98230 96.9255317\n#> 15   At Proficient Female  No 1769.6 1761.27402 98.7277592\n#> 16     At Advanced Female  No  359.2  377.03598 99.5226378\n#>    StandardError\n#> 1      1.6567088\n#> 2      0.7683424\n#> 3      0.5680079\n#> 4      0.1976280\n#> 5      1.6957678\n#> 6      0.7676397\n#> 7      0.4289833\n#> 8      0.7919682\n#> 9      1.6567088\n#> 10     0.7683424\n#> 11     0.5680079\n#> 12     0.1976280\n#> 13     1.6957678\n#> 14     0.7676397\n#> 15     0.4289833\n#> 16     0.7919682\naLev3$cumulative\n#>           composite_Level   dsex lep      N       wtdN\n#> 1             Below Basic   Male Yes  355.8  436.03778\n#> 2       At or Above Basic   Male Yes  167.2  189.26522\n#> 3  At or Above Proficient   Male Yes   28.8   32.51376\n#> 4             At Advanced   Male Yes    1.2    0.75590\n#> 5             Below Basic Female Yes  334.2  422.06640\n#> 6       At or Above Basic Female Yes  116.8  127.30850\n#> 7  At or Above Proficient Female Yes   20.4   24.50486\n#> 8             At Advanced Female Yes    1.2    1.80846\n#> 9             Below Basic   Male  No 2523.8 2429.29192\n#> 10      At or Above Basic   Male  No 5435.2 5455.60908\n#> 11 At or Above Proficient   Male  No 2310.2 2377.41152\n#> 12            At Advanced   Male  No  460.6  498.38332\n#> 13            Below Basic Female  No 2515.4 2491.67850\n#> 14      At or Above Basic Female  No 5461.6 5379.29230\n#> 15 At or Above Proficient Female  No 2128.8 2138.31000\n#> 16            At Advanced Female  No  359.2  377.03598\n#>       Percent StandardError\n#> 1  15.2177175     1.6567088\n#> 2   3.3528686     0.5358274\n#> 3   1.3491605     0.4574292\n#> 4   0.1514407     0.1976280\n#> 5  14.4853587     1.6957678\n#> 6   2.3119254     0.5208317\n#> 7   1.1330078     0.4270291\n#> 8   0.4773622     0.7919682\n#> 9  84.7822825     1.6567088\n#> 10 96.6471314     0.5358274\n#> 11 98.6508395     0.4574292\n#> 12 99.8485593     0.1976280\n#> 13 85.5146413     1.6957678\n#> 14 97.6880746     0.5208317\n#> 15 98.8669922     0.4270291\n#> 16 99.5226378     0.7919682\naLev4 <- achievementLevels(achievementVars = c(\"composite\", \"dsex\"),\n                           aggregateBy = \"dsex\",\n                           data = sdf,\n                           cutpoints = c(\"Customized Basic\" = 267, \n                                         \"Customized Proficient\" = 299, \n                                         \"Customized Advanced\" = 333),\n                           returnCumulative = TRUE)\naLev4$discrete\n#>            composite_Level   dsex      N      wtdN\n#> 1   Below Customized Basic   Male 3285.0 3262.6418\n#> 2      At Customized Basic   Male 2862.0 2839.4071\n#> 3 At Customized Proficient   Male 1877.2 1910.7861\n#> 4   At Customized Advanced   Male  461.8  499.1392\n#> 5   Below Customized Basic Female 3284.8 3324.5956\n#> 6      At Customized Basic Female 2995.0 2933.0787\n#> 7 At Customized Proficient Female 1788.8 1783.9704\n#> 8   At Customized Advanced Female  360.4  378.8444\n#>     Percent StandardError\n#> 1 38.330025     1.2149501\n#> 2 33.357798     0.9636501\n#> 3 22.448213     0.7257305\n#> 4  5.863965     0.5081607\n#> 5 39.482215     1.1460243\n#> 6 34.832640     0.7304983\n#> 7 21.186066     0.8148916\n#> 8  4.499079     0.3888590\naLev1$discrete\n#>   composite_Level   dsex      N      wtdN   Percent\n#> 1     Below Basic   Male 2880.8 2865.6455 33.666050\n#> 2        At Basic   Male 3266.2 3236.4034 38.021772\n#> 3   At Proficient   Male 1877.2 1910.7861 22.448213\n#> 4     At Advanced   Male  461.8  499.1392  5.863965\n#> 5     Below Basic Female 2850.4 2913.8597 34.604399\n#> 6        At Basic Female 3429.4 3343.8146 39.710456\n#> 7   At Proficient Female 1788.8 1783.9704 21.186066\n#> 8     At Advanced Female  360.4  378.8444  4.499079\n#>   StandardError\n#> 1     1.0951825\n#> 2     0.9537470\n#> 3     0.7257305\n#> 4     0.5081607\n#> 5     1.1154848\n#> 6     0.8650729\n#> 7     0.8148916\n#> 8     0.3888590"},{"path":"descriptive-statistics.html","id":"calculating-percentiles-with-percentile","chapter":"7 Descriptive Statistics","heading":"7.2 Calculating Percentiles With percentile","text":"percentile function compares numeric vector percentiles range 0 100 data year. example, compare NAEP Primer’s subject composite scale 10th, 25th, 50th, 75th, 90th percentiles, include integers percentiles argument:","code":"\npct1 <- percentile(variable = \"composite\", percentiles = c(10, 25, 50, 75, 90), data = sdf)\npct1\n#> Percentile\n#> Call: percentile(variable = \"composite\", percentiles = c(10, 25, 50, \n#>     75, 90), data = sdf)\n#> full data n: 17606\n#> n used: 16915\n#> \n#>  percentile estimate        se       df confInt.ci_lower\n#>          10 227.7226 1.0585355 39.78256         225.2284\n#>          25 251.9626 1.0179363 42.53475         249.7120\n#>          50 277.4784 1.1375443 51.15378         275.7035\n#>          75 301.1827 0.9141083 70.56403         299.4265\n#>          90 321.9303 0.9061950 62.07559         319.9351\n#>  confInt.ci_upper\n#>          230.0172\n#>          254.0142\n#>          279.1926\n#>          302.8973\n#>          324.0329"},{"path":"descriptive-statistics.html","id":"correlating-variables-with-cor.sdf","chapter":"7 Descriptive Statistics","heading":"7.3 Correlating Variables With cor.sdf","text":"EdSurvey features multiple correlation methods data exploration analysis fully account complex sample design NCES data using cor.sdf function. features include following correlation procedures:Pearson product-moment correlations continuous variablesSpearman rank correlation ranked variablespolyserial correlations one categorical one continuous variablepolychoric correlations two categorical variablescorrelations among plausible values subject scales subscales (marginal correlation coefficients, uses Pearson type)","code":""},{"path":"descriptive-statistics.html","id":"weighted-correlations","chapter":"7 Descriptive Statistics","heading":"7.3.1 Weighted Correlations","text":"following example, b013801, t088001, full sample weight origwt read calculate correlation using Pearson method. Similar EdSurvey functions, data removed automatically memory correlation run.important note order levels ensure correlations functioning intended. Printing correlation object provide condensed summary correlation details order levels variable:Variables cor.sdf can recoded reordered. Variable levels values can redefined given desired specifications. example, b017451 t088001 correlated using Pearson method, levels \"2 3 times week\" \"Every day\" variable b017451 recoded \"Frequently\" within list lists recode argument:Recoding useful level thinly populated (might merit combination another level) changing value label something appropriate particular analysis.variables b017451 t088001 correlated using Pearson method following example, t088001’s values \"Less 3 hours\", \"3-4.9 hours\", \"5-6.9 hours\", \"7 hours \" reordered \"7 hours \", \"5-6.9 hours\", \"3-4.9 hours\", \"Less 3 hours\" \"7 hours \" lowest level list:Changing order levels might useful modify variable order reversing orientation series. reorder argument also suitable implemented conjunction recoded levels.NOTE: alternative, recoding can completed within getData. see additional examples recoding reordering, use ?cor.sdf R console.marginal correlation coefficient among plausible values subject scales subscales can calculated using cor.sdf function Pearson method. subject subscales num_oper algebra correlated example:Use showPlausibleValues function return plausible values edsurvey.data.frame calculate correlation coefficients subject scales subscales.cor.sdf function features multiple methods data exploration analysis using correlations. following example shows differences correlation coefficients among Pearson, Spearman, polychoric methods using subset edsurvey.data.frame data, dsex == 1 (saved sdf_dnf object), b017451, pared, full sample weight origwt:Plausible values subject scales subscales also can correlated variables using cor.sdf function. case, five plausible values composite, b017451, full sample weight origwt read calculate correlation coefficients using Pearson, Spearman, polyserial methods:","code":"\ncor_pearson <- cor.sdf(x = \"b013801\", y = \"t088001\", data = sdf, \n                    method = \"Pearson\", weightVar = \"origwt\")\n#> Converting \"b013801\" to a continuous variable.\n#> Converting \"t088001\" to a continuous variable.\ncor_pearson\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 14492\n#> \n#> Correlation: -0.07269657\n#> Standard Error: 0.02022161\n#> Confidence Interval: [-0.1134367, -0.03171236]\n#> \n#> Correlation Levels:\n#>   Levels for Variable 'b013801' (Lowest level first):\n#>     1. 0-10\n#>     2. 11-25\n#>     3. 26-100\n#>     4. >100\n#>   Levels for Variable 't088001' (Lowest level first):\n#>     1. Less than 3 hours\n#>     2. 3-4.9 hours\n#>     3. 5-6.9 hours\n#>     4. 7 hours or more\ncor_recode <- cor.sdf(x = \"b017451\", y = \"t088001\", data = sdf, \n                      method = \"Pearson\", weightVar = \"origwt\",\n                      recode = list(b017451 = list(from = c(\"2 or 3 times a week\", \"Every day\"),\n                                               to = c(\"Frequently\"))))\n#> Converting \"b017451\" to a continuous variable.\n#> Converting \"t088001\" to a continuous variable.\ncor_recode\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 14468\n#> \n#> Correlation: -0.01949923\n#> Standard Error: 0.01198974\n#> Confidence Interval: [-0.04386941, 0.004894141]\n#> \n#> Correlation Levels:\n#>   Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever\n#>     2. Once every few weeks\n#>     3. About once a week\n#>     4. Frequently\n#>   Levels for Variable 't088001' (Lowest level first):\n#>     1. Less than 3 hours\n#>     2. 3-4.9 hours\n#>     3. 5-6.9 hours\n#>     4. 7 hours or more\ncor_reorder <- cor.sdf(x = \"b017451\", y = \"t088001\", data = sdf, \n                       method = \"Pearson\", weightVar = \"origwt\",\n                       reorder = list(t088001 = c(\"7 hours or more\", \"5-6.9 hours\",\n                                                  \"3-4.9 hours\", \"Less than 3 hours\")))\n#> Converting \"b017451\" to a continuous variable.\n#> Converting \"t088001\" to a continuous variable.\ncor_reorder\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 14468\n#> \n#> Correlation: 0.02048827\n#> Standard Error: 0.01241005\n#> Confidence Interval: [-0.004827359, 0.04577766]\n#> \n#> Correlation Levels:\n#>   Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever\n#>     2. Once every few weeks\n#>     3. About once a week\n#>     4. 2 or 3 times a week\n#>     5. Every day\n#>   Levels for Variable 't088001' (Lowest level first):\n#>     1. 7 hours or more\n#>     2. 5-6.9 hours\n#>     3. 3-4.9 hours\n#>     4. Less than 3 hours\ncor3_mcc <- cor.sdf(x = \"num_oper\", y = \"algebra\", data = sdf, method = \"Pearson\")\ncor3_mcc\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 16915\n#> \n#> Correlation: 0.8924728\n#> Standard Error: 0.004867251\n#> Confidence Interval: [0.8822278, 0.901873]\nsdf_dnf <- subset(x = sdf, subset = dsex == 1)\ncor_pearson <- cor.sdf(x = \"b017451\", y = \"pared\", data = sdf_dnf, \n                    method = \"Pearson\", weightVar = \"origwt\")\n#> Converting \"b017451\" to a continuous variable.\n#> Converting \"pared\" to a continuous variable.\ncor_spearman <- cor.sdf(x = \"b017451\", y = \"pared\", data = sdf_dnf, \n                    method = \"Spearman\", weightVar = \"origwt\")\ncor_polychoric <- cor.sdf(x = \"b017451\", y = \"pared\", data = sdf_dnf, \n                    method = \"Polychoric\", weightVar = \"origwt\")\ncbind(Correlation = c(Pearson = cor_pearson$correlation,\n                    Spearman = cor_spearman$correlation,\n                    Polychoric = cor_polychoric$correlation))\n#>            Correlation\n#> Pearson     0.08027069\n#> Spearman    0.06655368\n#> Polychoric  0.06972564\ncor_pearson2 <- cor.sdf(x = \"composite\", y = \"b017451\", data = sdf_dnf, \n                    method = \"Pearson\", weightVar = \"origwt\")\n#> Converting \"b017451\" to a continuous variable.\ncor_spearman2 <- cor.sdf(x = \"composite\", y = \"b017451\", data = sdf_dnf, \n                    method = \"Spearman\", weightVar = \"origwt\")\ncor_polyserial2 <- cor.sdf(x = \"composite\", y = \"b017451\", data = sdf_dnf, \n                    method = \"Polyserial\", weightVar = \"origwt\")\ncbind(Correlation = c(Pearson = cor_pearson2$correlation,\n                      Spearman = cor_spearman2$correlation,\n                      Polyserial = cor_polyserial2$correlation))\n#>            Correlation\n#> Pearson      0.1031247\n#> Spearman     0.1148957\n#> Polyserial   0.1044407"},{"path":"descriptive-statistics.html","id":"unweighted-correlations","chapter":"7 Descriptive Statistics","heading":"7.3.2 Unweighted Correlations","text":"cor.sdf function also features ability perform correlations without accounting weights. cor.sdf function automatically accounts default sample weights NCES dataset read analysis weightVar = \"default\" can modified setting weightVar = NULL. following example shows correlation coefficients Pearson Spearman methods variables pared b017451 excluding weights:","code":"\ncor_pearson_unweighted <- cor.sdf(x = \"b017451\", y = \"pared\", data = sdf,\n                                  method = \"Pearson\", weightVar = NULL)\n#> Converting \"b017451\" to a continuous variable.\n#> Converting \"pared\" to a continuous variable.\ncor_pearson_unweighted\n#> Method: Pearson\n#> full data n: 17606\n#> n used: 16278\n#> \n#> Correlation: 0.05316366\n#> Standard Error: NA\n#> Confidence Interval: [NA]\n#> \n#> Correlation Levels:\n#>   Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever\n#>     2. Once every few weeks\n#>     3. About once a week\n#>     4. 2 or 3 times a week\n#>     5. Every day\n#>   Levels for Variable 'pared' (Lowest level first):\n#>     1. Did not finish H.S.\n#>     2. Graduated H.S.\n#>     3. Some ed after H.S.\n#>     4. Graduated college\n#>     5. I Don't Know\ncor_spearman_unweighted <- cor.sdf(x = \"b017451\", y = \"pared\", data = sdf,\n                                   method = \"Spearman\", weightVar = NULL)\ncor_spearman_unweighted\n#> Method: Spearman\n#> full data n: 17606\n#> n used: 16278\n#> \n#> Correlation: 0.04283483\n#> Standard Error: NA\n#> Confidence Interval: [NA]\n#> \n#> Correlation Levels:\n#>   Levels for Variable 'b017451' (Lowest level first):\n#>     1. Never or hardly ever\n#>     2. Once every few weeks\n#>     3. About once a week\n#>     4. 2 or 3 times a week\n#>     5. Every day\n#>   Levels for Variable 'pared' (Lowest level first):\n#>     1. Did not finish H.S.\n#>     2. Graduated H.S.\n#>     3. Some ed after H.S.\n#>     4. Graduated college\n#>     5. I Don't Know"},{"path":"descriptive-statistics.html","id":"preparing-an-edsurvey.data.frame.list-for-cross-datasets-comparisons","chapter":"7 Descriptive Statistics","heading":"7.4 Preparing an edsurvey.data.frame.list for Cross Datasets Comparisons","text":"Previous examples demonstrated analyses using one dataset, EdSurvey functions—including summary2, achievementLevels, percentile—support analysis multiple datasets one time edsurvey.data.frame.list. edsurvey.data.frame.list appends edsurvey.data.frame objects one list, useful looking data, example, across time geographically, reduces repetition function calls. instance, four NAEP mathematics assessments different years can combined edsurvey.data.frame.list make single call analysis functions ease use comparing, formatting, /plotting output data. Data various countries international study can integrated edsurvey.data.frame.list analysis.prepare edsurvey.data.frame.list cross datasets analysis, necessary ensure variable information consistent across edsurvey.data.frame. comparing groups across data years, uncommon variable names labels change. example, data years feature split-sample design based accommodations status, thereby containing differences frequently used demographic variables samples well across data years. Two useful functions determining inconsistencies searchSDF() levelsSDF(), return variable names, labels, levels based character string.","code":""},{"path":"descriptive-statistics.html","id":"combining-several-edsurvey.data.frame-objects-into-a-single-object","chapter":"7 Descriptive Statistics","heading":"7.4.1 Combining Several edsurvey.data.frame Objects Into a Single Object","text":"standardizing variables edsurvey.data.frame, combined edsurvey.data.frame.list ready analysis. following example, sdf subset four datasets, appended edsurvey.data.frame.list, assigned unique labels:edsurvey.data.frame.list can now analyzed EdSurvey functions.","code":"\n\n# make four subsets of sdf by a location variable-scrpsu, \"Scrambled PSU and school code\"\nsdfA <- subset(x = sdf, subset = scrpsu %in% c(5, 45, 56))\nsdfB <- subset(x = sdf, subset = scrpsu %in% c(75, 76, 78))\nsdfC <- subset(x = sdf, subset = scrpsu %in% 100:200)\nsdfD <- subset(x = sdf, subset = scrpsu %in% 201:300)\n\n#combine four datasets to an `edsurvey.data.frame.list`\nsdfl <- edsurvey.data.frame.list(datalist = list(sdfA, sdfB, sdfC, sdfD),\n                                 labels = c(\"A locations\",\"B locations\",\n                                          \"C locations\",\"D locations\"))"},{"path":"descriptive-statistics.html","id":"recommended-workflow-for-standardizing-variables-in-cross-datasets-comparisons","chapter":"7 Descriptive Statistics","heading":"7.4.2 Recommended Workflow for Standardizing Variables in Cross Datasets Comparisons","text":"Although EdSurvey features several methods resolve inconsistencies across edsurvey.data.frames, following approach recommended:Connect dataset using read function, readNAEP().Recode discrepant variable name level using recode.sdf() rename.sdf().Combine datasets one edsurvey.data.frame.list object.Analyze datasets using edsurvey.data.frame.list object.NOTE: also possible retrieve recode variables getData function; details examples method appear vignette titled Using getData Function EdSurvey.","code":""},{"path":"descriptive-statistics.html","id":"estimating-the-difference-in-two-statistics-with-gap","chapter":"7 Descriptive Statistics","heading":"7.5 Estimating the Difference in Two Statistics With gap","text":"Gap analysis term often used NAEP refers methodology estimates difference two statistics (e.g., mean scores, achievement level percentages, percentiles, student group percentages) two groups population. gap occurs one group outperforms group, difference two statistics statistically significant (.e., difference larger margin error).gap analysis can comparisonsbetween groups (e.g., male students versus female students) across years,group years (e.g., male students 2017 versus 2019), orbetween jurisdictions (e.g., two states, district versus home state, state versus national public) across years.Independent tests alpha level .05 performed types comparisons. comparisons jurisdictions, dependent test used case one jurisdiction contained another (e.g., state versus national public).typical test two statistics (e.g., two groups 2 years) time; want test , multiple comparison procedures applied conservative results. information gap analysis multiple comparison, see Drawing Inferences NAEP Results.","code":""},{"path":"descriptive-statistics.html","id":"performing-gap-analysis-and-understanding-the-summary-output","chapter":"7 Descriptive Statistics","heading":"7.5.1 Performing Gap Analysis and Understanding the Summary Output","text":"following example demonstrates gap function, comparing gender difference achievement:gap output contains three blocks: labels, percentage, results.first block, labels, shows definition groups B, along reminder full data n count (nFullData) n count number individuals two subgroups valid scores (nUsed).second block, percentage, shows percentage individuals fall category, omitted levels removed.third block, results, shows estimated outcomes two groups listed columns estimateA estimateB. diffAB column shows estimated difference two groups, diffABse column shows standard error difference. t-test significance results show difABpValue, degrees freedom following. sampling survey respondents cluster sampling designs (e.g., design involving sampling students classrooms schools), respondents common randomly selected individuals. Therefore, EdSurvey calculates covariance groups assessment sample (assessment year), appears covAB column. Even selecting respondents simple random sampling, little harm occurs estimating covariance close zero.Users can choose return data.frame detailing results using","code":"\nmathGap <- gap(variable = \"composite\", data = sdf,\n               groupA = dsex == \"Male\", groupB = dsex == \"Female\")\n\nmathGap\n#> Call: gap(variable = \"composite\", data = sdf, groupA = dsex == \"Male\", \n#>     groupB = dsex == \"Female\")\n#> \n#> Labels:\n#>  group       definition nFullData nUsed\n#>      A   dsex == \"Male\"     17606  8486\n#>      B dsex == \"Female\"     17606  8429\n#> \n#> Percentage:\n#>      pctA  pctAse  pctB  pctBse  diffAB    covAB diffABse\n#>  50.27015 0.50168 49.73 0.50168 0.54029 -0.25168   1.0034\n#>  diffABpValue  dofAB\n#>        0.5925 53.457\n#> \n#> Results:\n#>  estimateA estimateAse estimateB estimateBse diffAB   covAB\n#>   276.7235     0.82071    275.05     0.94025 1.6778 0.56766\n#>  diffABse diffABpValue dofAB\n#>   0.64987      0.01259 53.71\nmathGap$results\n#>   estimateA estimateAse estimateB estimateBse   diffAB\n#> 1  276.7235   0.8207151  275.0458   0.9402535 1.677756\n#>       covAB  diffABse diffABpValue    dofAB\n#> 1 0.5676583 0.6498719   0.01259479 53.70969"},{"path":"descriptive-statistics.html","id":"gap-analysis-across-years","chapter":"7 Descriptive Statistics","heading":"7.5.2 Gap Analysis Across Years","text":"illustration purposes, first generate two fake datasets Year 1 Year 2 use examples. can skip step already cross-year datasets handy.following example demonstrates gap function, comparing gender gap year1 year2 datasets, appended edsurvey.data.frame.list:gap output contains data.frame detailing results analyses, returned using following:data argument edsurvey.data.frame.list, summary results include following information:group means (estimateA/estimateB) standard errors (estimateAse/estimateBse) across variable (typically data years)difference values estimateA estimateB, well respective standard errors p-value (starting diffAB)difference values estimateA across variable compared reference dataset, well respective standard errors p-value (starting diffAA)difference within values estimateB across variable compared reference dataset, well respective standard errors p-value (starting diffBB)difference difference estimateA estimateB across variable compared reference dataset, well respective standard errors p-value (starting diffABAB)value sameSurvey, indicates line data output uses survey reference line (logical: TRUE/FALSE)example, mathGap2$results,gap mean mathematics scores dsex variables Year 1 (diffAB) 2.358576.gap mean mathematics scores within dsex variables across data years groupA = \"Male\" (diffAA) 0.4342073.gap mean mathematics scores within dsex variables across data years groupB = \"Female\" (diffBB) 0.5395077.gap mean mathematics scores dsex variables across data years (diffABAB) -0.1053004.addition summary results, gap output also contains data.frame percentage gaps, format matching data.frame previous results. returned using following:","code":"\nset.seed(42)\nyear1 <- EdSurvey:::copyDataToTemp(f0 = \"M32NT2PM\")\nyear2 <- EdSurvey:::copyDataToTemp(f0 = \"M40NT2PM\")\n# combine two datasets\nmathList <- edsurvey.data.frame.list(datalist = list(year1, year2),\n                                     labels = c(\"math year1\", \"math year2\"))\n# perform cross year analysis between gender\nmathGap2 <- gap(variable = \"composite\", data = mathList,\n               groupA = dsex == \"Male\", groupB = dsex == \"Female\")\nmathGap2$results\n#>       labels estimateA estimateAse estimateB estimateBse\n#> 1 math year1  277.2735    1.014495  274.9149    1.040229\n#> 2 math year2  276.8393    1.056766  274.3754    1.114861\n#>     diffAB     covAB  diffABse diffABpValue    dofAB\n#> 1 2.358576 0.3694072 1.1715210   0.05398869 27.44776\n#> 2 2.463876 0.7071580 0.9722933   0.01338217 74.24251\n#>      diffAA covAA diffAAse diffAApValue    dofAA    diffBB\n#> 1        NA    NA       NA           NA       NA        NA\n#> 2 0.4342073     0 1.464908    0.7678634 65.12246 0.5395077\n#>   covBB diffBBse diffBBpValue    dofBB   diffABAB covABAB\n#> 1    NA       NA           NA       NA         NA      NA\n#> 2     0 1.524792    0.7241024 117.9997 -0.1053004       0\n#>   diffABABse diffABABpValue  dofABAB sameSurvey\n#> 1         NA             NA       NA         NA\n#> 2   1.522437       0.945065 66.60037      FALSE\nmathGap2$percentage\n#>       labels     pctA    pctAse     pctB    pctBse\n#> 1 math year1 50.31267 0.7732424 49.68733 0.7732424\n#> 2 math year2 51.04887 0.7316137 48.95113 0.7316137\n#>      diffAB      covAB diffABse diffABpValue    dofAB\n#> 1 0.6253492 -0.5979038 1.546485    0.6884604 34.19288\n#> 2 2.0977415 -0.5352586 1.463227    0.1569309 59.25477\n#>       diffAA covAA diffAAse diffAApValue    dofAA    diffBB\n#> 1         NA    NA       NA           NA       NA        NA\n#> 2 -0.7361961     0 1.064501    0.4911036 83.97934 0.7361961\n#>   covBB diffBBse diffBBpValue    dofBB  diffABAB covABAB\n#> 1    NA       NA           NA       NA        NA      NA\n#> 2     0 1.064501    0.4911036 83.97934 -1.472392       0\n#>   diffABABse diffABABpValue  dofABAB\n#> 1         NA             NA       NA\n#> 2   2.129002      0.4911036 83.97934"},{"path":"descriptive-statistics.html","id":"gap-analysis-of-jurisdictions","chapter":"7 Descriptive Statistics","heading":"7.5.3 Gap Analysis of Jurisdictions","text":"Comparisons district, state, national jurisdictions also can performed using gap function. next example demonstrates compare multiple datasets, jurisdiction, using edsurvey.data.frame.list object sdfl, created previously representing data four locations.NAEP, jurisdiction information included single restricted-use data file. following examples illustrate, using NAEP, conduct comparisons () states, (b) state versus nation, (c) district versus home state.","code":"\nmathlocGap <- gap(variable = \"composite\", data = sdfl,\n               groupA = dsex == \"Male\", groupB = dsex == \"Female\")\n\nmathlocGap$results\n#>        labels estimateA estimateAse estimateB estimateBse\n#> 1 A locations  294.9192    6.158446  278.4914    4.998736\n#> 2 B locations  290.7389   19.347898  296.2575   18.361466\n#> 3 C locations  286.5300    3.707036  294.3619    3.838862\n#> 4 D locations  285.8196   37.473667  279.3090   17.786705\n#>      diffAB      covAB  diffABse diffABpValue    dofAB\n#> 1 16.427856  26.692493  3.086880  0.001331239 6.590889\n#> 2 -5.518624 340.429882  5.533971  0.353403676 6.678675\n#> 3 -7.831865   3.802534  4.568798  0.134082911 6.418453\n#> 4  6.510538 653.985648 20.314313  0.767500316 3.362254\n#>     diffAA      covAA  diffAAse diffAApValue    dofAA\n#> 1       NA         NA        NA           NA       NA\n#> 2 4.180366 84.7127213 15.583394    0.8012387 4.174503\n#> 3 8.389230  0.5497927  7.111187    0.2760963 7.105454\n#> 4 9.099644 -0.6240987 37.992768    0.8244191 3.404922\n#>        diffBB      covBB  diffBBse diffBBpValue     dofBB\n#> 1          NA         NA        NA           NA        NA\n#> 2 -17.7661140 59.0011184 15.624614   0.30822190  4.882245\n#> 3 -15.8704905 -0.2746742  6.346146   0.02943236 11.018163\n#> 4  -0.8176736 -0.2150138 18.487408   0.96692113  3.848665\n#>    diffABAB    covABAB diffABABse diffABABpValue  dofABAB\n#> 1        NA         NA         NA             NA       NA\n#> 2 21.946480 -5.1831666   7.107742    0.018774175 6.658063\n#> 3 24.259720 -0.2137924   5.552506    0.001956103 8.690019\n#> 4  9.917317 -2.5253958  20.670049    0.660489851 3.410698\n#>   sameSurvey\n#> 1         NA\n#> 2       TRUE\n#> 3       TRUE\n#> 4       TRUE\n# comparisons of two states\nmathStateGap <- gap(variable = \"composite\", data = mathList,\n                    fips == \"California\", fips == \"Virginia\")\n\n# comparisons of state to all public schools in nation\nmathList <- subset(mathList, schtyp2 == \"Public\")\nmathStateNationGap <- gap(variable = \"composite\", data = mathList,\n                          fips == \"California\", schtyp2 == \"Public\")\n\n# comparisons of district to state\nmathStateDistrictGap <- gap(\"composite\", data = mathList,\n                            distcod == \"Los Angeles\", fips == \"California\")"},{"path":"descriptive-statistics.html","id":"gap-analysis-of-achievement-levels-and-percentiles","chapter":"7 Descriptive Statistics","heading":"7.5.4 Gap Analysis of Achievement Levels and Percentiles","text":"Gap analysis also may performed across achievement levels percentiles specifying values achievementLevel percentiles arguments, respectively. Using previous edsurvey.data.frame.list object (mathList), setting achievementLevel=c(\"Basic\", \"Proficient\", \"Advanced\") perform comparisons groups across years achievement level value.Similarly, setting percentiles = c(10, 25, 50, 75, 90) perform comparisons groups across years percentile value.","code":"\nmathALGap <- gap(variable = \"composite\", data = mathList,\n                 groupA = dsex == \"Male\", groupB = dsex == \"Female\",\n                 achievementLevel = c(\"Basic\", \"Proficient\", \"Advanced\"))\nmathALGap$results\n#>         achievementLevel     labels estimateA estimateAse\n#> 1      At or Above Basic math year1 66.870662   1.2335219\n#> 2      At or Above Basic math year2 66.008354   1.4761274\n#> 3 At or Above Proficient math year1 28.719053   1.2778962\n#> 4 At or Above Proficient math year2 28.469990   1.0605786\n#> 5            At Advanced math year1  6.111211   0.6868165\n#> 6            At Advanced math year2  5.833023   0.7136854\n#>   estimateB estimateBse   diffAB      covAB  diffABse\n#> 1 65.100350   1.3290706 1.770311 0.47346693 1.5300559\n#> 2 64.212592   1.2702205 1.795762 0.80498819 1.4773070\n#> 3 25.546317   1.1150117 3.172735 0.16683642 1.5945522\n#> 4 25.852175   1.2256185 2.617815 0.63726122 1.1629469\n#> 5  4.509459   0.5578078 1.601751 0.09886164 0.7649465\n#> 6  4.353453   0.4823550 1.479570 0.11276154 0.7186725\n#>   diffABpValue    dofAB    diffAA covAA  diffAAse\n#> 1   0.25305547 47.43947        NA    NA        NA\n#> 2   0.22899798 58.93240 0.8623073     0 1.9236757\n#> 3   0.05430082 35.80025        NA    NA        NA\n#> 4   0.02759747 68.48216 0.2490623     0 1.6606763\n#> 5   0.04228707 42.36482        NA    NA        NA\n#> 6   0.04512671 46.64694 0.2781884     0 0.9904867\n#>   diffAApValue     dofAA     diffBB covBB  diffBBse\n#> 1           NA        NA         NA    NA        NA\n#> 2    0.6559148  49.66853  0.8877581     0 1.8384474\n#> 3           NA        NA         NA    NA        NA\n#> 4    0.8810447 115.55769 -0.3058583     0 1.6569224\n#> 5           NA        NA         NA    NA        NA\n#> 6    0.7795513  79.05949  0.1560067     0 0.7374387\n#>   diffBBpValue     dofBB    diffABAB covABAB diffABABse\n#> 1           NA        NA          NA      NA         NA\n#> 2    0.6302057 102.66886 -0.02545076       0   2.126854\n#> 3           NA        NA          NA      NA         NA\n#> 4    0.8538879 109.77788  0.55492055       0   1.973586\n#> 5           NA        NA          NA      NA         NA\n#> 6    0.8331024  66.60928  0.12218164       0   1.049587\n#>   diffABABpValue   dofABAB sameSurvey\n#> 1             NA        NA         NA\n#> 2      0.9904753 104.21223      FALSE\n#> 3             NA        NA         NA\n#> 4      0.7793705  73.18939      FALSE\n#> 5             NA        NA         NA\n#> 6      0.9075937  87.93697      FALSE\nmathPercentilesGap <- gap(variable = \"composite\", data = mathList,\n                          groupA = dsex == \"Male\", groupB = dsex == \"Female\",\n                          percentiles = c(10, 25, 50, 75, 90))\nmathPercentilesGap$results\n#>    percentiles     labels estimateA estimateAse estimateB\n#> 1           10 math year1  228.5492   0.9667854  227.0247\n#> 2           10 math year2  227.9186   2.4995864  226.2819\n#> 3           25 math year1  253.0893   0.9471983  250.9874\n#> 4           25 math year2  252.2491   1.3755823  250.0428\n#> 5           50 math year1  278.2843   1.3730106  276.9812\n#> 6           50 math year2  278.0656   1.6903894  276.3454\n#> 7           75 math year1  302.8779   1.3682276  299.6181\n#> 8           75 math year2  302.7776   0.8726368  299.9592\n#> 9           90 math year1  324.2191   1.7859545  320.1731\n#> 10          90 math year2  324.3229   1.8148749  319.6371\n#>    estimateBse   diffAB      covAB diffABse diffABpValue\n#> 1    2.2177507 1.524483 0.12874954 2.365501  0.524380292\n#> 2    2.2006815 1.636691 1.59047562 2.812469  0.567514040\n#> 3    1.5062090 2.101920 0.06906226 1.740036  0.231540228\n#> 4    1.3677150 2.206282 0.05717917 1.910108  0.253858464\n#> 5    0.9264616 1.303117 0.14110321 1.568848  0.411462617\n#> 6    1.3722702 1.720201 1.27774827 1.478190  0.250443398\n#> 7    1.1878050 3.259775 0.07671289 1.769040  0.073719644\n#> 8    1.0668784 2.818378 0.39727222 1.051275  0.009435823\n#> 9    1.2427261 4.046013 0.13587502 2.112404  0.075499842\n#> 10   1.3593064 4.685793 0.47512103 2.047252  0.026239504\n#>       dofAB     diffAA covAA diffAAse diffAApValue    dofAA\n#> 1  28.76492         NA    NA       NA           NA       NA\n#> 2  18.81623  0.6305664     0 2.680038    0.8155427 30.88172\n#> 3  63.44991         NA    NA       NA           NA       NA\n#> 4  47.38973  0.8401989     0 1.670153    0.6168345 57.62887\n#> 5  37.37699         NA    NA       NA           NA       NA\n#> 6  46.73963  0.2186734     0 2.177745    0.9203339 63.31403\n#> 7  35.58427         NA    NA       NA           NA       NA\n#> 8  60.84149  0.1002895     0 1.622819    0.9508935 72.08366\n#> 9  14.41527         NA    NA       NA           NA       NA\n#> 10 51.30331 -0.1038355     0 2.546253    0.9676270 52.23293\n#>        diffBB covBB diffBBse diffBBpValue     dofBB\n#> 1          NA    NA       NA           NA        NA\n#> 2   0.7427746     0 3.124327    0.8129968  53.19276\n#> 3          NA    NA       NA           NA        NA\n#> 4   0.9445612     0 2.034529    0.6434062 106.40957\n#> 5          NA    NA       NA           NA        NA\n#> 6   0.6357575     0 1.655735    0.7024377  56.57640\n#> 7          NA    NA       NA           NA        NA\n#> 8  -0.3411076     0 1.596593    0.8316963  49.70196\n#> 9          NA    NA       NA           NA        NA\n#> 10  0.5359443     0 1.841761    0.7717175  90.91000\n#>      diffABAB covABAB diffABABse diffABABpValue   dofABAB\n#> 1          NA      NA         NA             NA        NA\n#> 2  -0.1122082       0   3.674993      0.9757890  41.32595\n#> 3          NA      NA         NA             NA        NA\n#> 4  -0.1043623       0   2.583842      0.9678588 104.78313\n#> 5          NA      NA         NA             NA        NA\n#> 6  -0.4170841       0   2.155534      0.8470519  81.70437\n#> 7          NA      NA         NA             NA        NA\n#> 8   0.4413971       0   2.057834      0.8308790  60.72581\n#> 9          NA      NA         NA             NA        NA\n#> 10 -0.6397798       0   2.941682      0.8288465  43.44324\n#>    sameSurvey\n#> 1          NA\n#> 2       FALSE\n#> 3          NA\n#> 4       FALSE\n#> 5          NA\n#> 6       FALSE\n#> 7          NA\n#> 8       FALSE\n#> 9          NA\n#> 10      FALSE"},{"path":"descriptive-statistics.html","id":"multiple-comparisons","chapter":"7 Descriptive Statistics","heading":"7.5.5 Multiple Comparisons","text":"making groups families comparisons single analysis, comparing White students minority student groups terms test scores, probability finding significance chance least one comparison increases family size number comparisons. Multiple methods exist adjust p-values hold significance level set comparisons particular level (e.g., 0.05), adjustments called multiple comparison procedures. NAEP employs two procedures: Benjamini-Hochberg false discovery rate (FDR) procedure (Benjamini & Hochberg, 1995) Bonferroni procedure. Bonferroni procedure used prior 1996 assessment. Thereafter, NAEP used FDR procedure. detailed explanation NAEP multiple comparison procedures can found Comparison Multiple Groups.Typically, number comparisons determined number possible statistical tests single analysis. However, NAEP reports, comparing multiple years multiple jurisdictions (e.g., multiple states versus United States whole), usually neither number years number jurisdictions counts toward number comparisons.next example illustrates adjust p-values using Bonferroni FDR procedures R’s p.adjust function. First, generate gaps comparing achievement differences (\"composite\") one race/ethnicity group (case 'White') five levels sdracem.’ll append results list use -loop retrieve results data.frame gap object (levelResults1 levelResults5). clarity, ’ll also create two new variables showing comparison levels.reshaped, p-values gap result can adjusted via p.adjust(). following examples show Bonferroni FDR adjustment methods:","code":"\nlevelResults1 <- gap(variable = \"composite\", data = sdf, groupA = sdracem == \"White\",\n                     groupB = sdracem == \"Black\")\nlevelResults2 <- gap(variable = \"composite\", data = sdf, groupA = sdracem == \"White\",\n                     groupB = sdracem == \"Hispanic\")\nlevelResults3 <- gap(variable = \"composite\", data = sdf, groupA = sdracem == \"White\",\n                     groupB = sdracem == \"Asian/Pacific Island\")\nlevelResults4 <- gap(variable = \"composite\", data = sdf, groupA = sdracem == \"White\",\n                     groupB = sdracem == \"Amer Ind/Alaska Natv\")\nlevelResults5 <- gap(variable = \"composite\", data = sdf, groupA = sdracem == \"White\",\n                     groupB = sdracem == \"Other\")\nresultsList <- list(levelResults1, levelResults2, levelResults3, levelResults4, levelResults5)\n\nfullResults <- data.frame()\nfor(i in 1:length(resultsList)) {\n  fullResults <- rbind(fullResults, resultsList[[i]]$results)\n}\nfullResults$levelA <- c(\"White\")\nfullResults$levelB <- c(\"Black\", \"Hispanic\", \"Asian/Pacific Island\", \"Amer Ind/Alaska Natv\", \"Other\")\nfullResults\n#>   estimateA estimateAse estimateB estimateBse    diffAB\n#> 1   287.301   0.7991882  253.4925    1.349386 33.808504\n#> 2   287.301   0.7991882  259.8218    1.258471 27.479214\n#> 3   287.301   0.7991882  289.8092    3.290948 -2.508196\n#> 4   287.301   0.7991882  265.4023    3.630704 21.898677\n#> 5   287.301   0.7991882  281.3191    5.154681  5.981855\n#>         covAB diffABse diffABpValue    dofAB levelA\n#> 1  0.23565724 1.410046 0.000000e+00 40.83522  White\n#> 2  0.10045282 1.421811 0.000000e+00 27.01301  White\n#> 3  0.57184616 3.213308 4.473733e-01 14.78845  White\n#> 4 -0.02820715 3.725201 6.830990e-06 21.70421  White\n#> 5 -0.05243699 5.226310 2.615158e-01 29.74570  White\n#>                 levelB\n#> 1                Black\n#> 2             Hispanic\n#> 3 Asian/Pacific Island\n#> 4 Amer Ind/Alaska Natv\n#> 5                Other\nfullResults$diffABpValueBon <- p.adjust(fullResults$diffABpValue, method = \"bonferroni\")\nfullResults$diffABpValueFDR <- p.adjust(fullResults$diffABpValue, method = \"BH\")\nfullResults\n#>   estimateA estimateAse estimateB estimateBse    diffAB\n#> 1   287.301   0.7991882  253.4925    1.349386 33.808504\n#> 2   287.301   0.7991882  259.8218    1.258471 27.479214\n#> 3   287.301   0.7991882  289.8092    3.290948 -2.508196\n#> 4   287.301   0.7991882  265.4023    3.630704 21.898677\n#> 5   287.301   0.7991882  281.3191    5.154681  5.981855\n#>         covAB diffABse diffABpValue    dofAB levelA\n#> 1  0.23565724 1.410046 0.000000e+00 40.83522  White\n#> 2  0.10045282 1.421811 0.000000e+00 27.01301  White\n#> 3  0.57184616 3.213308 4.473733e-01 14.78845  White\n#> 4 -0.02820715 3.725201 6.830990e-06 21.70421  White\n#> 5 -0.05243699 5.226310 2.615158e-01 29.74570  White\n#>                 levelB diffABpValueBon diffABpValueFDR\n#> 1                Black    0.000000e+00    0.000000e+00\n#> 2             Hispanic    0.000000e+00    0.000000e+00\n#> 3 Asian/Pacific Island    1.000000e+00    4.473733e-01\n#> 4 Amer Ind/Alaska Natv    3.415495e-05    1.138498e-05\n#> 5                Other    1.000000e+00    3.268948e-01"},{"path":"models.html","id":"models","chapter":"8 Models","heading":"8 Models","text":"Last edited: November 2024Suggested Citation\nLiao, Y., Bailey, P., & Yavuz, S. Models. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"models.html","id":"regression-analysis-with-lm.sdf","chapter":"8 Models","heading":"8.1 Regression Analysis With lm.sdf","text":"data read EdSurvey package, linear model can fit fully account complex sample design used NCES data using lm.sdf.lm.sdf function allows jackknife methods (.e., JK1, JK2, BRR) Taylor series method variance estimation. default, standard error coefficient estimated jackknife replication method, users can switch Taylor series appropriate setting varMethod argument varMethod=\"Taylor\". explicit weight variable set, lm.sdf function uses default weight full sample analysis. instance, origwt default weight NAEP.data read analyzed lm.sdf function—case, dsex, b017451, five plausible values composite, full sample weight origwt. default, variance estimated using jackknife method, following call reads jackknife replicate weights:regression run, data automatically removed memory.EdSurvey drops first/lowest level default discrete predictor treats reference group—first level table, :Never hardly ever first level table omitted group regression. reference level can changed argument relevels. example, previous model. following example, reference group changed level closer middle scale: week variable b017451:coefficient dsex stayed intercept b017451 levels adjusted; expected result change predicted score model.Standardized coefficients can help interpretation can interpreted association one standard deviation increase predictor outcome, also terms standard deviations. case, one standard deviation increase , e.g. covariate b017451 level “2 3 times week” doesn’t add interpretability. , typical standardized regresion coefficient setting src=\"\", instead request coefficients show results terms standardized outcome using src=\"outcome\":results shows studnts report talking studies home 2 3 times week score 3.72 NAEP math scale score points higher report talking studies week. stdCoef column indicates score 0.046 NAEP math standard deviations higher females. p-value affected transformation can used either coefficient.","code":"\nlm1 <- lm.sdf(formula = composite ~ dsex + b017451, data = sdf)\nsummary(object = lm1)\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17600\n#> n used: 16300\n#> \n#> Coefficients:\n#>                                 coef       se        t\n#> (Intercept)                 270.4110   1.0244 263.9615\n#> dsexFemale                   -2.9590   0.6042  -4.8965\n#> b017451Once every few weeks   4.2330   1.1833   3.5777\n#> b017451About once a week     11.2260   1.2585   8.9200\n#> b0174512 or 3 times a week   14.9460   1.1866  12.5951\n#> b017451Every day              7.5300   1.3085   5.7549\n#>                                dof  Pr(>|t|)    \n#> (Intercept)                 54.670 < 2.2e-16 ***\n#> dsexFemale                  54.991 8.947e-06 ***\n#> b017451Once every few weeks 57.316 0.0007131 ***\n#> b017451About once a week    54.683 2.983e-12 ***\n#> b0174512 or 3 times a week  72.582 < 2.2e-16 ***\n#> b017451Every day            48.470 5.755e-07 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0224\ntable(sdf$b017451)\n#> \n#> Never or hardly ever Once every few weeks \n#>                 3837                 3147 \n#>    About once a week  2 or 3 times a week \n#>                 2853                 3362 \n#>            Every day              Omitted \n#>                 3132                  575 \n#>             Multiple \n#>                    9\nlm1f <- lm.sdf(formula = composite ~ dsex + b017451, data = sdf,\n               relevels = list(b017451 = \"About once a week\"))\nsummary(object = lm1f)\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17600\n#> n used: 16300\n#> \n#> Coefficients:\n#>                                 coef       se        t\n#> (Intercept)                 281.6370   1.2367 227.7378\n#> dsexFemale                   -2.9590   0.6042  -4.8965\n#> b017451Never or hardly ever -11.2260   1.2585  -8.9200\n#> b017451Once every few weeks  -6.9930   1.1800  -5.9261\n#> b0174512 or 3 times a week    3.7200   1.2526   2.9696\n#> b017451Every day             -3.6960   1.1880  -3.1111\n#>                                dof  Pr(>|t|)    \n#> (Intercept)                 51.228 < 2.2e-16 ***\n#> dsexFemale                  54.991 8.947e-06 ***\n#> b017451Never or hardly ever 54.683 2.983e-12 ***\n#> b017451Once every few weeks 62.379 1.458e-07 ***\n#> b0174512 or 3 times a week  65.850  0.004156 ** \n#> b017451Every day            60.349  0.002846 ** \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0224\nsummary(object = lm1f, src=\"outcome\")\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17600\n#> n used: 16300\n#> \n#> Coefficients:\n#>                                 coef       se        t\n#> (Intercept)                 281.6370   1.2367 227.7378\n#> dsexFemale                   -2.9590   0.6042  -4.8965\n#> b017451Never or hardly ever -11.2260   1.2585  -8.9200\n#> b017451Once every few weeks  -6.9930   1.1800  -5.9261\n#> b0174512 or 3 times a week    3.7200   1.2526   2.9696\n#> b017451Every day             -3.6960   1.1880  -3.1111\n#>                                dof   Pr(>|t|) stdCoef\n#> (Intercept)                 51.228 0.0000e+00      NA\n#> dsexFemale                  54.991 8.9474e-06  -0.081\n#> b017451Never or hardly ever 54.683 2.9833e-12  -0.309\n#> b017451Once every few weeks 62.379 1.4583e-07  -0.192\n#> b0174512 or 3 times a week  65.850 4.1563e-03   0.102\n#> b017451Every day            60.349 2.8455e-03  -0.102\n#>                              stdSE  \n#> (Intercept)                     NA  \n#> dsexFemale                  0.0166 *\n#> b017451Never or hardly ever 0.0346 *\n#> b017451Once every few weeks 0.0325 *\n#> b0174512 or 3 times a week  0.0345 *\n#> b017451Every day            0.0327 *\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0224"},{"path":"models.html","id":"calculating-multiple-comparisons-in-lm.sdf","chapter":"8 Models","heading":"8.1.1 Calculating Multiple Comparisons in lm.sdf","text":"linear model analyzed lm.sdf function—case, dsex, b017451, five plausible values composite, full sample weight origwt.Table 8.1. Coefficients p-values variables run lm1 can corrected multiple testing. Notice p-values adjusted example rows 6, 7, 8 coefficients lm1, column’s name Pr(>|t|) can extract commandHere Benjamini & Hochberg (1995) FDR adjustment used argument method = \"BH\". output displays adjusted p-values FDR adjustment:next example adjusts p-values using Bonferroni adjustment method=\"bonferroni\". shows adjusted p-values:can compare values single table \\(\\ref{tab:allp}\\)Table 8.2. Various p-values adjustments b003501 coefficients matrix also can overwritten selecting vector lm1 linear regression object, updated Bonferroni p-values:Table 8.3. Coefficients table using Bonferroni adjustment b003501 variable ","code":"\nlm1 <- lm.sdf(formula = composite ~ dsex + b003501 + b003601, data = sdf)\nsummary(object = lm1)$coefmat\n# p-values without adjustment\nsummary(object = lm1)$coefmat[6:8, \"Pr(>|t|)\"]\n#> [1] 8.666330e-02 4.083289e-05 1.035995e-02\n# Benjamini and Hochberg adjusted p-values\np.adjust(p = lm1$coefmat[6:8, \"Pr(>|t|)\"], method = \"BH\")\n#> [1] 0.0866633006 0.0001224987 0.0155399244\n# Bonferroni adjusted p-values\np.adjust(p = lm1$coefmat[6:8, \"Pr(>|t|)\"], method = \"bonferroni\")\n#> [1] 0.2599899019 0.0001224987 0.0310798488\nlm1$coefmat[6:8, \"Pr(>|t|)\"] <- p.adjust(lm1$coefmat[6:8, \"Pr(>|t|)\"], method = \"bonferroni\")\nsummary(object = lm1)$coefmat[6:8, ]"},{"path":"models.html","id":"adjusting-p-values-from-multiple-sources","chapter":"8 Models","heading":"8.1.2 Adjusting p-Values From Multiple Sources","text":"Sometimes several values must adjusted . cases, p.adjust function must called p-values researcher wishes adjust together.example, one wishes adjust values two regressions additional value another test, p-values must put single vector adjusted set. Therefore, p-value adjustments called smaller portions regressions/tests independently may return incorrect adjusted p-values result incorrect inference.example, coefficients b003501 b003601—independent regressions—well another p-value 0.02 adjusted.code careful note values came help avoid transcription errors. pvalues object populated using p-values coefficients lm2a lm2b linear regression objects, rows 1–3 4–6 , respectively.additional p-value due adjustment included row 7:Table 8.4. Unadjusted p-values Now aforementioned p-values included vector, adjusted via p.adjust using Benjamini Hochberg method:Table 8.5. Adjusted p-values NOTE: EdSurvey package produces p-values based assumption tests independent unassociated ; yet assumption always valid. Several possible methods developed dealing multiple hypothesis testing problem.","code":"\nlm2a <- lm.sdf(formula = composite ~ dsex + b003501, data = sdf)\nlm2b <- lm.sdf(formula = composite ~ dsex + b003601, data = sdf)\n# pvalues data.frame with missing values\n# values of coef that are not in this initial call but will be added\npvalues <- data.frame(source=c(rep(\"lm2a\",3), rep(\"lm2b\",3), \"otherp\"),\n                      coef=rep(\"\",7),\n                      p=rep(NA,7),\n                      stringsAsFactors=FALSE)\n# load in values from lm2a\nlm2aCoef <- summary(object = lm2a)$coefmat\npvalues$p[1:3] <- lm2aCoef[3:5,5]\npvalues$coef[1:3] <- row.names(lm2aCoef)[3:5]\n# load in values from lm2b\nlm2bCoef <- summary(object = lm2b)$coefmat\npvalues$p[4:6] <- lm2bCoef[3:5,5]\npvalues$coef[4:6] <- row.names(lm2aCoef)[3:5]\n# load in other p-value\npvalues$p[7] <- 0.02\ncolnames(pvalues)[3] <- \"Pr(>|t|)\"\n# check matrix\npvalues\npvalues[,\"Adjusted Pr(>|t|)\"] <- p.adjust(p = pvalues[,\"Pr(>|t|)\"], method = \"BH\")\npvalues"},{"path":"models.html","id":"multivariate-regression-with-mvrlm.sdf","chapter":"8 Models","heading":"8.2 Multivariate Regression With mvrlm.sdf","text":"multivariate regression model can fit fully account complex sample design used NCES data using mvrlm.sdf. function implements estimator correctly handles multiple dependent variables continuous (plausible values), allows variance estimation using jackknife replication method.vertical line symbol | separates dependent variables left-hand side formula. following example, multivariate regression fit two subject scales outcome variables (algebra geometry) two predictor variables signifying gender survey item concerning ability identify best unit area (dsex m072801):mvrlm.sdf documentation provides examples compare regression outputs. See ?mvrlm.sdf overview additional details can accessed components returned object. addition, vignette titled Statistical Methods Used EdSurvey goes detail describing estimation reported statistics.","code":"\nmvrlm1 <- mvrlm.sdf(algebra | geometry ~ dsex + m072801, data = sdf)\nsummary(object = mvrlm1)\n#> \n#> Formula: algebra | geometry ~ dsex + m072801\n#> \n#> jrrIMax: \n#> Weight variable: 'origwt'\n#> Variance method: \n#> JK replicates: 62\n#> full data n: 17600\n#> n used: 16900\n#> \n#> Coefficients:\n#> \n#> algebra \n#>                        coef       se        t    dof\n#> (Intercept)        258.6000   2.3782 108.7357 42.830\n#> dsexFemale           6.4920   1.5177   4.2777 52.594\n#> m072801B *          24.7390   2.2301  11.0934 67.824\n#> m072801C            11.6810   2.9777   3.9228 64.728\n#> m072801D           -12.8870   6.5688  -1.9619 12.101\n#> m072801E             1.9870   5.3819   0.3693 21.258\n#> m072801Omitted      -5.3110   9.4365  -0.5628 24.518\n#> m072801Not Reached -33.4930  17.4425  -1.9202 10.866\n#>                     Pr(>|t|)    \n#> (Intercept)        < 2.2e-16 ***\n#> dsexFemale         8.001e-05 ***\n#> m072801B *         < 2.2e-16 ***\n#> m072801C           0.0002143 ***\n#> m072801D           0.0731901 .  \n#> m072801E           0.7155757    \n#> m072801Omitted     0.5786675    \n#> m072801Not Reached 0.0814534 .  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> geometry \n#>                        coef       se        t    dof\n#> (Intercept)        255.5010   2.3672 107.9322 33.772\n#> dsexFemale           5.1590   1.5762   3.2728 36.308\n#> m072801B *          22.3460   2.2124  10.1004 57.151\n#> m072801C             8.8090   3.6470   2.4154 51.207\n#> m072801D            -9.2610   5.8778  -1.5756 12.865\n#> m072801E            -0.1750   5.9198  -0.0295 23.927\n#> m072801Omitted      -4.7140   7.3458  -0.6417 25.505\n#> m072801Not Reached -31.7660  23.8885  -1.3298  5.130\n#>                     Pr(>|t|)    \n#> (Intercept)        < 2.2e-16 ***\n#> dsexFemale          0.002341 ** \n#> m072801B *         2.531e-14 ***\n#> m072801C            0.019324 *  \n#> m072801D            0.139370    \n#> m072801E            0.976677    \n#> m072801Omitted      0.526790    \n#> m072801Not Reached  0.239653    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual correlation matrix:\n#> \n#>          algebra geometry\n#> algebra    1.000    0.849\n#> geometry   0.849    1.000\n#> \n#> Multiple R-squared by dependent variable: \n#> \n#>  algebra geometry \n#>   0.0944   0.0882"},{"path":"models.html","id":"logistic-regression-analysis-with-glm.sdf-logit.sdf-and-probit.sdf","chapter":"8 Models","heading":"8.3 Logistic Regression Analysis With glm.sdf, logit.sdf, and probit.sdf","text":"logistic regression model can fit fully account complex sample design used NCES data using glm.sdf, logit.sdf, probit.sdf. functions predict binary outcomes set predictor variables factoring appropriate weights variance estimates. glm.sdf umbrella function currently fits logit probit models. Alternatively, users can choose logit.sdf probit.sdf functions binomial outcomes.following example demonstrates use logit.sdf predict number books home student gender. example arguments generalizable glm.sdf probit.sdf. information use latter two functions, check help files calling ?glm.sdf ?probit.sdf, respectively.logit.sdf, although variables might already binary, function () dichotomize nonbinary variable specify desired outcome level. logistic regression can run exploring association gender (dsex) outcome variable: number books home (b013801), dichotomized level matching “100 books home” (\">100\") outcome level:log odds 100 books home (versus less equal 100 books) increases 0.178274 female students compared male students.Logistic regression results can interpreted assistance oddsRatio waldTest functions.","code":"\nlogit1 <- logit.sdf(formula = I(b013801 %in% \">100\") ~ dsex,\n                    weightVar = 'origwt', data = sdf)\nsummary(object = logit1)\n#> \n#> Formula: b013801 ~ dsex\n#> Family: binomial (logit)\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> full data n: 17600\n#> n used: 16400\n#> \n#> Coefficients:\n#>                 coef       se        t    dof  Pr(>|t|)    \n#> (Intercept)  -0.9200   0.0464 -19.8558 60.635 < 2.2e-16 ***\n#> dsexFemale    0.1780   0.0501   3.5563 54.578 0.0007863 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"models.html","id":"recovering-odds-ratios","chapter":"8 Models","heading":"8.3.1 Recovering Odds Ratios","text":"oddsRatio helper function converts coefficients EdSurvey logit regression model odds ratios. Odds ratios useful understanding real likelihood event occurring based transformation log odds returned logistic model.EdSurvey, odds ratios can returned specifying logistic model object (logit1).odds 100 books home (versus less equal 100 books) increases 1.1951531 female students compared male students.","code":"\noddsRatio(model = logit1)\n#>                    OR      2.5%     97.5%\n#> (Intercept) 0.3983511 0.3630823 0.4370459\n#> dsexFemale  1.1951531 1.0809029 1.3214796"},{"path":"models.html","id":"wald-tests","chapter":"8 Models","heading":"8.3.2 Wald Tests","text":"waldTest function allows user test composite hypotheses—multiple coefficients involved—even data include plausible values. likelihood test plausible values residuals large-scale assessment data analysis, Wald test fills role likelihood ratio test, analysis variance, F-test.Wald tests can run specifying model coefficients. second coefficient logit1 model object (Female) tested following example:learn conducting Wald tests, consult vignette titled Methods Overview Using EdSurvey Running Wald Tests.","code":"\nwaldTest(model = logit1, coefficients = 2)\n#> Wald test:\n#> ----------\n#> H0:\n#> dsexFemale = 0\n#> \n#> Chi-square test:\n#> X2 = 12.6, df = 1, P(> X2) = 0.00038\n#> \n#> F test:\n#> W = 12.6, df1 = 1, df2 = 62, P(> W) = 0.00073"},{"path":"models.html","id":"using-plausible-values-as-a-predictor","chapter":"8 Models","heading":"8.3.3 Using Plausible Values as a Predictor","text":"research questions, set plausible values, represents students’ achievement subject scale subscale can used predictor. feature enabled generalized linear regression (glm.sdf, logit.sdf, probit.sdf) linear regression (lm.sdf). methodology regression models documented [Chapter 11, Statistical Methodology][methods]. subchapter explain use feature linear generalized linear regressions.","code":""},{"path":"models.html","id":"using-plausible-values-as-a-predictor-for-generalized-linear-regression","chapter":"8 Models","heading":"8.3.3.1 Using Plausible Values as a Predictor for Generalized Linear Regression","text":"section, show examples using logit.sdf. example, demonstrate exploration analysis research question “students’ algebra achievement associated students’ current enrollment algebra class (Algebra Algebra II)?” 2005 NAEP Primer, “Math class taking now” variable variable name m815701 sdf object. useful look raw frequency table see levels approximate distribution table function.One way run analyses research question interest create new variable indicating student taking “Algebra (1-yr crs),” “1st yr 2-yr Algeb ,” “2nd yr 2-yr Algeb ,” “Algebra II.” following code uses ifelse function create new variable called AlgebraClass sdf object, assigning value 1 m815701 column contains Algebra II classes mentioned 0 otherwise. Note multiple categories “Algebra ,” included following code:ifelse function converts multiple Algebra class categories 1 coding categories 0, including Multiple Omitted. following code provides frequencies category newly created AlgebraClass variable actual variable NAEP 2005 Primer.creating AlgebraClass variable, logit.sdf function can used answer research question “students’ algebra achievement associated students currently enrollment algebra class (Algebra Algebra II)”? context, AlgebraClass outcome variable algebra achievement—represented algebra subscale sdf object—predictor. algebra subscale includes multiple plausible values. logit.sdf function runs analyses plausible value, combines according Rubin’s rules (Rubin, 1987) provides final results. logit.sdf function, like glm.sdf, probit.sdf, lm.sdf functions, also accepts subscales composite scales. can use showPlausibleValues function find name subject scale subscales sdf object.following code demonstrates use plausible values predictor answer research question interest:running logistic regression, EdSurvey package, default, uses listwise deletion special values, including missing values Multiple Omitted categories. change setting, set dropOmittedLevels = FALSE recode another category. case, special values converted 0 ifelse function. AlgebraClass variable already created binary variable, default logit.sdf models likelihood highest category (.e., level 1: taking one algebra classes). Additionally, created AlgebraClass variable certain condition (.e., 1 taking one algebra classes 0 taking one algebra classes), 0 condition contains Multiple Omitted categories well. According logistic regression results, changes algebra achievement significantly associated likelihood enrollment Algebra II classes (versus taking , taking another math class, selecting multiple responses, omitting question). one-unit increase algebra score associated increase log odds Algebra class 0.0160. First, using summary2 get summary statistics NAEP algebra scores,user can find modeled probability student took Algebra class mean one standard deviation mean relatively easily.shows student mean algebra score 278.94 predicted enrolled algebra class probability 36% student one standard devation higher score 315.6 predicted enrilled algebra class 51% time.","code":"\ntable(sdf$m815701)\n#> \n#>             Geometry           Algebra II \n#>                  588                  589 \n#> Algebra I (1-yr crs)  1st yr 2-yr Algeb I \n#>                 4567                  471 \n#>  2nd yr 2-yr Algeb I  Int algeb,pre-algeb \n#>                  254                 4406 \n#>  Basic,gen gr 8 math Integrat or seq math \n#>                 4175                  277 \n#>     Other math class              Omitted \n#>                  824                  659 \n#>             Multiple \n#>                  105\nsdf$AlgebraClass <- ifelse(sdf$m815701 %in% c('Algebra I (1-yr crs)', '1st yr 2-yr Algeb I', '2nd yr 2-yr Algeb I', 'Algebra II'), 1, 0)\ntable(sdf$m815701,sdf$AlgebraClass,  useNA = \"ifany\")\n#>                       \n#>                           0    1\n#>   Geometry              588    0\n#>   Algebra II              0  589\n#>   Algebra I (1-yr crs)    0 4567\n#>   1st yr 2-yr Algeb I     0  471\n#>   2nd yr 2-yr Algeb I     0  254\n#>   Int algeb,pre-algeb  4406    0\n#>   Basic,gen gr 8 math  4175    0\n#>   Integrat or seq math  277    0\n#>   Other math class      824    0\n#>   Omitted               659    0\n#>   Multiple              105    0\nlogit2 <- logit.sdf(formula = AlgebraClass ~ algebra,\n                    weightVar = 'origwt', data = sdf)\nsummary(object = logit2)\n#> \n#> Formula: AlgebraClass ~ algebra\n#> Family: binomial (logit)\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> full data n: 17600\n#> n used: 16900\n#> \n#> Coefficients:\n#>                 coef       se        t    dof  Pr(>|t|)    \n#> (Intercept)  -5.1640   0.4050 -12.7492 48.046 < 2.2e-16 ***\n#> algebra       0.0160   0.0014  11.8882 49.207 4.441e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsalg <- summary2(\"algebra\", data=sdf, weightVar=\"origwt\")\nsalg\n#> Estimates are weighted using the weight variable 'origwt'\n#>   Variable     N Weighted N    Min.  1st Qu.  Median\n#> 1  algebra 16900      16900 109.842 254.7982 279.832\n#>       Mean  3rd Qu.    Max.       SD NA's Zero weights\n#> 1 278.9366 304.0186 412.152 36.65571    0            0\nmean_alg <- salg$summary$Mean\nsd_alg <- salg$summary$SD\nmean_pred <- data.frame(algebra=c(mean_alg, # a student with mean algebra score\n                                  mean_alg + sd_alg)) # a student with algebra 1 SD above the mean\nround(100 * # multiply by 100 to make the 0-1 outcome into a percentage on 0-100\n      predict(logit2, # predict with the logit2 model that was fit above\n              newdata=mean_pred, # predict at these levels\n              type=\"response\")) # predict in the 0-1 space\n#>   [,1]\n#> 1   36\n#> 2   51"},{"path":"models.html","id":"using-plausible-values-as-a-predictor-for-linear-regression","chapter":"8 Models","heading":"8.3.3.2 Using Plausible Values as a Predictor for Linear Regression","text":"section explains provides examples cases outcome variable continuous predictor scale subscale. lm.sdf function can used perform analyses. example, lm.sdf can applied address research question “students’ performance geometry relate achievement algebra?” algebra geometry mathematics subscales within sdf object. following call performs linear regression analysis geometry subscale predictor:lm.sdf function can also applied analyze cases outcome variable Likert scale, treat continuous variable example. Let’s consider scenario goal investigate relationship students’ effort math test overall math achievement. research question guiding analysis “students’ overall academic performance predict effort math test?” address , use lm.sdf function, outcome variable Likert scale measuring effort math test (m815501) predictor math composite scale.running analyses lm.sdf function, need ensure categories ordered meaningfully Omitted Multiple categories converted NA. First, check category order using levelsSDF function:output shows, categories range 1 4, representing responses Tried hard Tried much harder. reordering necessary, Multiple Omitted categories must converted NA, numeric codes (8 0, respectively) distort linear regression results. following code converts m815501 numeric variable recodes 0 8 NA:preparing variable, can apply lm.sdf run linear regression model:analysis shows mathematics composite scale score statistically significant predictor effort math test. coefficient negative, indicating higher scoring students tend report lower effort math test. R-squared value 0.02, meaning model explains 2% variance m815501 variable.can also visually inspect fitted values observed values. following code extracts fitted values lm5 model, removes plausible values students missing m815501, creates plot first plausible value, listwise-deleted m815501_numeric, fitted values:Figure 1 provides visual comparison fitted values linear model observed student effort test. figure uses jittered dots show students distributed across effort categories. blue dots represent individual student effort scores, red line indicates fitted values calculated linear model. line slight downward slope, consistent negative coefficient composite variable regression output. suggests students higher mathematics composite scores tend report slightly lower effort math test.","code":"\nlm3 <- lm.sdf(formula = algebra ~ geometry, data = sdf)\nsummary(lm3)\n#> \n#> Formula: algebra ~ geometry\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17600\n#> n used: 16900\n#> \n#> Coefficients:\n#>                coef      se       t    dof  Pr(>|t|)    \n#> (Intercept) 27.1500  2.7556  9.8528 49.373 3.026e-13 ***\n#> geometry     0.9220  0.0099 93.0226 53.519 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.7459\nlevelsSDF(\"m815501\", sdf)\n#> Levels for Variable 'm815501' (Lowest level first):\n#>     1. Tried not as hard (n = 4000)\n#>     2. Tried about as hard (n = 8500)\n#>     3. Tried harder (n = 2300)\n#>     4. Tried much harder (n = 1100)\n#>     8. Omitted* (n = 990)\n#>     0. Multiple* (n = 0)\n#>     NOTE: * indicates an omitted level.\nsdf$m815501_numeric <- as.numeric(sdf$m815501)\nsdf$m815501_numeric <- ifelse(sdf$m815501_numeric  %in% c(0,8), NA,  sdf$m815501_numeric)\nrequire(\"tidyEdSurvey\") # needed to use with() on the next line\nwith(sdf, table(m815501, m815501_numeric))\n#>                      m815501_numeric\n#> m815501                  1    2    3    4\n#>   Tried not as hard   3970    0    0    0\n#>   Tried about as hard    0 8543    0    0\n#>   Tried harder           0    0 2277    0\n#>   Tried much harder      0    0    0 1129\n#>   Omitted                0    0    0    0\n#>   Multiple               0    0    0    0\nlm5 <- lm.sdf(formula = m815501_numeric  ~ composite, data = sdf) \nsummary(lm5) \n#> \n#> Formula: m815501_numeric ~ composite\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> full data n: 17600\n#> n used: 15900\n#> \n#> Coefficients:\n#>                coef      se       t    dof  Pr(>|t|)    \n#> (Intercept)  2.8900  0.0689  41.938 56.558 < 2.2e-16 ***\n#> composite   -0.0030  0.0002 -12.614 55.118 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0195\n# Extract fitted values\nfittedValues <- lm5$fitted.values\n \n# Remove composite plausible values for the missing students on the m815501 variable\nnoNA_mrpcm1 <- sdf$mrpcm1[!is.na(sdf$m815501_numeric)]\nplotData <- data.frame(noNA_mrpcm1, m815501_numeric = na.omit(sdf$m815501_numeric), fittedValues)\n \n# Create the plot using ggplot2\nggplot(plotData, aes(x = noNA_mrpcm1, y = m815501_numeric)) +\n  geom_point(position = position_jitter(width = 0.2), color = \"blue\", size = .3) +  # Adding jitter to the points\n  geom_line(aes(y = fittedValues), color = \"red\", linewidth = 1) +  # Line with fitted values\n  labs(\n    title = \"Figure 1\",\n    x = \"Plausible value 1\",  # Category label for the x-axis\n    y = \"Effort on this test\"   # Category label for the y-axis\n  ) +\n  theme_minimal()"},{"path":"models.html","id":"quantile-regression-analysis-with-rq.sdf","chapter":"8 Models","heading":"8.4 Quantile Regression Analysis with rq.sdf","text":"rq.sdf function computes estimate tau-th conditional quantile function response, given covariates, specified formula argument. Similar lm.sdf, function presumes linear specification quantile regression model (.e., formula defines model linear parameter). Jackknife applicable variance estimation method used function.conduct quantile regression given tau value (default, tau set 0.5), specify using tau argument (example tau = 0.8); arguments otherwise consistent lm.sdf, except returnVarEstInputs, returnNumberOfPSU, standardizeWithSamplingVar, available.details quantile regression models implemented R, see vignette quantreg package (accessible vignette(\"rq\", package=\"quantreg\")), rq.sdf function built (Koenker, 2024).","code":"\nrq1 <- rq.sdf(composite ~ dsex + b017451, data=sdf, tau = 0.8)\nsummary(object = rq1)\n#> \n#> Formula: composite ~ dsex + b017451\n#> \n#> tau: 0.8\n#> jrrIMax: 1\n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> full data n: 17600\n#> n used: 16300\n#> \n#> Coefficients:\n#>                                 coef       se        t\n#> (Intercept)                 299.7680   1.8103 165.5883\n#> dsexFemale                   -4.6280   1.2908  -3.5852\n#> b017451Once every few weeks   6.5880   1.9086   3.4518\n#> b017451About once a week     12.4800   2.2959   5.4359\n#> b0174512 or 3 times a week   16.5420   2.4616   6.7201\n#> b017451Every day             12.7420   1.6932   7.5253\n#>                                dof  Pr(>|t|)    \n#> (Intercept)                 29.388 < 2.2e-16 ***\n#> dsexFemale                  58.617 0.0006868 ***\n#> b017451Once every few weeks 46.045 0.0012041 ** \n#> b017451About once a week    67.782 8.032e-07 ***\n#> b0174512 or 3 times a week  29.867 1.943e-07 ***\n#> b017451Every day            50.342 8.717e-10 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"models.html","id":"mixed-models-with-mixed.sdf","chapter":"8 Models","heading":"8.5 Mixed Models With mixed.sdf","text":"EdSurvey features functionality estimating mixed-effects models accounting plausible values survey weights. EdSurvey fits weighted mixed model, also known weighted multilevel hierarchical linear model using WeMix package.example illustrates user might implement student-level weighting using survey (NAEP example) weighting scheme previously implemented.following two examples illustrate model random intercept mathematics achievement school level students’ gender covariate, using TIMSS 2015 datasets.guidance use cases mixed-effects models EdSurvey, see vignette titled Methods Used Estimating Mixed-Effects Models EdSurvey. examples NCES recommends using weighted mixed-effects models, well summary mathematical background description insufficiency hierarchical linear models case, see Appendix D NCES working paper analysis TIMSS data Using TIMSS Analyze Correlates Performance Variation Mathematics.","code":"\n# Subset data to a sample of interest\nsdf2 <- subset(x = sdf, subset = scrpsu < 500)\n\n# Extract variables of interest to a light.edsurvey.data.frame\nlsdf <- getData(sdf2, c(\"composite\",\"dsex\",\"b017451\",\"scrpsu\",\"origwt\",\"smsrswt\"),\n                addAttributes=TRUE)\n\n# Transform weights using your method (Note that this method is not recommended for NAEP)\nlsdf$pwt1 <- lsdf$origwt/lsdf$smsrswt\nlsdf$pwt2 <- lsdf$smsrswt\n\nm1 <- mixed.sdf(composite ~ dsex + b017451 + (1|scrpsu), data=lsdf,\n                weightVar = c('pwt1', 'pwt2'))\nsummary(object = m1)\n#> Call:\n#> mixed.sdf(formula = composite ~ dsex + b017451 + (1 | scrpsu), \n#>     data = lsdf, weightVars = c(\"pwt1\", \"pwt2\"))\n#> \n#> Formula: composite ~ dsex + b017451 + (1 | scrpsu)\n#> \n#> Plausible Values: 5\n#> Number of Groups:\n#>  Level  Group n size mean wgt sum wgt\n#>      2 scrpsu      0        0       0\n#>      1    Obs    490        0     790\n#> \n#> Variance terms:\n#>  Level    Group        Name Variance Std. Error Std.Dev.\n#>      2   scrpsu (Intercept)    558.6     204.64    23.64\n#>      1 Residual                876.8      74.69    29.61\n#> \n#> Fixed Effects:\n#>                             Estimate Std. Error t value\n#> (Intercept)                  266.795      8.200  32.537\n#> dsexFemale                    -1.179      2.998  -0.393\n#> b017451Once every few weeks    2.173      6.954   0.312\n#> b017451About once a week       9.809      4.472   2.193\n#> b0174512 or 3 times a week    10.863      6.098   1.781\n#> b017451Every day               6.792      7.365   0.922\n#> \n#> Intraclass Correlation= 0.389\n\n#Use all plausible values\nTIMSS15USA<- readTIMSS(file.path(edsurveyHome, \"TIMSS/2015\"), countries = c(\"usa\"), gradeLvl = \"4\")\n#> Found cached Grade 4 data for country code \"usa: United States\".\n#> edsurvey.data.frame data level detail:\n#> |---DataLevel----|----Rows----|--Columns---|---MergeType----|-------MatchedRecords-------|-OK-|\n#> |Student         |       10029|        1196|                |*base level*                | ✓  |\n#> |>School         |       10029|         101|many:one        |10029 of 10029              | ✓  |\n#> |>Teacher        |       12119|         745|one:many        |12119 of 12119              | ✓  |\nmix1 <- mixed.sdf(mmat ~ itsex + (1|idschool), data = TIMSS15USA,\n                  weightVar=c(\"totwgt\",\"schwgt\"), weightTransformation=FALSE)\nsummary(object = mix1)\n#> Call:\n#> mixed.sdf(formula = mmat ~ itsex + (1 | idschool), data = TIMSS15USA, \n#>     weightVars = c(\"totwgt\", \"schwgt\"), weightTransformation = FALSE)\n#> \n#> Formula: mmat ~ itsex + (1 | idschool)\n#> \n#> Plausible Values: 5\n#> Number of Groups:\n#>  Level    Group n size mean wgt sum wgt\n#>      2 idschool    250      260   64000\n#>      1      Obs  10000      370 3757000\n#> \n#> Variance terms:\n#>  Level    Group        Name Variance Std. Error Std.Dev.\n#>      2 idschool (Intercept)     1758      173.7    41.93\n#>      1 Residual                 4672      105.3    68.35\n#> \n#> Fixed Effects:\n#>             Estimate Std. Error t value\n#> (Intercept)  536.042      3.767 142.288\n#> itsexMALE      6.091      1.500   4.061\n#> \n#> Intraclass Correlation= 0.273\n# uses only one plausible value\nmix2 <- mixed.sdf(asmmat01 ~ itsex + (1|idschool), data = TIMSS15USA,\n                  weightVar=c(\"totwgt\",\"schwgt\"), weightTransformation=FALSE)\nsummary(object = mix2)\n#> Call:\n#> mixed.sdf(formula = asmmat01 ~ itsex + (1 | idschool), data = TIMSS15USA, \n#>     weightVars = c(\"totwgt\", \"schwgt\"), weightTransformation = FALSE)\n#> \n#> Formula: asmmat01 ~ itsex + (1 | idschool)\n#> Number of Groups:\n#>  Level    Group n size mean wgt sum wgt\n#>      2 idschool    250      260   64000\n#>      1      Obs  10000      370 3757000\n#> \n#> Variance terms:\n#>  Level    Group        Name Variance Std. Error Std.Dev.\n#>      2 idschool (Intercept)     1713      173.7    41.39\n#>      1 Residual                 4658      105.3    68.25\n#> \n#> Fixed Effects:\n#>             Estimate Std. Error t value\n#> (Intercept)  536.847      3.668 146.349\n#> itsexMALE      5.726      1.442   3.972\n#> \n#> lnl=-21290221.51\n#> Intraclass Correlation= 0.269"},{"path":"analysisOutsideEdSurvey.html","id":"analysisOutsideEdSurvey","chapter":"9 Analysis Outside EdSurvey","heading":"9 Analysis Outside EdSurvey","text":"Last edited: July 2023Suggested Citation\nLee, M. Analysis Outside EdSurvey. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.EdSurvey gives users functions efficiently analyze education survey data. Although EdSurvey allows rudimentary data manipulation analysis, chapter discuss integrate R packages EdSurvey. chapter demonstrate, functionality especially useful data processing manipulation popular R packages dplyr.","code":""},{"path":"analysisOutsideEdSurvey.html","id":"integration-with-any-other-package","chapter":"9 Analysis Outside EdSurvey","heading":"9.1 Integration With Any Other Package","text":"calling function getData(), one can extract light.edsurvey.data.frame: data.frame-like object containing requested variables, weights, weight’s associated replicate weights. light.edsurvey.data.frame can manipulated data.frame objects also used packaged EdSurvey functions. noted Chapter 6, setting arguments dropOmittedLevels defaultConditions FALSE ensures values normally removed included. argument addAttributes = TRUE ensures extraction necessary survey design attributes, including replicate weights, PSU variables, strata variables.base R function gsub allows users substitute one string another. following step recodes “Every day” “Seven days week”. head function reveals first 6 values recoded variable b017451 accessed $ operator:manipulating data, can use light.edsurvey.data.frame EdSurvey function. shown previous example, retrieving dataset, can used R package functions, occasionally one might encounter errors. helper function circumvent errors rebindAttributes.","code":"\nlibrary(EdSurvey)\n#> Loading required package: car\n#> Loading required package: carData\n#> Loading required package: lfactors\n#> lfactors v1.0.4\n#> Loading required package: Dire\n#> Dire v2.2.0\n#> EdSurvey v4.0.8\nsdf <- readNAEP(path = system.file(\"extdata/data\", \"M36NT2PM.dat\", package = \"NAEPprimer\"))\ngddat <- getData(data = sdf, varnames = c('composite', 'dsex', 'b017451', 'origwt'),\n                addAttributes = TRUE, dropOmittedLevels = FALSE)\n# 1. Recode a Column Based on a String\n\ngddat$b017451 <- gsub(pattern = \"Every day\", replacement = \"Seven days a week\",\n                      x = gddat$b017451)\nhead(x = gddat$b017451)\n#> [1] \"Seven days a week\"    \"About once a week\"   \n#> [3] \"Seven days a week\"    \"Seven days a week\"   \n#> [5] \"Once every few weeks\" \"2 or 3 times a week\""},{"path":"analysisOutsideEdSurvey.html","id":"applying-rebindattributes-to-use-edsurvey-functions-with-manipulated-data-frames-2","chapter":"9 Analysis Outside EdSurvey","heading":"9.2 Applying rebindAttributes to Use EdSurvey Functions With Manipulated Data Frames","text":"rebindAttributes function allows users reassign survey data attributes required EdSurvey data frame might attributes stripped manipulation process. rebinding attributes, variables—including outside original dataset—available EdSurvey analytical functions.example, user might want run linear model using composite, default weight origwt, variable dsex, categorical variable b017451 recoded binary variable. , can return portion sdf survey data gddat object. Next, use base R function ifelse conditionally recode variable b017451 collapsing levels \"Never hardly ever\" \"every weeks\" one level (\"Rarely\") levels \"least week\"., apply rebindAttributes attribute data sdf manipulated data frame gddat. new variables now available use EdSurvey analytical functions:","code":"\ngddat <- getData(data = sdf, varnames = c(\"dsex\", \"b017451\", \"origwt\", \"composite\"),\n                 dropOmittedLevels = TRUE)\ngddat$studyTalk <- ifelse(gddat$b017451 %in% c(\"Never or hardly ever\",\n                                               \"Once every few weeks\"),\n                          \"Rarely\", \"At least once a week\")\ngddat <- rebindAttributes(data = gddat, attributeData = sdf)\nlm2 <- lm.sdf(formula = composite ~ dsex + studyTalk, data = gddat)\nsummary(object = lm2)\n#> \n#> Formula: composite ~ dsex + studyTalk\n#> \n#> Weight variable: 'origwt'\n#> Variance method: jackknife\n#> JK replicates: 62\n#> Plausible values: 5\n#> jrrIMax: 1\n#> full data n: 17606\n#> n used: 16331\n#> \n#> Coefficients:\n#>                      coef        se        t    dof\n#> (Intercept)     281.69030   0.96690 291.3349 39.915\n#> dsexFemale       -2.89797   0.59549  -4.8665 52.433\n#> studyTalkRarely  -9.41418   0.79620 -11.8239 53.205\n#>                  Pr(>|t|)    \n#> (Intercept)     < 2.2e-16 ***\n#> dsexFemale      1.081e-05 ***\n#> studyTalkRarely < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0168"},{"path":"analysisOutsideEdSurvey.html","id":"integration-with-dplyr","chapter":"9 Analysis Outside EdSurvey","heading":"9.3 Integration With dplyr","text":"One popular package data manipulation R ecosystem dplyr. Given ubiquity, merits noting common errors one might encounter performing analyses using EdSurvey together dplyr.Let’s say user interested predicting often student talks studies home based gender disability status. following example demonstrates predict whether student talks studies home (b017451) based sex (dsex) whether individualized education plan (iep) using weight origwt. dependent variable b017451 specified using outcome level regression (b017451 == \"Never hardly ever\"):dplyr function unite() takes multiple variables concatenates , similar base R function paste0(). %>% (pipe) operator allows object passed forward another function call.attempt run logistic regression, EdSurvey returns error locate survey weights data frame. creating new variable, EdSurvey can longer access survey attributes needed complete analysis. remedy, apply rebindAttributes attribute data sdf manipulated data frame gddat:functions, rowwise(), group_by(), ungroup() silently override class light.edsurvey.data.frame, causing attributes inaccessible. following example, use mutate() create new variable mrpcmAverage calculates mean row’s plausible values:function rebindAttributes()reapplies survey attributes prepares data use EdSurvey analysis functions.","code":"\nlibrary(dplyr)\nlibrary(tidyr)\ngddat <- getData(data = sdf, varnames = c(\"dsex\", \"b017451\", \"iep\", \"lep\", \"origwt\", \"composite\"),\n                 addAttributes = TRUE, dropOmittedLevels = TRUE)\n# Unite columns \ngddat <- gddat %>% unite(col = \"combinedVar\", dsex, iep, sep = \"_\")\ntable(gddat$combinedVar)\n#> \n#>  Female_No Female_Yes    Male_No   Male_Yes \n#>       7574        590       7044       1113\n# Specify level in I()\nlogit1 <- logit.sdf(formula = I(b017451 == \"Never or hardly ever\") ~ combinedVar,\n                    data = gddat)\n#> Error in checkDataClass(data, c(\"edsurvey.data.frame\", \"light.edsurvey.data.frame\", : The argument 'data' must be an edsurvey.data.frame, a light.edsurvey.data.frame, or an edsurvey.data.frame.list. See \"Using the 'EdSurvey' Package's getData Function to Manipulate the NAEP Primer Data vignette\" for how to work with data in a light.edsurvey.data.frame.\ngddat <- rebindAttributes(data = gddat, attributeData = sdf)\nlogit1 <- logit.sdf(formula = I(b017451 ==\"Never or hardly ever\") ~ combinedVar,\n                    data = gddat)\ngddat <- getData(data = sdf,\n                 varnames = c(\"dsex\", \"b017451\", \"iep\", \"lep\", \"origwt\", \"composite\"),\n                 addAttributes = TRUE, dropOmittedLevels = TRUE)\ngddat <- gddat %>%        \n  rowwise() %>% \n  mutate(mrpcmAverage = mean(c(mrpcm1, mrpcm2, mrpcm3, mrpcm4, mrpcm5), na.rm = TRUE))\nclass(gddat)\n#> [1] \"rowwise_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\ngddat <- rebindAttributes(data = gddat, attributeData = sdf)\nclass(gddat)\n#> [1] \"light.edsurvey.data.frame\" \"data.frame\""},{"path":"longitudinal-datasets.html","id":"longitudinal-datasets","chapter":"10 Longitudinal Datasets","heading":"10 Longitudinal Datasets","text":"Last edited: July 2023Suggested Citation\nLee, M. Longitudinal Datasets. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.Data large-scale educational assessment programs require special statistical methods analysis. scope complexity, EdSurvey gives users functions perform analyses account complex sample survey designs. chapter provides analysis guidelines tips apply NCES longitudinal data, using Early Childhood Longitudinal Study, Kindergarten Class 2010–11 (ECLS-K:2011) example data.","code":""},{"path":"longitudinal-datasets.html","id":"using-edsurvey-to-access-ecls-k2011-data-for-analysis","chapter":"10 Longitudinal Datasets","heading":"10.1 Using EdSurvey to Access ECLS-K:2011 Data for Analysis","text":"Refer Chapter 4 download read specific longitudinal dataset interest. following example shows download ECLS-K:2011 Kindergarten–Fifth Grade public-use data file:load ECLS-K:2011 data fifth graders create edsurvey.data.frame, select pathway ECLS-K:2011 data folder assign name eclsk11 call:function may take several minutes run first time; subsequent calls readECLS_K2011 stored user’s drive easy access near instant retrieval. read , users can analyze merge data ECLS-K:2011 dataset loading data R working environment.","code":"\ndownloadECLS_K(years = 2011, root = \"C:/\", cache=FALSE)\neclsk11 <- readECLS_K2011(\"C:/ECLS_K/2011\")"},{"path":"longitudinal-datasets.html","id":"retrieving-survey-weights","chapter":"10 Longitudinal Datasets","heading":"10.2 Retrieving Survey Weights","text":"variables associated survey weights can seen showWeights functions, respectively, setting verbose argument TRUE.version, (lengthy) results shown, user can easily see results running code. Selecting survey weights especially important ECLS-K ECLS-K:2011. selected, users can specify survey weight using weightVar argument EdSurvey analytical functions.learn selecting sample weights analyses using ECLS:K-2011 data, consult Calculation Use Sample Weights section Public-Use Data File User’s Manuals respective public-use file interest. ECLS-K:2011 Kindergarten–Fifth Grade User’s Manual, Public Version relevant K–5 data used chapter. Alternative releases NCES site: ECLS-K:2011 Public-Use Data File User’s Manuals.","code":"\nshowWeights(data = eclsk11, verbose = TRUE)"},{"path":"longitudinal-datasets.html","id":"retrieving-stratum-and-psu-variables","chapter":"10 Longitudinal Datasets","heading":"10.3 Retrieving Stratum and PSU Variables","text":"functions getStratumVar getPSUVar return default stratum variable name PSU variable associated weight variable. ECLS-K:2011 default weights, users need specify weight return associated psu/stratum variables. example, total student weight ninth round weightVar = \"w9c29p_9a0\" returns following:arguments quite useful accessing variables associated weights longitudinal surveys.","code":"\ngetStratumVar(data = eclsk11, weightVar = \"w9c29p_9a0\")\n#> [1] \"w9c29p_9astr\"\ngetPSUVar(data = eclsk11, weightVar = \"w9c29p_9a0\")\n#> [1] \"w9c29p_9apsu\""},{"path":"longitudinal-datasets.html","id":"recoding-data","chapter":"10 Longitudinal Datasets","heading":"10.4 Recoding Data","text":"Data recoding especially important performing analyses ECLS:K-2011 data. default, EdSurvey omits special values, multiple entries, skipped values, NAs. Typically, setting helps users dropping levels factors typically included regressions, tables, correlations, analyses. ECLS:K-2011, default setting requires careful consideration. many instances user keep special values analyses; cases, recoding data advised.ECLS:K-2011, special codes used indicate item nonresponse, legitimate skips, unit nonresponse.Table 10.1. Missing value codes used ECLS-K:2011 data file method recoding values appears later chapter Recoding Variables Dataset Retrieving Data Manipulation getData section chapter.","code":""},{"path":"longitudinal-datasets.html","id":"removing-special-values","chapter":"10 Longitudinal Datasets","heading":"10.5 Removing Special Values","text":"EdSurvey uses listwise deletion remove special values analyses default, detailed Table 10.1. use different method, set dropOmittedLevels = FALSE running analysis. can remove levels want remove call subset, discussed “Subsetting Data” section Chapter 3.","code":""},{"path":"longitudinal-datasets.html","id":"explore-variable-distributions-with-summary2-1","chapter":"10 Longitudinal Datasets","heading":"10.6 Explore Variable Distributions With summary2","text":"summary2 function produces weighted unweighted descriptive statistics variable. functionality quite useful gathering response information survey variables conducting data exploration. default, estimates weighted. example, variable x9povty_i (“Imputed poverty level”) returns following output:default, summary2 function includes omitted levels; remove , set dropOmittedLevels = TRUE:summary2 function returns weighted number cases, weighted percentage, weighted standard error categorical variable specified argument weightVar, using total student weight 9th round weightVar = \"w9c29p_9a0\":","code":"\nsummary2(data = eclsk11, variable = \"x9povty_i\")\n#> Estimates are not weighted.\n#>                                                                  x9povty_i\n#> 1                                               1: BELOW POVERTY THRESHOLD\n#> 2 2: AT OR ABOVE POVERTY THRESHOLD, BELOW 200 PERCENT OF POVERTY THRESHOLD\n#> 3                          3: AT OR ABOVE 200 PERCENT OF POVERTY THRESHOLD\n#> 4                                                                     <NA>\n#>      N  Percent\n#> 1 2185 12.02267\n#> 2 2226 12.24827\n#> 3 5809 31.96324\n#> 4 7954 43.76582\nsummary2(data = eclsk11, variable = \"x9povty_i\", dropOmittedLevels = TRUE)\n#> Estimates are not weighted.\n#>                                                                  x9povty_i\n#> 1                                               1: BELOW POVERTY THRESHOLD\n#> 2 2: AT OR ABOVE POVERTY THRESHOLD, BELOW 200 PERCENT OF POVERTY THRESHOLD\n#> 3                          3: AT OR ABOVE 200 PERCENT OF POVERTY THRESHOLD\n#>      N  Percent\n#> 1 2185 21.37965\n#> 2 2226 21.78082\n#> 3 5809 56.83953\nsummary2(data = eclsk11, variable = \"x9povty_i\", weightVar = \"w9c29p_9a0\")\n#> Warning in calcEdsurveyTable(formula, data, weightVar,\n#> jrrIMax, pctAggregationLevel, : Removing 9632 rows with 0\n#> weight from analysis.\n#> Estimates are weighted using the weight variable 'w9c29p_9a0'\n#>                                                                  x9povty_i\n#> 1                                               1: BELOW POVERTY THRESHOLD\n#> 2 2: AT OR ABOVE POVERTY THRESHOLD, BELOW 200 PERCENT OF POVERTY THRESHOLD\n#> 3                          3: AT OR ABOVE 200 PERCENT OF POVERTY THRESHOLD\n#>      N Weighted N Weighted Percent Weighted Percent SE\n#> 1 1720     887797         22.28798           0.9054683\n#> 2 1823     936566         23.51232           0.6704569\n#> 3 4999    2158936         54.19970           1.0531340"},{"path":"longitudinal-datasets.html","id":"retrieving-data-for-further-manipulation-with-getdata-2","chapter":"10 Longitudinal Datasets","heading":"10.7 Retrieving Data for Further Manipulation With getData","text":"","code":""},{"path":"longitudinal-datasets.html","id":"retrieving-a-set-of-variables-in-a-dataset","chapter":"10 Longitudinal Datasets","heading":"10.7.1 Retrieving a Set of Variables in a Dataset","text":"Although EdSurvey allows rudimentary data manipulation analysis directly edsurvey.data.frame connection, function getData() can extract dataset variables manipulation analyses data.frame objects. object—referred light.edsurvey.data.frame—can used packaged EdSurvey analytical functions.Variables extracted edsurvey.data.frame returned light.edsurvey.data.frame specifying set variable names varnames entering formula formula.8To access manipulate data x_chsex_r (“Sex students”), weight variable w5cf5pf_50, p5sumsch (“Child attended summer school”), p5nhrprm (“Hours per day child attended summer school”) variables eclsk11, call getData.default, setting dropOmittedLevels TRUE removes special values, multiple entries NAs. getData tries help dropping levels factors regression, tables, correlations typically included analyses. set dropOmittedLevels FALSE recode special values example follows.argument addAttributes = TRUE ensures analysis functions shown far can continue used resulting dataset: gddat.","code":"\ngddat <- getData(data = eclsk11, varnames = c(\"x_chsex_r\", \"w5cf5pf_50\", \"x12sesl\",\n                                              \"p5sumsch\", \"p5nhrprm\"), \n                                 dropOmittedLevels = FALSE, addAttributes = TRUE)"},{"path":"longitudinal-datasets.html","id":"retrieving-all-variables-in-a-dataset-1","chapter":"10 Longitudinal Datasets","heading":"10.7.2 Retrieving All Variables in a Dataset","text":"extract data edsurvey.data.frame, define varnames argument names(eclsk11), query variables. Setting argument dropOmittedLevels = FALSE ensures values normally removed included:Additional details features getData function appear vignette titled Using getData Function EdSurvey.","code":"\nlsdf0 <- getData(data = eclsk11, varnames = colnames(eclsk11), addAttributes = TRUE,\n                 dropOmittedLevels = FALSE)\ndim(x = lsdf0) \ndim(x = eclsk11)"},{"path":"longitudinal-datasets.html","id":"recodingVariables","chapter":"10 Longitudinal Datasets","heading":"10.7.3 Recoding Variables in a Dataset","text":"mentioned earlier, data recoding particular importance performing analyses ECLS:K-2011 data given complexity survey design dataset. EdSurvey offers methods recoding data fit needs.Let’s suppose desire explore student performance mathematics based number hours/day parent reported child attended summer school (p5nhrprm). ’d first need recode variable students attend summer school (p5sumsch coded 2: ) included analytic subset 0 minutes.table function simple method ascertaining number values level variable dataset. Using table function p5nhrprm variable indicates parents reported child attending summer school anywhere 2 7 hours per day:include children attended summer school 0 hours per day—skipped design survey—recode p5nhrprm values zero p5sumsch == \"2: \":Alternatively, demonstration purposes, researcher also may choose recode -1 values p5nhrprm variable directly:second example recoding variable response skip pattern pertains frequency () child homework (variable p9hmwork) (b) parent/someone else helps (variable p9hlphwk). levelsSDF function useful show variable’s levels unweighted n sizes.skip pattern sequence survey questions follows: p9hmwork == \"1: NEVER\" p9hlphwk skipped coded \"-1: APPLICABLE\". include subset data analysis, variable p9hlphwk can recoded 0. First, retrieve data via getData (along variables subsequent example) recode using ifelse:use table view counts level.Now 294 cases variable mvData$p9hmwork == \"1: NEVER\" included level recoded mvData$p9hlphwk.recoding steps, appropriate value levels can included dataset preparation analysis EdSurvey. find information special values specific ECLS-K:2011, consult Missing Values section ECLS-K:2011 Public-Use Data File User’s Manual.","code":"\ntable(gddat$p5nhrprm,useNA = \"ifany\")\n#> \n#>     2     3     4     5     6     7  <NA> \n#>    55    72   126    43    87    62 17729\ngddat$p5nhrprm <- ifelse(gddat$p5sumsch == \"2: NO\", 0, gddat$p5nhrprm)\ntable(gddat$p5nhrprm,useNA = \"ifany\")\n#> \n#>     0     2     3     4     5     6     7  <NA> \n#>  3913    55    72   126    43    87    62 13816\ngddat$p5nhrprm <- ifelse(gddat$p5nhrprm == \"-1: NOT APPLICABLE*\", 0, gddat$p5nhrprm)\ntable(gddat$p5nhrprm,useNA = \"ifany\")\n#> \n#>     0     2     3     4     5     6     7  <NA> \n#>  3913    55    72   126    43    87    62 13816\nlevelsSDF(\"p9hmwork\",eclsk11)\n#> Levels for Variable 'p9hmwork' (Lowest level first):\n#>     1. 1: NEVER (n = 294)\n#>     2. 2: LESS THAN ONCE A WEEK (n = 381)\n#>     3. 3: 1 TO 2 TIMES A WEEK (n = 1406)\n#>     4. 4: 3 TO 4 TIMES A WEEK (n = 4236)\n#>     5. 5: 5 OR MORE TIMES A WEEK (n = 3838)\n#>     -1. -1: NOT APPLICABLE* (n = 51)\n#>     -7. -7: REFUSED* (n = 1)\n#>     -8. -8: DON'T KNOW* (n = 13)\n#>     -9. -9: NOT ASCERTAINED* (n = 0)\n#>     NOTE: * indicates an omitted level.\nlevelsSDF(\"p9hlphwk\",eclsk11)\n#> Levels for Variable 'p9hlphwk' (Lowest level first):\n#>     1. 1: NEVER (n = 643)\n#>     2. 2: LESS THAN ONCE A WEEK (n = 1786)\n#>     3. 3: 1 TO 2 TIMES A WEEK (n = 3774)\n#>     4. 4: 3 TO 4 TIMES A WEEK (n = 2558)\n#>     5. 5: 5 OR MORE TIMES A WEEK (n = 1094)\n#>     -1. -1: NOT APPLICABLE* (n = 359)\n#>     -7. -7: REFUSED* (n = 2)\n#>     -8. -8: DON'T KNOW* (n = 4)\n#>     -9. -9: NOT ASCERTAINED* (n = 0)\n#>     NOTE: * indicates an omitted level.\nmvData <- getData(data = eclsk11, varnames = c(\"p9hmwork\", \"p9hlphwk\", \"x_chsex_r\",\n                                              \"x9rscalk5\", \"x9mscalk5\", \"w9c29p_9t90\"), \n                                 dropOmittedLevels = FALSE, addAttributes = TRUE)\nmvData$p9hlphwk <- ifelse(mvData$p9hmwork == \"1: NEVER\" &\n                          mvData$p9hlphwk == \"-1: NOT APPLICABLE\", 0,\n                          mvData$p9hlphwk)\ntable(mvData$p9hlphwk,useNA = \"ifany\")\n#> \n#>    0    1    2    3    4    5    6    7    8 <NA> \n#>  294  643 1786 3774 2558 1094   65    2    4 7954"},{"path":"longitudinal-datasets.html","id":"applying-rebindattributes-to-use-edsurvey-functions-with-manipulated-data-frames-3","chapter":"10 Longitudinal Datasets","heading":"10.7.3.1 Applying rebindAttributes to Use EdSurvey Functions With Manipulated Data Frames","text":"helper function pairs well getData rebindAttributes. function allows users reassign attributes survey dataset data frame might attributes stripped manipulation process. rebinding attributes, variables—including outside original dataset—available use EdSurvey analytical functions.p9hlphwk variable Recoding Variables Dataset section chapter recoded using ifelse function; therefore, following example display apply survey attributes object analysis.Using mvData object created earlier, apply rebindAttributes attribute data eclsk11 manipulated data frame mvData. new variables now available EdSurvey analytical functions:information rebindAttributes function available Chapter 9.","code":"\nmvData <- rebindAttributes(data = mvData, attributeData = eclsk11)\nlm2 <- lm.sdf(formula = x9rscalk5 ~ x_chsex_r + p9hlphwk, data = mvData,\n              weightVar = \"w9c29p_9t90\")\n#> Removing 1422 rows with nonpositive weight from analysis.\nsummary(object = lm2)\n#> \n#> Formula: x9rscalk5 ~ x_chsex_r + p9hlphwk\n#> \n#> Weight variable: 'w9c29p_9t90'\n#> Variance method: jackknife\n#> JK replicates: 80\n#> full data n: 18174\n#> n used: 7906\n#> \n#> Coefficients:\n#>                         coef        se        t    dof\n#> (Intercept)        142.46410   0.74660 190.8168 67.852\n#> x_chsex_r2: FEMALE   1.44536   0.38854   3.7200 46.223\n#> p9hlphwk            -2.11562   0.21672  -9.7619 54.904\n#>                     Pr(>|t|)    \n#> (Intercept)        < 2.2e-16 ***\n#> x_chsex_r2: FEMALE 0.0005384 ***\n#> p9hlphwk           1.338e-13 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Multiple R-squared: 0.0284"},{"path":"longitudinal-datasets.html","id":"making-a-table-with-edsurveytable","chapter":"10 Longitudinal Datasets","heading":"10.8 Making a Table With edsurveyTable","text":"Summary tables can created EdSurvey using edsurveyTable function. call edsurveyTable9 two variables, x_chsex_r (“Sex students”) p9curmar (“Current marital status”), creates table shows number percentage students gender parent’s current marital status. Percentages add 100 within gender.edsurveyTable saved object es1, resulting table can displayed printing object:Table 10.2. Weighted Unweighted Sample Size, Percentage\nDistribution, Standard Error Percentage Distribution\nChildren Students’ Gender Parents’ Marital Status Given previous analysis uses parent data Round 9, weight variable \"w9c29p_9a0\" also might appropriate. \"w9c29p_9t90\" \"w9c29p_9a0\" used analysis, although include nonresponse adjustments additional data components rounds data collection interest current analysis. Therefore, analysts need determine weight prefer use weight adjusts nonresponse sources used analysis. Successive analyses chapter mix Round 9 child parent variables might substitute selected weight chosen. Note slight differences *n* used results. Consult 4.3.1 Types Sample Weights section ECLS-K:2011 Kindergarten–Fifth Grade User’s Manual, Public Version additional guidance choosing appropriate sample weight analysis.Table 10.3. Weighted Unweighted Sample Size, Percentage\nDistribution, Standard Error Percentage Distribution \nChildren Students’ Gender Parents’ Marital Status—Using Parent Weights function also features variance estimation setting varMethod argument.10 shown previous example, default varMethod = \"jackknife\" indicates call used jackknife method variance estimation. setting varMethod = \"Taylor\", edsurveyTable call previous example can return results using Taylor series variance estimation:Table 10.4. Weighted Unweighted Sample Size, Percentage Distribution, Standard Error Percentage Distribution Children Students’ Gender Parents’ Marital Status—Taylor Series percentages add 100 desired level, adjust pctAggregationLevel argument change aggregation level. default, pctAggregationLevel = 1, indicating formula aggregated level first variable call; previous example, x_chsex_r. Setting pctAggregationLevel = 0 aggregates level variable call.calculation means standard errors requires computation time user may want wait . wish simply see table levels N sizes, set returnMeans returnSepct arguments FALSE omit columns follows:edsurveyTable, resulting table can displayed printing object:Table 10.5. Weighted Unweighted Sample Size Percentage Distribution Children Students’ Gender Parents’ Marital Status details arguments edsurveyTable function, look examples using ?edsurveyTable.","code":"\nes1 <- edsurveyTable(formula = ~ x_chsex_r + p9curmar, data = eclsk11,\n                     weightVar = \"w9c29p_9t90\",\n                     varMethod = \"jackknife\")\n#> Warning in calcEdsurveyTable(formula, data, weightVar,\n#> jrrIMax, pctAggregationLevel, : Removing 2251 rows with 0\n#> weight from analysis.\nes1p <- edsurveyTable(formula = ~ x_chsex_r + p9curmar, data = eclsk11,\n                     weightVar = \"w9c29p_9a0\",\n                     varMethod = \"jackknife\")\n#> Warning in calcEdsurveyTable(formula, data, weightVar,\n#> jrrIMax, pctAggregationLevel, : Removing 1673 rows with 0\n#> weight from analysis.\nes1t <- edsurveyTable(formula = ~ x_chsex_r + p9curmar, data = eclsk11,\n                      weightVar = \"w9c29p_9t90\",\n                      varMethod = \"Taylor\")\n#> Warning in calcEdsurveyTable(formula, data, weightVar,\n#> jrrIMax, pctAggregationLevel, : Removing 2251 rows with 0\n#> weight from analysis.\nes1b <- edsurveyTable(formula = ~ x_chsex_r + p9curmar, data = eclsk11,\n                      weightVar = \"w9c29p_9t90\", jrrIMax = Inf,\n                      returnMeans = FALSE, returnSepct = FALSE)"},{"path":"methods.html","id":"methods","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11 Statistical Methods Used in EdSurvey","text":"Last edited: June 2024Suggested Citation\nBailey, P., Cohen, M., & Yavuz, S. Statistical Methods Used EdSurvey. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"methods.html","id":"introduction-1","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.1 Introduction","text":"chapter describes estimation procedures EdSurvey. includes estimation means (including regression analysis), percentages, degrees freedom; estimation weighted mixed models plausible values; multivariate regression method; Wald test. estimation correlation coefficients appears vignette wCorr package.11Which estimation procedure used statistic appears Help file function creates statistic. example, find estimation procedure used standard error regression coefficients, use ?lm.sdf see manual entry.chapter uses many symbols; table symbols follows reference. Terms used defined immediately equations, appear table.remainder chapter describes estimation procedures used EdSurvey. Sections organized follows:estimation meansestimation percentagesthe methods weighted mixed models plausible valuesthe methods multivariate multiple regressionthe Wald test methodEach section starts describing estimation statistic, followed estimation procedures variances statistic. Separate sections address situations plausible values present situations plausible values present. sections variance estimation, separate sections address jackknife Taylor series variance estimators.NAEP surveys linking error relevant, alternative methodology calculating standard errors used. methodology applies variables end _linking example, composite_linking. NAEP linking error methods, see next chapter. methods detailed chapter.","code":""},{"path":"methods.html","id":"estimation-of-weighted-means-and-regression-coefficients","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2 Estimation of Weighted Means and Regression Coefficients","text":"section concerns estimation means, including regression coefficients standard errors means regression coefficients.","code":""},{"path":"methods.html","id":"estimation-of-weighted-means-when-plausible-values-are-not-present","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.1 Estimation of Weighted Means When Plausible Values Are Not Present","text":"Weighted means estimated according \n\\[\\begin{align}\n\\mu_x = \\frac{\\sum_{=1}^n w_i x_i}{\\sum_{=1}^n w_i}\n\\end{align}\\]\n\\(x_i\\) \\(w_i\\) outcome weight, respectively, \\(\\)th unit, \\(n\\) total number units sample.regressions form\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{y}}=\\boldsymbol{\\mathbf{X\\beta}} + \\boldsymbol{\\mathbf{\\epsilon}}\n\\end{align}\\]\nweighted regression used estimated coefficients (\\(\\boldsymbol{\\mathbf{\\beta}}\\)) minimize weighted square residuals:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{\\beta}} = \\mathrm{ArgMin}_{\\boldsymbol{\\mathbf{b}}} \\sum_{=1}^n w_i (y_i-\\boldsymbol{\\mathbf{X}}_i \\boldsymbol{\\mathbf{b}})^2\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{X}}_i\\) \\(\\)th row \\(\\boldsymbol{\\mathbf{X}}\\), \\(\\mathrm{ArgMin}_{\\boldsymbol{\\mathbf{b}}}\\) means value \\(\\boldsymbol{\\mathbf{b}}\\) minimizes expression follows .","code":""},{"path":"methods.html","id":"estimation-of-weighted-means-when-plausible-values-are-present","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.2 Estimation of Weighted Means When Plausible Values Are Present","text":"variable \\(x\\) plausible values, form mean estimate (\\(\\mu\\)) according \n\\[\\begin{align}\n\\mu = \\frac{1}{m} \\sum_{p=1}^{m} \\frac{\\sum_{=1}^n w_i x_{ip}}{\\sum_{=1}^n w_i}\n\\end{align}\\]\n\\(x_{ip}\\) \\(p\\)th plausible value \\(\\)th unit’s outcome, \\(m\\) plausible values unit.regressions, coefficient estimates simply averaged plausible values,\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{\\beta}} = \\frac{1}{m} \\sum_{p=1}^{m} \\boldsymbol{\\mathbf{\\beta}}_p\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{\\beta}}_p\\) vector estimated regression coefficients, calculated using \\(p\\)th set plausible values.","code":""},{"path":"methods.html","id":"estimation-of-regression-coefficients-when-plausible-values-are-used-as-a-predictor","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.3 Estimation of Regression Coefficients when Plausible Values are Used as a Predictor","text":"lm.sdf accepts subscale subject scales left-hand side regression equation, described . section explains lm.sdf glm.sdf handle plausible values right hand side regression equation. section, describe outcome plausible values .Let dependent variable \\(y\\), \\(y_{ip}\\) \\(p\\)th plausible value \\(\\)th unit \\(m\\) plausible values unit. Similarly, let independent variable \\(x\\) scale subscale \\(x_{ip}\\) \\(p\\)th plausible value \\(\\)th unit. linear regression equation \\[\\begin{align}\n\\boldsymbol{\\mathbf{y}} = \\beta_0 + \\beta_1 \\boldsymbol{\\mathbf{x}}  + \\epsilon  \n\\end{align}\\]\\(\\beta_0\\) intercept \\(\\beta_1\\) coefficient \\(x\\), \\(y\\) \\(x\\) \\(m\\) plausible values. Therefore regression performed \\(m\\) times follows\\[\\begin{align}\n\\begin{split}\n\\boldsymbol{\\mathbf{y}}_{1} = \\beta_{0,1} + \\beta_{1,1} \\boldsymbol{\\mathbf{x}}_{1}  + \\epsilon_1 \\\\\n\\boldsymbol{\\mathbf{y}}_{2} = \\beta_{0,2} + \\beta_{1,2} \\boldsymbol{\\mathbf{x}}_{2}  + \\epsilon_2 \\\\\n\\vdots \\\\\n\\boldsymbol{\\mathbf{y}}_{m} = \\beta_{0,m} + \\beta_{1,m} \\boldsymbol{\\mathbf{x}}_{m}  + \\epsilon_{m}\n\\end{split}\n\\end{align}\\]dependent variable represented plausible value, regression equation \\[\\begin{align}\n\\begin{split}\n\\boldsymbol{\\mathbf{y}} = \\beta_{0,1} + \\beta_{1,1} \\boldsymbol{\\mathbf{x}}_{1}  + \\epsilon_1 \\\\\n\\boldsymbol{\\mathbf{y}} = \\beta_{0,2} + \\beta_{1,2} \\boldsymbol{\\mathbf{x}}_{2}  + \\epsilon_2 \\\\\n\\vdots \\\\\n\\boldsymbol{\\mathbf{y}} = \\beta_{0,m} + \\beta_{1,m} \\boldsymbol{\\mathbf{x}}_{m}  + \\epsilon_{m}\n\\end{split}\n\\end{align}\\]\\(y\\) fixed across regression runs, regression coefficients estimated using \\(m\\) plausible values \\(x\\).approach similar Weirich et al. (2014)`s Single+Multiple Imputation (SMI) method, produce \\(m\\) number plausible values instead \\(m \\times m\\) plausible values.coefficient estimates averages \\(m\\)\\[\\begin{align}\n\\boldsymbol{\\mathbf{\\beta_i}} = \\frac{1}{m} \\sum_{m=1}^{p} \\boldsymbol{\\mathbf{\\beta_{,m}}}_{p}\n\\end{align}\\]\\(\\beta_{p}\\) vector estimated regression coefficients, calculated using \\(p\\)th set plausible values.","code":""},{"path":"methods.html","id":"estimation-of-the-coefficient-of-determination-in-a-weighted-linear-regression","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.3.1 Estimation of the Coefficient of Determination in a Weighted Linear Regression","text":"regression analysis, statistics coefficient determination (.e., \\(R\\)-squared) estimated across observations. statistics normalize average values across regression runs (one per set plausible values). example,\\[\\begin{align}\nR^2 = \\left( \\tanh \\left( \\frac{1}{m} \\sum_{p=1}^m \\left( \\text{atanh} \\left( \\sqrt{R^2_p} \\right) \\right) \\right) \\right)^2\n\\end{align}\\]\\(R^2_p\\) \\(R\\)-squared value regression run \\(p\\)th set plausible values. also scales subscales sides equation, analyses adapts Weirich et al. (2014)`s Single+Multiple Imputation (SMI) method mentioned previously. result , method produce \\(m\\) number \\(R\\)-squared values.particular regression, (Weisberg, 1985, Eq. 2.31) defined \\(R\\)-squared \n\\[\\begin{align}\nR^2 = 1 - \\frac{RSS}{SYY}\n\\end{align}\\]\n\\(RSS=\\boldsymbol{\\mathbf{e}}^T \\boldsymbol{\\mathbf{}}\\) (Weisberg, 1985, Eq. 4.2), \\(SYY=(\\boldsymbol{\\mathbf{y}}-\\bar{y})^T \\boldsymbol{\\mathbf{W}} (\\boldsymbol{\\mathbf{y}}-\\bar{y})\\); \\(\\bar{y}\\) weighted mean outcome, \\(\\boldsymbol{\\mathbf{e}} = \\boldsymbol{\\mathbf{y}} - \\boldsymbol{\\mathbf{X\\beta}}\\).","code":""},{"path":"methods.html","id":"estimation-of-standard-deviations","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.4 Estimation of Standard Deviations","text":"user desires measure dispersion variable plausible values, weighted variance estimate calculated according \n\\[\\begin{align}\n\\hat{s}^2 = \\frac{\\sum_{=1}^{n} w_i (x_i - \\mu_x)^2}{\\sum_{=1}^{n} w_i}\n\\end{align}\\]\n\\(\\mu_x\\) weighted mean. several plausible values, average variance across plausible values (calculating \\(\\mu_x\\) per plausible value).estimate standard deviation square root estimated variance.","code":""},{"path":"methods.html","id":"estimation-of-standardized-regression-coefficients","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.5 Estimation of Standardized Regression Coefficients","text":"Using definition standardized regression coefficients (\\(b\\)),\\[\\begin{align}\nb_j = \\frac{\\tilde{\\sigma}_y}{\\tilde{\\sigma}_{X_j}} \\beta_j\n\\end{align}\\]\\(b_j\\) standardized regression coefficient associated \\(j\\)th regressor, \\(\\tilde{\\sigma}_y\\) weighted standard deviation outcome variable, \\(\\tilde{\\sigma}_{X_j}\\) weighted standard deviation \\(j\\)th regressor.","code":""},{"path":"methods.html","id":"default-variance-estimation-of-standardized-regression-coefficients","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.5.1 Default Variance Estimation of Standardized Regression Coefficients","text":"default standard error standardized regression coefficients treats standard error estimates constants, follows:\\[\\begin{align}\n\\sigma_{b_j} = \\frac{\\sigma_y}{\\sigma_{X_j}} \\sigma_{\\beta_j}\n\\end{align}\\]","code":""},{"path":"methods.html","id":"sampling-variance-estimation-of-standardized-regression-coefficients","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.5.2 Sampling Variance Estimation of Standardized Regression Coefficients","text":"alternative method estimates standardized regression coefficients using process estimates standard error, accounting design-based sampling variance.method estimates standardized regression coefficients per plausible value jackknife replicate. estimating standardized regression coefficient plausible value, overall variance outcome (\\(\\tilde{\\sigma}{y}\\)) regressors (\\(\\tilde{\\sigma}_{X_j}\\)) used. jackknife replicate, values \\(\\tilde{\\sigma}_y\\) \\(\\tilde{\\sigma}_{X_j}\\) updated jackknife replicate weights.Estimating variance standardized regression coefficient proceeds identically estimating variance regressors, weighted standard deviations also updated jackknife replicate weights.","code":""},{"path":"methods.html","id":"estimation-of-standard-errors-of-weighted-means-when-plausible-values-are-not-present-using-the-jackknife-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.6 Estimation of Standard Errors of Weighted Means When Plausible Values Are Not Present, Using the Jackknife Method","text":"predicted value plausible values requested variance method jackknife, estimate variance coefficients (\\(\\boldsymbol{\\mathbf{V}}_J\\)) follows:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_J=\\boldsymbol{\\mathbf{V}}_{jrr,0} = \\gamma \\sum_{j=1}^J (\\boldsymbol{\\mathbf{\\beta}}_j - \\boldsymbol{\\mathbf{\\beta}}_0)^2\n\\end{align}\\]\n\\(\\gamma\\) constant equal one jackknife variance estimation method, inclusion allows us extend equations variance estimation methods, balanced repeated replication (Wolter, 2007) Fay’s method (Judkins, 1990); \\(\\boldsymbol{\\mathbf{\\beta}}_j\\) coefficient estimated \\(j\\)th jackknife replicate weight; \\(\\boldsymbol{\\mathbf{\\beta}}_0\\) coefficient estimated sample weight; \\(J\\) total number jackknife replicate weights.covariance \\(\\beta_l\\) \\(\\beta_m\\) (\\(C_{J;lm}\\)) estimated \n\\[\\begin{align}\nC_{J;lm}=C_{jrr,0;lm} = \\gamma \\sum_{j=1}^J (\\beta_{j;l} - \\beta_{0;l})(\\beta_{j;m} - \\beta_{0;m})\n\\end{align}\\]\nsubscripts semicolon indicate matrix element (two subscripts) covariance matrix (\\(\\boldsymbol{\\mathbf{C}}\\)) vector element (one subscript) estimate vector \\(\\boldsymbol{\\mathbf{\\beta}}\\). subscripts variance estimation.","code":""},{"path":"methods.html","id":"estimation-of-standard-errors-of-weighted-means-when-plausible-values-are-present-using-the-jackknife-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.7 Estimation of Standard Errors of Weighted Means When Plausible Values Are Present, Using the Jackknife Method","text":"predictor /outcome value plausible values requested variance method jackknife, estimate variance (\\(\\boldsymbol{\\mathbf{V}}_{JP}\\)) sum variance component plausible values (also called imputation values variance term called \\(\\boldsymbol{\\mathbf{V}}_{imp}\\)) estimate sampling variance using plausible values (\\(\\boldsymbol{\\mathbf{V}}_{jrr,P}\\)) according following formula:\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{JP}=\\boldsymbol{\\mathbf{V}}_{imp} + \\boldsymbol{\\mathbf{V}}_{jrr,P}\n\\end{align}\\]sampling variance \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{jrr,P} = \\frac{1}{m^*} \\sum_{=1}^{m^*} \\boldsymbol{\\mathbf{V}}_{jrr,p}  \n\\end{align}\\]equation, \\(m^*\\) number can small one large number plausible values.12 previous equation, \\(\\boldsymbol{\\mathbf{V}}_{jrr,P}\\) average \\(\\boldsymbol{\\mathbf{V}}_{jrr,p}\\) plausible values, values \\(\\boldsymbol{\\mathbf{V}}_{jrr,p}\\) calculated way analogous \\(\\boldsymbol{\\mathbf{V}}_{jrr,0}\\) previous section, except \\(p\\)th plausible values used within step:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{jrr,p} = \\gamma \\sum_{j=1}^{J} (\\boldsymbol{\\mathbf{\\beta}}_{jp} - \\boldsymbol{\\mathbf{\\beta}}_{0p})^2\n\\end{align}\\]imputation variance estimated according Rubin (1987):\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{imp} = \\frac{m+1}{m(m-1)} \\sum_{p=1}^m (\\boldsymbol{\\mathbf{\\beta}}_p - \\boldsymbol{\\mathbf{\\beta}})^2\n\\end{align}\\]\n\\(m\\) number plausible values, \\(\\boldsymbol{\\mathbf{\\beta}}_p\\) vector coefficients calculated \\(p\\)th set plausible values, \\(\\boldsymbol{\\mathbf{\\beta}}\\) estimated coefficient vector averaged plausible values.Covariance terms \\(\\beta_l\\) \\(\\beta_m\\) estimated according \n\\[\\begin{align}\nC_{JP;lm}=C_{imp;lm} + C_{jrr,P;lm}\n\\end{align}\\]\nsubscripts semicolon indicate indexes covariance term identified:\n\\[\\begin{align}\nC_{jrr,p;lm} = \\gamma \\sum_{j=1}^{J} (\\beta_{jp;l} - \\beta_{0p;l}) (\\beta_{jp;m} - \\beta_{0p;m})\n\\end{align}\\]\n\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{C}}_{imp;lm} = \\frac{m+1}{m(m-1)} \\sum_{p=1}^m (\\beta_{p;l} - \\beta_{l}) (\\beta_{p;m} - \\beta_{m})\n\\end{align}\\]\n\\(\\beta_l\\) \\(\\beta_m\\) estimates averaged across plausible values.","code":""},{"path":"methods.html","id":"estimation-of-standard-errors-of-weighted-means-when-plausible-values-are-not-present-using-the-taylor-series-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.8 Estimation of Standard Errors of Weighted Means When Plausible Values Are Not Present, Using the Taylor Series Method","text":"predicted value plausible values requested variance method Taylor series, variance coefficients (\\(\\boldsymbol{\\mathbf{V}}_{T}\\)) estimated as13.\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{T}=\\boldsymbol{\\mathbf{V}}_{Taylor,0}(\\boldsymbol{\\mathbf{\\beta}}) = \\boldsymbol{\\mathbf{D}}^T \\boldsymbol{\\mathbf{Z D}}\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{V}}_T\\) matrix, variance estimates along diagonal, whereas covariances -diagonal elements. \\(\\boldsymbol{\\mathbf{V}}_T\\) estimated \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{D}}= (\\boldsymbol{\\mathbf{X}}^T \\boldsymbol{\\mathbf{W X}})^{-1}\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{X}}\\) matrix regressors, \\(\\boldsymbol{\\mathbf{W}}\\) matrix diagonal matrix \\(\\)th weight \\(\\)th diagonal element,\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{Z}} = \\sum_{j=1}^{J} \\frac{n_s}{n_s-1} \\sum_{u=1}^{n_s} \\boldsymbol{\\mathbf{z}}_{uj} \\boldsymbol{\\mathbf{z}}_{uj}^T\n\\end{align}\\]inner sum sampled PSUs (\\(u\\)), \\(n_s\\), outer sum units jackknife replicate strata (\\(j\\)), still \\(J\\). strata least two PSUs students included sum; others simply excluded.14 mean, \\(\\boldsymbol{\\mathbf{z}}_{uj}\\) scalar; regression, \\(\\boldsymbol{\\mathbf{z}}_{uj}\\) vector entry regressor. follows, estimand mean, \\(\\boldsymbol{\\mathbf{X}}\\) simply column vector ones.Define estimated residual vector (\\(\\boldsymbol{\\mathbf{e}}\\)) \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{e}} = \\boldsymbol{\\mathbf{y}}-\\boldsymbol{\\mathbf{X\\beta}}\n\\end{align}\\]\ndefine term\n\\[\\begin{align}\nU_{ik} = e_i X_{ik} w_{}\n\\end{align}\\]\n\\(\\) indexes matrix row (observation) \\(k\\) indexes matrix column (regressor). \\(k\\)th entry \\(\\boldsymbol{\\mathbf{z}}_{uj}\\) given \n\\[\\begin{align}\nz_{ujk} = \\sum_{\\\\mathcal{Q}_{uj}}^{n_s} \\left[U_{ik} - \\left( \\frac{1}{n_s}\\sum_{'\\\\mathcal{Q}_{j}}^{n_s} U_{'k} \\right) \\right]\n\\end{align}\\]\n\\(\\mathcal{Q}_{uj}\\) indices observations \\(u\\)th PSU \\(j\\)th stratum, \\(\\mathcal{Q}_{j}\\) indices observations \\(j\\)th stratum (across PSUs). Thus, two PSUs selected per stratum, value \\(\\boldsymbol{\\mathbf{z}}\\) related \\(\\boldsymbol{\\mathbf{z}}_{1j}= \\operatorname{-}\\boldsymbol{\\mathbf{z}}_{2j}\\).","code":""},{"path":"methods.html","id":"estimation-of-standard-errors-of-weighted-means-when-plausible-values-are-present-using-the-taylor-series-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.9 Estimation of Standard Errors of Weighted Means When Plausible Values Are Present, Using the Taylor Series Method","text":"predicted value plausible values requested variance method Taylor series, variance coefficients (\\(\\boldsymbol{\\mathbf{V}}_{TP}\\)) estimated \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{TP}=\\boldsymbol{\\mathbf{V}}_{Taylor,P}(\\boldsymbol{\\mathbf{\\beta}}) + \\boldsymbol{\\mathbf{V}}_{imp}\n\\end{align}\\]\nequation \\(\\boldsymbol{\\mathbf{V}}_{imp}\\) \\(\\boldsymbol{\\mathbf{C}}_{imp}\\) given section jackknife variance estimator \n\\(\\boldsymbol{\\mathbf{V}}_{Taylor,P}\\) averaged plausible values according \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{Taylor,P} = \\frac{1}{m} \\sum_{p=1}^m \\boldsymbol{\\mathbf{V}}_{Taylor}(\\boldsymbol{\\mathbf{\\beta}}_p)\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{V}}_{Taylor}(\\boldsymbol{\\mathbf{\\beta}}_p)\\) calculated previous section, using \\(p\\)th plausible values form \\(\\boldsymbol{\\mathbf{e}}\\), \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{e}}=\\boldsymbol{\\mathbf{y}}_p - \\boldsymbol{\\mathbf{X\\beta}}_p\n\\end{align}\\]\nremainder calculation \\(U_{ik}\\) \\(z_{ujk}\\) otherwise identical.","code":""},{"path":"methods.html","id":"estimation-of-standard-errors-of-differences-of-means","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.2.10 Estimation of Standard Errors of Differences of Means","text":"Occasionally, two means (\\(\\mu_1\\) \\(\\mu_2\\)) calculated potentially overlapping groups. calculation done, difference (\\(\\Delta = \\mu_1 - \\mu_2\\)) may interest. covariance term available, estimate variance difference using formula\n\\[\\begin{align}\n\\sigma_{\\Delta}^2 = \\sigma_1^2 + \\sigma_2^2 - 2 \\sigma_{12}\n\\end{align}\\]\n\\(\\sigma_{12}\\) covariance \\(\\mu_1\\) \\(\\mu_2\\).covariance term available, approximate equation used, \n\\[\\begin{align}\n\\sigma_{\\Delta}^2 = \\sigma_1^2 + \\sigma_2^2 - 2  p \\sigma_m^2\n\\end{align}\\]\nsubscript \\(m\\) used indicate subset observations, \\(p\\) ratio number observations used calculating \\(\\mu_1\\) \\(\\mu_2\\) divided \\(n\\) size larger two samples.one group subset , part-whole comparison. Part-whole comparisons NAEP context apply comparisons jurisdictions (e.g., state versus nation). Please use caution implementing method types gap comparisons.","code":""},{"path":"methods.html","id":"estimation-of-weighted-percentages","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3 Estimation of Weighted Percentages","text":"Percentages estimate proportion individuals group characteristic (e.g., percentage Black students female). often called “domain.” population, universe set \\(\\tilde{\\mathcal{U}}\\); example, \\(\\tilde{\\mathcal{U}}\\) Black students eligible sampling. tilde indicates set population.15 sought-percentage percentage individuals subset \\(\\tilde{\\mathcal{}} \\subseteq \\tilde{\\mathcal{U}}\\). example, \\(\\tilde{\\mathcal{}}\\) set Black females eligible sampling. percentage estimate desired 100 times number individuals \\(\\tilde{\\mathcal{}}\\) divided number individuals \\(\\tilde{\\mathcal{U}}\\). Mathematically,\n\\[\\begin{align}\n\\Pi=100 \\times \\frac{|\\tilde{\\mathcal{}}|}{|\\tilde{\\mathcal{U}|}}\n\\end{align}\\]\n\\(|\\cdot|\\) cardinality, count number members set. example, \\(\\tilde{\\mathcal{U}}\\) subset entire eligible population. cases, \\(\\tilde{\\mathcal{U}}\\) simply population eligible individuals. value \\(\\Pi\\) represent percentage eligible individuals Black females.remainder section describes statistics meant estimate \\(\\Pi\\) variance estimates.","code":""},{"path":"methods.html","id":"estimation-of-weighted-percentages-when-plausible-values-are-not-present","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3.1 Estimation of Weighted Percentages When Plausible Values Are Not Present","text":"sample, units identified \\(\\mathcal{}\\) \\(\\mathcal{U}\\) (tilde dropped indicate sampled sets) estimator is16\n\\[\\begin{align}\n\\pi=100 \\times \\frac{\\sum_{\\\\mathcal{}} w_i }{\\sum_{\\\\mathcal{U}} w_i }\n\\end{align}\\]\n\\(\\pi\\) estimated percentage.Another statistic interest weighted sample size \\(\\mathcal{}\\), estimate number individuals population members \\(\\tilde{\\mathcal{}}\\). calculated \\(\\sum_{\\\\mathcal{}} w_i\\).","code":""},{"path":"methods.html","id":"estimation-of-weighted-percentages-when-plausible-values-are-present","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3.2 Estimation of Weighted Percentages When Plausible Values Are Present","text":"membership \\(\\mathcal{}\\) \\(\\mathcal{}\\) \\(\\mathcal{U}\\) depends measured score range, value \\(\\Pi\\) estimated set plausible values (indexed \\(p\\)) \n\\[\\begin{align}\n\\pi=100 \\times \\frac{1}{m} \\sum_{p=1}^m \\frac{\\sum_{\\\\mathcal{}_p} w_i }{\\sum_{\\\\mathcal{U}_p} w_i }\n\\end{align}\\]\nmembership \\(\\mathcal{U}\\) associated plausible value, \\(\\mathcal{U}_p\\) sets plausible values. applies \\(\\mathcal{}_p\\).","code":""},{"path":"methods.html","id":"estimation-of-the-standard-error-of-weighted-percentages-when-plausible-values-are-not-present-using-the-jackknife-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3.3 Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Jackknife Method","text":"membership \\(\\mathcal{}\\) \\(\\mathcal{U}\\) dependent plausible values requested variance method jackknife, estimate variance percentage (\\(\\boldsymbol{\\mathbf{V}}_{\\pi,J}\\)) follows:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{\\pi,J}=100^2 \\times \\boldsymbol{\\mathbf{V}}_{jrr,f,0}\n\\end{align}\\]\njackknife variance fraction given \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{jrr,f,0} = \\gamma \\sum_{j=1}^J \\left( \\frac{\\sum_{\\\\mathcal{}} w_{ij} }{\\sum_{\\\\mathcal{U}} w_{ij} } -  \\frac{\\sum_{\\\\mathcal{}} w_i }{\\sum_{\\\\mathcal{U}} w_i } \\right)^2\n\\end{align}\\]\nsubscript \\(j\\) indicates weights \\(j\\)th jackknife replicates used, weights contain second subscript student full sample weights.","code":""},{"path":"methods.html","id":"estimation-of-the-standard-error-of-weighted-percentages-when-plausible-values-are-present-using-the-jackknife-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3.4 Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Present, Using the Jackknife Method","text":"membership \\(\\mathcal{}\\) \\(\\mathcal{U}\\) depends plausible values requested variance method jackknife, estimate variance percentage (\\(\\boldsymbol{\\mathbf{V}}_{\\pi,JP}\\)) follows:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{\\pi,TP}=100^2 \\times \\left( \\boldsymbol{\\mathbf{V}}_{jrr,f,P} + \\boldsymbol{\\mathbf{V}}_{imp,f}\\right)\n\\end{align}\\]\nmodification \\(\\boldsymbol{\\mathbf{V}}_{jrr,f}\\) make \\(\\boldsymbol{\\mathbf{V}}_{jrr,f,P}\\) sets \\(\\mathcal{}\\) \\(\\mathcal{U}\\) must modified regard one set plausible values.\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{jrr,f,P}=\\gamma \\frac{1}{m^*} \\sum_{p=1}^{m^*} \\sum_{j=1}^J \\left( \\frac{\\sum_{\\\\mathcal{}_p} w_{ij} }{\\sum_{\\\\mathcal{U}_p} w_{ij} } -  \\frac{\\sum_{\\\\mathcal{}_p} w_i }{\\sum_{\\\\mathcal{U}_p} w_i } \\right)^2\n\\end{align}\\]\nsubscript \\(j\\) indicates weights \\(j\\)th jackknife replicates used, weights contain second subscript student full sample weights, subscript \\(p\\) indicates plausible values used. situations, \\(\\mathcal{}_p\\) identical across plausible values, \\(\\mathcal{U}_p\\) identical broader set situations.value \\(V_{imp,f}\\) given \n\\[\\begin{align}\nV_{imp,f}=\\frac{m+1}{m(m-1)}\\sum_{p=1}^m \\left( \\frac{\\sum_{\\\\mathcal{}_p} w_i }{\\sum_{\\\\mathcal{U}_p} w_i } - \\frac{1}{m} \\sum_{p'=1}^m \\frac{\\sum_{\\\\mathcal{}_{p'}} w_i }{\\sum_{\\\\mathcal{U}_{p'}} w_i } \\right)^2\n\\end{align}\\]\nsecond sum simply average plausible values represents estimate (\\(\\pi\\)). Thus, expression rewritten slightly compactly follows:\n\\[\\begin{align}\nV_{imp,f}=\\frac{m+1}{m(m-1)}\\sum_{p=1}^m \\left( \\frac{\\sum_{\\\\mathcal{}_p} w_i }{\\sum_{\\\\mathcal{U}_p} w_i } - \\frac{\\pi}{100} \\right)^2\n\\end{align}\\]","code":""},{"path":"methods.html","id":"estimation-of-the-standard-error-of-weighted-percentages-when-plausible-values-are-not-present-using-the-taylor-series-method","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.3.5 Estimation of the Standard Error of Weighted Percentages When Plausible Values Are Not Present, Using the Taylor Series Method","text":"membership \\(\\tilde{\\mathcal{}}\\) \\(\\tilde{\\mathcal{U}}\\) depend plausible values requested variance method Taylor series, estimate variance–covariance matrix \\(\\boldsymbol{\\mathbf{V}}_{\\pi,JP}\\) coefficients follows:\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{V}}_{\\pi,T}=100^2 \\times\n\\begin{bmatrix}\n  \\boldsymbol{\\mathbf{DZD}} & -\\boldsymbol{\\mathbf{DZD 1}} \\\\\n  -\\boldsymbol{\\mathbf{1}}^T \\boldsymbol{\\mathbf{DZD}} & \\boldsymbol{\\mathbf{1}}^T \\boldsymbol{\\mathbf{DZD 1}}\n\\end{bmatrix}\n\\end{align}\\]\nblock matrix elements \\(DZD \\\\mathbb{R}^{(c-1) \\times (c-1)}\\); \\(c\\)th row column products \\(DZD\\) vector \\(\\boldsymbol{\\mathbf{1}} \\\\mathbb{R}^{c-1}\\) one every element; definition \\(\\boldsymbol{\\mathbf{D}}\\) inverse matrix derivatives score vector taken respect \\(\\boldsymbol{\\mathbf{\\pi}}\\); \\(Z\\) variance estimate proportions based sample survey. calculation based results derived , following Binder (1983).score function question \n\\[\\begin{align}\nS(\\pi_h) = \\left( \\sum_{=1}^{n} w_i {\\rm 1\\kern -2.85 pxI}({\\rm unit\\ }{\\rm \\ \\ \\ class\\ }h) \\right) - \\left(  \\sum_{=1}^{n}  \\pi_h w_i \\right)\n\\end{align}\\]\nSetting score function zero solving yields parameter estimator shown section “Estimation Weighted Percentages Plausible Values Present,” less factor 100 converts proportion percentage.first \\(c-1\\) elements \\(\\boldsymbol{\\mathbf{\\pi}}\\), solving function \\(\\pi_h\\), solution estimate \\(\\pi_h\\) shown earlier:\n\\[\\begin{align}\n\\pi_h = \\frac{\\sum_{=1}^{n} w_i {\\rm 1\\kern -2.85 pxI}({\\rm unit\\ }{\\rm \\ \\ \\ class\\ }h)}{\\sum_{=1}^{n}  w_i}\n\\end{align}\\]\n\\(\\pi_c\\), definition \n\\[\\begin{align}\n\\pi_c = 1-\\sum_{k=1}^{c-1} \\pi_k\n\\end{align}\\]\nalgebraic rearrangement, equation becomes\n\\[\\begin{align}\n=  \\frac{\\sum_{=1}^{n} w_i {\\rm 1\\kern -2.85 pxI}({\\rm unit\\ }{\\rm \\ \\ \\ class\\ }c)}{\\sum_{=1}^{n}  w_i}\n\\end{align}\\]value \\(D\\) derivative \\(S(\\pi)\\) respect \\(\\pi\\). derivative must calculated total equilibrium (percentages add 100), done first \\(c-1\\) items, variance \\(\\pi_c\\) separately calculated. Taking derivative \\(S(\\pi)\\) inverting shows \\(\\boldsymbol{\\mathbf{D}} \\\\mathbb{R}^{(c-1) \\times (c-1)}\\) diagonal matrix entries \\(\\frac{1}{\\sum_{=1}^{n} w_i}\\).\\(\\boldsymbol{\\mathbf{Z}}\\) matrix accounts given \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{Z}}=\\sum_{s=1}^{N_s} \\frac{n_s}{n_s-1} \\sum_{j=1}^{n_s} \\boldsymbol{\\mathbf{U}}_{sk}^T \\boldsymbol{\\mathbf{U}}_{sk}\n\\end{align}\\]\n\\(N_s\\) number strata, \\(n_s\\) \nnumber PSUs stratum, \n\\(\\boldsymbol{\\mathbf{U}}_{sk}\\) vector mean score deviates given \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{U}}_{sk} = \\sum_{l=1}^{n_{sk}} \\boldsymbol{\\mathbf{S}}_{skl}(\\boldsymbol{\\mathbf{\\pi}}) - \\frac{1}{n_s} \\sum_{j=1}^{n_s} \\sum_{l=1}^{n_{sj}} \\boldsymbol{\\mathbf{S}}_{sjl}(\\boldsymbol{\\mathbf{\\pi}})\n\\end{align}\\]\n\\(n_{sk}\\) number observations PSU \\(k\\) stratum \\(s\\), \\(l\\) index individuals within stratum PSU, score vector given \n\\[\\begin{align}\n\\boldsymbol{\\mathbf{S}}_{skl}(\\boldsymbol{\\mathbf{\\pi}}) = w_{skl} \\boldsymbol{\\mathbf{e}}_{skl} - w_{skl} \\boldsymbol{\\mathbf{\\pi}}\n\\end{align}\\]\n\\(\\boldsymbol{\\mathbf{e}}_{skl}\\) vector 0 entries except single 1 class unit . example, respondent male possible levels (“Female”, “Male”), level \\(\\boldsymbol{\\mathbf{e}}_{skl}\\) \\((0,1)^T\\).gives covariance matrix first \\(c-1\\) elements \\(\\boldsymbol{\\mathbf{\\pi}}\\) vector. Using usual formula variance covariance, easy see variance final row column shown beginning section.17","code":""},{"path":"methods.html","id":"estimation-of-degrees-of-freedom","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.4 Estimation of Degrees of Freedom","text":"section next two subsections describe estimate degrees freedom statistic calculated entirely one survey. description follows poll degrees freedom statistic calculated across two cohorts samples.One method estimating degrees freedom education survey results find sum number PSUs (schools) subtract number strata number PSUs. NAEP surveys, results estimate 62.However, many estimates use variation across PSUs, expect degrees freedom smaller.","code":""},{"path":"methods.html","id":"estimation-of-degrees-of-freedom-using-the-jackknife","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.4.1 Estimation of Degrees of Freedom, Using the Jackknife","text":"jackknife estimator used, Welch-Satterthwaite (WS) degrees freedom estimate (\\(dof_{WS}\\)) (Satterthwaite, 1946; Welch, 1947)\n\\[\\begin{align}\ndof_{WS} = \\frac{1}{m^*} \\sum_{p=1}^{m^*} \\frac{ \\left[ \\sum_{j=1}^{J} \\left[ (A_{jp} - A_{0p}) - (B_{jp} - B_{0p}) \\right]^2 \\right]^2 }{ \\sum_{j=1}^{J}  \\left[(A_{jp} - A_{0p}) - (B_{jp} - B_{0p}) \\right]^4  }\n\\end{align}\\]\n\\(A_{jp}\\) estimate \\(\\) using \\(j\\)th jackknife replicate value \\(p\\)th plausible value, \\(A_{0p}\\) estimate \\(\\) using full sample weights \\(p\\)th plausible value. true \\(B\\) subscripts. regression coefficient, \\((A_{jp} - A_{0p}) - (B_{jp} - B_{0p})\\) replaced \\(j\\)th deviate full sample weight coefficient \\(\\beta_{jp} - \\beta_{0p}\\).Johnson & Rust (1992) corrected degrees freedom (\\(dof_{JR}\\)) \\[\\begin{align}\ndof_{JR} = \\left(3.16 - \\frac{2.77}{\\sqrt{J}} \\right) dof_{WS}\n\\end{align}\\]","code":""},{"path":"methods.html","id":"estimation-of-degrees-of-freedom-using-the-taylor-series","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.4.2 Estimation of Degrees of Freedom, Using the Taylor Series","text":"Taylor series estimator, degrees freedom estimator also uses WS degrees freedom estimate (\\(dof_{WS}\\)). However, jackknife replicate estimates available, different equation used. WS weights require estimate degrees freedom per group; using jackknife variance estimator, estimated using jackknife replicate weights. Taylor series, estimated per stratum.Following Binder (1983) American Institutes Research Jon Cohen (n.d.), contribution \\(c_s\\) degrees freedom stratum \\(s\\) defined \\(\\boldsymbol{\\mathbf{z}}_{uj}\\) section “Estimation Standard Errors Weighted Means Plausible Values Present, Using Taylor Series Method”:\n\\[\\begin{align}\nc_s = w_s \\frac{n_s}{n_s-1} \\sum_{u=1}^{n_s} \\boldsymbol{\\mathbf{z}}_{uj} \\boldsymbol{\\mathbf{z}}_{uj}^T\n\\end{align}\\]\n\\(u\\) indexes PSUs stratum, \\(n_s\\), \\(w_s\\) stratum weight, sum, stratum, unit’s full sample weights. stratum weight used calculation estimated degrees freedom jackknife applied approximately account size stratum degrees freedom calculation. Using \\(c_s\\) values, degrees freedom \n\\[\\begin{align}\ndof_{WS} = \\frac{\\left(\\sum c_s \\right)^2}{\\sum c_s^2}\n\\end{align}\\]\nmultiple plausible values, average \\(dof_{WS}\\) across plausible values used.","code":""},{"path":"methods.html","id":"estimation-of-degrees-of-freedom-for-statistics-pooled-across-multiple-surveys","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.4.3 Estimation of Degrees of Freedom for Statistics Pooled Across Multiple Surveys","text":"estimating statistic two surveys, different formula used. case, statistic survey combined final estimate; example, difference means use mean estimate survey. degrees freedom pooled statistic \n\\[\\begin{align}\ndof = \\frac{\\left(s_1^2 + s_2^2 \\right)^2}{ \\frac{s_1^4}{dof_1} + \\frac{s_2^4}{dof_2} }\n\\end{align}\\]\n\\(s_1^2\\) \\(dof_1\\) squared standard error degrees freedom, respectively, statistic calculated first survey, \\(s_2^2\\) \\(dof_2\\) squared standard error degrees freedom, respectively, statistic calculated second survey. intermediate degrees freedom calculated described one previous two sections.","code":""},{"path":"methods.html","id":"estimation-of-weighted-mixed-models","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.5 Estimation of Weighted Mixed Models","text":"Analysts estimate weighted mixed models, plausible value, using WeMix package. results combined described section.Estimate fixed effects WeMix results using\n\\[\\begin{align}\n\\boldsymbol{\\mathbf{\\beta}} = \\frac{1}{M} \\sum_{p=1}^M \\boldsymbol{\\mathbf{\\beta}}_p\n\\end{align}\\]\n\\(p\\) indexes plausible values, \\(M\\). formula used estimate variance random effects.","code":""},{"path":"methods.html","id":"weighted-mixed-model-variance-estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.5.1 Weighted Mixed Model Variance Estimation","text":"standard error mixed effects cluster robust already aggregated highest cluster level model. recommend highest level align sampling design, example, school study selects schools. cluster robust variance estimator includes sampling design, sampling variance can estimated simply averaging across plausible values. true fixed effects variances random effects.imputation variance calculated using Rubin’s rule. formula fixed effects shown, rule applies estimated variance random effects.\n\\[\\begin{align}\nV_{\\rm imp} = \\frac{M+1}{M(M-1)} \\sum_{p=1}^M (\\boldsymbol{\\mathbf{\\beta}}_p - \\boldsymbol{\\mathbf{\\beta}}) (\\boldsymbol{\\mathbf{\\beta}}_p - \\boldsymbol{\\mathbf{\\beta}})^{\\prime}\n\\end{align}\\]\n\\(V_{imp}\\) imputation covariance matrix. total covariance sum sampling covariance imputation covariance.\n\\[\\begin{align}\nV = V_{\\rm imp} + V_{\\rm smp}\n\\end{align}\\]\nvariance diagonal covariance matrix.","code":""},{"path":"methods.html","id":"multivariate-regression","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6 Multivariate Regression","text":"multivariate regression form\n\\[ \\boldsymbol{\\mathbf{Y}}=\\boldsymbol{\\mathbf{XB}} + \\boldsymbol{\\mathbf{E}}\\]\\(\\boldsymbol{\\mathbf{Y}}\\) matrix \\(n\\) observations \\(s\\) dependent variables; \\(\\boldsymbol{\\mathbf{X}}\\) matrix columns \\(k\\)+1 independent variables; \\(\\boldsymbol{\\mathbf{B}}\\) matrix regression coefficients, one column dependent variable; \\(\\boldsymbol{\\mathbf{E}}\\) matrix errors. weighted regression used estimated coefficients (\\(\\boldsymbol{\\mathbf{\\hat{B}}}\\)) minimize trace weighted residual sum squares cross-products matrix:\\[\\boldsymbol{\\mathbf{\\hat{B}}} = \\mathrm{ArgMin}_{\\boldsymbol{\\mathbf{B}}}\\ \\ tr((\\boldsymbol{\\mathbf{Y}}-\\boldsymbol{\\mathbf{X}} \\boldsymbol{\\mathbf{B}})^T \\boldsymbol{\\mathbf{W}} (\\boldsymbol{\\mathbf{Y}}-\\boldsymbol{\\mathbf{X}} \\boldsymbol{\\mathbf{B}}))\\]\\(\\boldsymbol{\\mathbf{X}}_i\\) \\(\\)th row \\(\\boldsymbol{\\mathbf{X}}\\), \\(\\boldsymbol{\\mathbf{Y}}_i\\) \\(\\)th row \\(\\boldsymbol{\\mathbf{Y}}\\), \\(\\boldsymbol{\\mathbf{W}}\\) diagonal matrix weights, \\(\\mathrm{ArgMin}_{\\boldsymbol{\\mathbf{B}}}\\) means value \\(\\boldsymbol{\\mathbf{B}}\\) minimizes expression follows .","code":""},{"path":"methods.html","id":"estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6.1 Estimation","text":"methods used estimate coefficients, variance, covariance multivariate multiple regression similar used univariate multiple regression.","code":""},{"path":"methods.html","id":"coefficient-estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6.1.1 Coefficient Estimation","text":"coefficient estimation mvrlm.sdf produces coefficient estimates regressions run separately using lm.sdf detailed chapter.","code":""},{"path":"methods.html","id":"variance-estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6.1.2 Variance Estimation","text":"variance estimation mvrlm.sdf produces standard error estimates regressions run separately using lm.sdf.predicted value plausible values, variance coefficients estimated according section “Estimation Standard Errors Weighted Means Plausible Values Present, Using Jackknife Method.”plausible values present either sides, variance coefficients estimated according section “Estimation Standard Errors Weighted Means Plausible Values Present, Using Jackknife Method.”","code":""},{"path":"methods.html","id":"residual-variancecovariance-matrix-estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6.1.3 Residual Variance–Covariance Matrix Estimation","text":"addition estimating regression coefficients dependent variable, mvrlm.sdf model also produces residual covariance estimates dependent variables. residual variance–covariance matrix \\(s \\times s\\) matrix model \\(s\\) dependent variables summarizes residuals within dependent variables.residuals \\(\\)th dependent variable calculated follows:\\[ \\boldsymbol{\\mathbf{R_i}} = \\boldsymbol{\\mathbf{Y_i}}-\\boldsymbol{\\mathbf{X}}\\boldsymbol{\\mathbf{\\hat{\\beta}_i}} \\]\\(\\boldsymbol{\\mathbf{Y_i}}\\) \\(p \\times n\\) matrix plausible values \\(\\)th dependent variable, \\(\\boldsymbol{\\mathbf{X}}\\) \\(k \\times n\\) matrix independent variables, \\(\\boldsymbol{\\mathbf{\\hat{\\beta}_i}}\\) \\(p \\times k\\) matrix estimated coefficients \\(p\\) plausible values \\(k\\) independent variables. \\(\\)th dependent variable plausible values, \\(\\boldsymbol{\\mathbf{R_i}}\\) simply vector residuals variable.calculate residual variance–covariance matrix, summarize residuals across plausible values. dependent variables plausible values, mean residual taken across plausible values observation, residual value simply taken dependent variables without plausible values. residual vector \\(\\)th dependent variable calculated follows:\\[ E_i = \\frac{1}{p} \\sum_{=1}^{p} r_a\\]\\(r_a\\) \\(\\)th column matrix residuals \\(\\boldsymbol{\\mathbf{R_i}}\\) \\(\\)th dependent variable. \\(\\)th dependent variable plausible values, \\(\\boldsymbol{\\mathbf{E_i}}\\) simply vector residuals variable.\\(s \\times s\\) residual variance–covariance matrix calculated residual vectors dependent variable follows:\\[\n\\begin{bmatrix}\n    E^T_{1} E_1 & E^T_{1} E_2 & \\dots  & E^T_{1} E_s  \\\\\n    E^T_{2} E_1 & E^T_{2} E_2 & \\dots  & E^T_{2} E_s \\\\\n    \\vdots & \\vdots  & \\ddots & \\vdots \\\\\n    E^T_{s} E_1 & E^T_{s} E_2  & \\dots  &E^T_{s} E_s\n\\end{bmatrix}\n\\]","code":""},{"path":"methods.html","id":"coefficient-variancecovariance-matrix-estimation","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.6.1.4 Coefficient Variance–Covariance Matrix Estimation","text":"Use vcov method find coefficient variance–covariance matrix marginal maximum likelihood models.univariate case, coefficient matrix \\(k \\times k\\) symmetric matrix model \\(k\\) regression coefficients, whereas variance–covariance matrix multivariate case \\(sk \\times sk\\) symmetric block matrix, \\(k \\times k\\) blocks diagonal represent variance–covariance values within dependent variable (values match variance–covariance matrix corresponding univariate model), whereas \\(k \\times k\\) -diagonal blocks represent variance–covariance values across dependent variables.\\[\n\\begin{bmatrix}\n    \\boldsymbol{\\mathbf{V_1}} & \\boldsymbol{\\mathbf{C_{1,2}}} & \\dots & \\boldsymbol{\\mathbf{C_{1,s}}}  \\\\\n    \\boldsymbol{\\mathbf{C_{2,1}}} & \\boldsymbol{\\mathbf{V_2}} & \\dots  & \\boldsymbol{\\mathbf{C_{2,s}}} \\\\\n    \\vdots & \\vdots  & \\ddots & \\vdots \\\\\n    \\boldsymbol{\\mathbf{C_{s,1}}} & \\boldsymbol{\\mathbf{C_{s,2}}} & \\dots  & \\boldsymbol{\\mathbf{V_s}}\n\\end{bmatrix}\n\\]diagonal blocks \\(\\boldsymbol{\\mathbf{V_i}}\\) \\(k \\times k\\) matrices following form \\(\\)th dependent variable:\\[ V_i = V_{jrr} + V_{imp} \\]variable plausible values, \\(V_{imp}\\) 0.-diagonal blocks \\(C_{,b}\\) \\(k \\times k\\) matrices following form dependent variables \\(\\) \\(b\\):\\[ C_{,b} = C_{jrr} + C_{imp} \\]one variable plausible values, \\(C_{imp}\\) 0.","code":""},{"path":"methods.html","id":"wald-tests-1","chapter":"11 Statistical Methods Used in EdSurvey","heading":"11.7 Wald Tests","text":"Wald test statistical test estimated parameters model, null hypothesis set parameters (\\(\\beta\\)) equal values (\\(\\beta_0\\)).18 default case, null hypothesis value parameters 0, test reject null hypothesis, removing variables model substantially harm fit model.formula test statistic single parameter follows:\\[W=\\frac{(\\hat{\\beta} - \\beta_0)^2}{Var(\\hat{\\beta)}}\\]\\(W\\) Wald test statistic, \\(Var(\\hat{\\beta})\\) variance estimate \\(\\hat{\\beta}\\).Wald test statistic multiple parameters equal \\[ W =(\\boldsymbol{\\mathbf{R}}\\hat{\\boldsymbol{\\mathbf{\\beta}}} - \\boldsymbol{\\mathbf{r}})'(\\boldsymbol{\\mathbf{R}}\\hat{\\boldsymbol{\\mathbf{V}}}\\boldsymbol{\\mathbf{R}}')^{-1}(\\boldsymbol{\\mathbf{R}}\\hat{\\boldsymbol{\\mathbf{\\beta}}} - \\boldsymbol{\\mathbf{r}}) \\]\\(\\boldsymbol{\\mathbf{R}}\\) \\(\\boldsymbol{\\mathbf{r}}\\) matrix vector, respectively, used specify null hypothesis, \\(\\hat{\\boldsymbol{\\mathbf{V}}}\\) variance estimator \\(\\hat{\\boldsymbol{\\mathbf{\\beta}}}\\).resulting test statistic can tested chi-square distribution F-distribution. chi-square distribution preferable F-distribution number degrees freedom large, whereas F-test preferable number degrees freedom small (Korn & Graubard, 1990).chi-square test, degrees freedom value equal number parameters tested, test statistic unadjusted value \\(W\\):\\[ W \\sim \\chi^2(p) \\]F-test, two scenarios dictate use two different adjustments test statistics, along two different values denominator degrees freedom.NAEP international assessments EdSurvey, collecting data using multistage stratified sampling design, test statistic adjusted based sampling parameters:\\[ W_{adj} = (d - p + 1) W / (pd)\\]\\(d\\) number PSUs minus number strata, \\(p\\) number parameters tested. adjusted test statistic compared F-distribution \\(p\\) \\((d - p - 1)\\) degrees freedom (Korn & Graubard, 1990):\\[ W_{adj} \\sim F(p, d - p - 1)\\]data collected using single-stage stratified sampling design (e.g., countries PIAAC data), test statistic follows:\\[ W_{adj} = W / p\\]adjusted test statistic compared F-distribution \\(p\\) \\(d\\) degrees freedom, \\(d\\) residual degrees freedom model \\(p\\) number parameters tested:\\[ W_{adj} \\sim F(p, d)\\]","code":""},{"path":"linkingerror.html","id":"linkingerror","chapter":"12 NAEP Linking Error","heading":"12 NAEP Linking Error","text":"Last edited: July 2023Suggested Citation\nBailey, P. NAEP Linking Error. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"linkingerror.html","id":"introduction-2","chapter":"12 NAEP Linking Error","heading":"12.1 Introduction","text":"Students take paper-based assessments (PBAs) digitally based assessments (DBAs) may experience items different ways—example, item may less difficult DBA format PBA format. account , NCES drew two nationally representative samples administered one PBA DBA. samples nationally representative, overall mean can assumed equivalent, two samples linked stochastic equivalence. However, linking introduced additional variance, linking error accounts additional variance, change modes. methodology assumes mode effect entire sample accounts variance introduced resulting change mode.EdSurvey implements method, developed NCES described chapter, account linking error assessments combined PBA DBA formats. June 2021, assessments include 2018 Grade 8 Civics, Geography, U.S. History; 2019 Science Grade 4 Grade 8; 2019 Grade 12 Mathematics Reading. method relevant 2017 Grade 4 Grade 8 Mathematics Reading. EdSurvey implements linking error studies, process described .Three groups plausible values used estimate statistics capture linking error variance estimation:first group plausible values used estimate quantity interest.second group plausible values used estimate sampling variance.third group plausible values used estimate imputation variance.NCES distributes NAEP data first group plausible values present, second third groups must calculated estimating linking error variance. three groups exist subject scale (e.g., composite, univariate) subscale (present). Although user work theta values directly, values used intermediate steps appear files. theta scores available EdSurvey.chapter begins describing use EdSurvey calculate linking error describes formulas used calculate linking error.","code":""},{"path":"linkingerror.html","id":"in-edsurvey","chapter":"12 NAEP Linking Error","heading":"12.2 In EdSurvey","text":"Beginning EdSurvey 2.7, NAEP linking error formulas implemented EdSurvey analytical functions, including edsurveyTable, achievementLevels, percentile, gap, cor.sdf, rq.sdf, lm.sdf, logit.sdf, probit.sdf, waldTest (applied results methods) summary2, mixed.sdf, mml.sdf, mvrlm.sdf. Users EdSurvey can account linking error simply using _linking outcomes place subject scale subscale. also listed separately calling showPlausibleValues. example, table can generated without linking error follows.limitations exist linking error procedure. First, allow Taylor series variance estimation. Second, value jrrIMax must always one. Attempting use EdSurvey Taylor series variance estimation jrrIMax greater one result error.Also, NCES provide necessary variables (shown next section) NAEP data, reading data slowed computing additional intermediate linking error variables (often taking several minutes), calculations slower linking error calculated.","code":"\nrequire(EdSurvey) # must be 2.7.0 or higher\nmath12 <- readNAEP(path = \"path/to/Data/M50NT3AT.dat\")\nshowPlausibleValues(data = math12)\n# Results, not accounting for DBA-PBA linking\nedsurveyTable(formula = composite ~ dsex, data = math12)\n# Results, accounting for DBA-PBA linking\nedsurveyTable(formula = composite_linking ~ dsex, data = math12)"},{"path":"linkingerror.html","id":"formulas","chapter":"12 NAEP Linking Error","heading":"12.2.1 Formulas","text":"section shows formulas used EdSurvey compute statistics accounting linking error.","code":""},{"path":"linkingerror.html","id":"estimation-1","chapter":"12 NAEP Linking Error","heading":"12.2.1.1 Estimation","text":"statistic estimated using usual scale score plausible values calculating statistic full sample weights averaging statistic across plausible values.\n\\[\\begin{equation}\nQ = \\frac{\\sum_{j=1}^J Q_j}{J}\n\\end{equation}\\]\n\\(Q\\) estimated statistic; \\(Q_j\\) statistic estimated \\(j\\)th set plausible values, \\(J\\); estimates weighted results full sample weights (origwt NAEP).","code":""},{"path":"linkingerror.html","id":"overview-of-naep-linking-error-methodology","chapter":"12 NAEP Linking Error","heading":"12.2.1.2 Overview of NAEP Linking Error Methodology","text":"exercise, use DBA student’s theta scores scale PBA reporting scale equation form\n\\[\\begin{equation}\n  X = b + \\theta\n\\end{equation}\\]\n\\(X\\) scale score, \\(b\\) location parameter, \\(\\) scale parameter, \\(\\theta\\) theta score. Although possible map scale scores directly one reporting scale another, complicated procedure neither described needed exercise.19The values \\(\\) \\(b\\) chosen students took DBA \\(\\theta\\) scores mapped mean standard deviation students took PBA. scaling performed imputation indexing imputation variance replicate weighting sampling variance, described next two subsections.typical NAEP, scores scaled subscale composite score weighted combination \n\\[\\begin{equation}\n  X_c = \\sum_{k=1}^{K} \\beta_k \\cdot X_k\n\\end{equation}\\]\\(X_c\\) composite scale score, \\(\\beta_k\\) weight applied \\(k\\)th subscale, \\(X_k\\) \\(k\\)th subscale scale score. sum \\(\\beta\\) values always one. subscales, overall (sometimes also called univariate) score can used following subsections, number subscales simply one.Students took DBA variable dbapba set \"DBA\", students took PBA variable set \"PBA\".","code":""},{"path":"linkingerror.html","id":"imputation-variance","chapter":"12 NAEP Linking Error","heading":"12.2.1.2.1 Imputation Variance","text":"Ideally, imputation variance summed possible combinations 20 PBA 20 DBA imputations, far can reasonably calculated. minimize computation time, five permutations plausible values chosen; permutations shown Table 12.1, row number index DBA plausible values use, cell value index PBA plausible values use.Table 12.1. Permutation Table data already plausible values used estimation need imputation variance sampling variance plausible values added.algorithm generating imputation variance plausible values follows:Define \\(w_{DBA}\\) vector weights students took DBA. vector length \\(n_{DBA}\\).Define \\(w_{PBA}\\) vector weights students took PBA. vector length \\(n_{PBA}\\).column (\\(n\\)) permutation table row (\\(j\\)) permutation table\nsubscale (\\(k\\))\nDefine \\(X_k\\) vector \\(k\\)th subscale, scale score plausible values students took PBA. Select plausible value based element Table 1 row column (\\(j\\), \\(n\\)th element permutation table).\nDefine \\(\\theta_k\\) vector \\(k\\)th subscale, theta score \\(j\\) (\\(j\\)th theta score plausible value) students took DBA.\nDefine \\(\\mu_t = \\frac{\\sum w_{DBA} \\theta_k}{\\sum w_{DBA}}\\)\nDefine \\(s_t = \\sqrt{ \\frac{\\sum w_{DBA} (\\theta_k - \\mu_t)^2}{\\sum w_{DBA}}}\\)\nDefine \\(\\mu_x = \\frac{\\sum w_{PBA} X_k}{\\sum w_{PBA}}\\)\nDefine \\(s_x = \\sqrt{ \\frac{\\sum w_{PBA} (X_k - \\mu_x)^2}{\\sum w_{PBA}}}\\)\nGenerate new scale score DBA students, centered mean PBA students using \\(X_k^\\prime = b + \\theta_k\\), \\(=\\frac{s_x}{s_t}\\) \\(b=\\mu_x - \\mu_t\\).\n\\(j\\), \\(n\\)th imputation variance plausible value subscale \\(k\\) \\(X_k^\\prime\\) students took DBA \\(X_k\\) students took PBA.\n\nGenerate composite DBA students using composite formula \\(X_c^\\prime = \\sum_k \\beta_k X_k^\\prime\\).\n\\(j\\), \\(n\\)th imputation variance plausible value composite \\(X_c^\\prime\\) students took DBA \\(X_c\\) students took PBA.\nsubscale (\\(k\\))\nDefine \\(X_k\\) vector \\(k\\)th subscale, scale score plausible values students took PBA. Select plausible value based element Table 1 row column (\\(j\\), \\(n\\)th element permutation table).\nDefine \\(\\theta_k\\) vector \\(k\\)th subscale, theta score \\(j\\) (\\(j\\)th theta score plausible value) students took DBA.\nDefine \\(\\mu_t = \\frac{\\sum w_{DBA} \\theta_k}{\\sum w_{DBA}}\\)\nDefine \\(s_t = \\sqrt{ \\frac{\\sum w_{DBA} (\\theta_k - \\mu_t)^2}{\\sum w_{DBA}}}\\)\nDefine \\(\\mu_x = \\frac{\\sum w_{PBA} X_k}{\\sum w_{PBA}}\\)\nDefine \\(s_x = \\sqrt{ \\frac{\\sum w_{PBA} (X_k - \\mu_x)^2}{\\sum w_{PBA}}}\\)\nGenerate new scale score DBA students, centered mean PBA students using \\(X_k^\\prime = b + \\theta_k\\), \\(=\\frac{s_x}{s_t}\\) \\(b=\\mu_x - \\mu_t\\).\n\\(j\\), \\(n\\)th imputation variance plausible value subscale \\(k\\) \\(X_k^\\prime\\) students took DBA \\(X_k\\) students took PBA.\nDefine \\(X_k\\) vector \\(k\\)th subscale, scale score plausible values students took PBA. Select plausible value based element Table 1 row column (\\(j\\), \\(n\\)th element permutation table).Define \\(\\theta_k\\) vector \\(k\\)th subscale, theta score \\(j\\) (\\(j\\)th theta score plausible value) students took DBA.Define \\(\\mu_t = \\frac{\\sum w_{DBA} \\theta_k}{\\sum w_{DBA}}\\)Define \\(s_t = \\sqrt{ \\frac{\\sum w_{DBA} (\\theta_k - \\mu_t)^2}{\\sum w_{DBA}}}\\)Define \\(\\mu_x = \\frac{\\sum w_{PBA} X_k}{\\sum w_{PBA}}\\)Define \\(s_x = \\sqrt{ \\frac{\\sum w_{PBA} (X_k - \\mu_x)^2}{\\sum w_{PBA}}}\\)Generate new scale score DBA students, centered mean PBA students using \\(X_k^\\prime = b + \\theta_k\\), \\(=\\frac{s_x}{s_t}\\) \\(b=\\mu_x - \\mu_t\\).\\(j\\), \\(n\\)th imputation variance plausible value subscale \\(k\\) \\(X_k^\\prime\\) students took DBA \\(X_k\\) students took PBA.Generate composite DBA students using composite formula \\(X_c^\\prime = \\sum_k \\beta_k X_k^\\prime\\).\\(j\\), \\(n\\)th imputation variance plausible value composite \\(X_c^\\prime\\) students took DBA \\(X_c\\) students took PBA.previous steps need performed . , statistic, imputation variance calculated follows. Using imputation variance plausible values, linking imputation variance calculated per permutation (column) averaged across permutations.column (\\(n\\)) permutation table row (\\(j\\)) permutation table,\nCalculate statistic question using \\(j\\), \\(n\\)th imputation variance plausible values full sample weights, call \\(Q_{jn}\\).\nCalculate \\(Q_{\\cdot n} = \\frac{1}{J} \\sum_{j=1}^J Q_{jn}\\), \\(J\\) number permutation table rows.\nCalculate \\(V_{imp,n} = \\frac{J+1}{J(J-1)} \\sum_{j=1}^J \\left(Q_{jn}-Q_{\\cdot n}\\right)^2\\).\nCalculate statistic question using \\(j\\), \\(n\\)th imputation variance plausible values full sample weights, call \\(Q_{jn}\\).Calculate \\(Q_{\\cdot n} = \\frac{1}{J} \\sum_{j=1}^J Q_{jn}\\), \\(J\\) number permutation table rows.Calculate \\(V_{imp,n} = \\frac{J+1}{J(J-1)} \\sum_{j=1}^J \\left(Q_{jn}-Q_{\\cdot n}\\right)^2\\).Calculate \\(V_{imp} = \\frac{1}{N} \\sum_n^N V_{imp,n}\\), \\(N\\) number columns permutable tableThe value \\(V_{imp}\\) estimated imputation variance statistic question.","code":""},{"path":"linkingerror.html","id":"sampling-variance","chapter":"12 NAEP Linking Error","heading":"12.2.1.2.2 Sampling Variance","text":"generate sampling variance plausible values, using first plausible value reweighting using replicate weights.subscale (\\(k\\)),\nDefine \\(X_k\\) vector \\(k\\)th subscale, scale score plausible value students took PBA. Select first plausible value.\nDefine \\(\\theta_k\\) vector theta scores \\(k\\)th subscale students took DBA. Select first plausible value.\nreplicate weight (\\(\\)),\nDefine \\(w_{DBA}^{()}\\) vector \\(\\)th replicate weights students took DBA. vector length \\(n_{DBA}\\).\nDefine \\(w_{PBA}^{()}\\) vector \\(\\)th replicate weights students took PBA. vector length \\(n_{PBA}\\).\nDefine \\(\\mu_t^{()} = \\frac{\\sum w_{DBA}^{()} \\theta_k}{\\sum w_{DBA}^{()}}\\)\nDefine \\(s_t^{()} = \\sqrt{ \\frac{\\sum w_{DBA}^{()} (\\theta_k - \\mu_t^{()})^2}{\\sum w_{DBA}^{()}}}\\)\nDefine \\(\\mu_x^{()} = \\frac{\\sum w_{PBA}^{()} X_k}{\\sum w_{PBA}^{()}}\\)\nDefine \\(s_x^{()} = \\sqrt{ \\frac{\\sum w_{PBA}^{()} (X_k - \\mu_x^{()})^2}{\\sum w_{PBA}^{()}}}\\)\nGenerate new scale score DBA students, centered mean PBA students using \\(X_k^{\\prime()} = b^{()} + ^{()}\\theta_k\\), \\(^{()}=\\frac{s_x^{()}}{s_t^{()}}\\) \\(b^{()}=\\mu_x^{()} - ^{()} \\mu_t^{()}\\).\n\\(\\)th sampling variance plausible value \\(X_k^{\\prime()}\\) students took DBA \\(X_k\\) students took PBA.\n\nDefine \\(X_k\\) vector \\(k\\)th subscale, scale score plausible value students took PBA. Select first plausible value.Define \\(\\theta_k\\) vector theta scores \\(k\\)th subscale students took DBA. Select first plausible value.replicate weight (\\(\\)),\nDefine \\(w_{DBA}^{()}\\) vector \\(\\)th replicate weights students took DBA. vector length \\(n_{DBA}\\).\nDefine \\(w_{PBA}^{()}\\) vector \\(\\)th replicate weights students took PBA. vector length \\(n_{PBA}\\).\nDefine \\(\\mu_t^{()} = \\frac{\\sum w_{DBA}^{()} \\theta_k}{\\sum w_{DBA}^{()}}\\)\nDefine \\(s_t^{()} = \\sqrt{ \\frac{\\sum w_{DBA}^{()} (\\theta_k - \\mu_t^{()})^2}{\\sum w_{DBA}^{()}}}\\)\nDefine \\(\\mu_x^{()} = \\frac{\\sum w_{PBA}^{()} X_k}{\\sum w_{PBA}^{()}}\\)\nDefine \\(s_x^{()} = \\sqrt{ \\frac{\\sum w_{PBA}^{()} (X_k - \\mu_x^{()})^2}{\\sum w_{PBA}^{()}}}\\)\nGenerate new scale score DBA students, centered mean PBA students using \\(X_k^{\\prime()} = b^{()} + ^{()}\\theta_k\\), \\(^{()}=\\frac{s_x^{()}}{s_t^{()}}\\) \\(b^{()}=\\mu_x^{()} - ^{()} \\mu_t^{()}\\).\n\\(\\)th sampling variance plausible value \\(X_k^{\\prime()}\\) students took DBA \\(X_k\\) students took PBA.\nDefine \\(w_{DBA}^{()}\\) vector \\(\\)th replicate weights students took DBA. vector length \\(n_{DBA}\\).Define \\(w_{PBA}^{()}\\) vector \\(\\)th replicate weights students took PBA. vector length \\(n_{PBA}\\).Define \\(\\mu_t^{()} = \\frac{\\sum w_{DBA}^{()} \\theta_k}{\\sum w_{DBA}^{()}}\\)Define \\(s_t^{()} = \\sqrt{ \\frac{\\sum w_{DBA}^{()} (\\theta_k - \\mu_t^{()})^2}{\\sum w_{DBA}^{()}}}\\)Define \\(\\mu_x^{()} = \\frac{\\sum w_{PBA}^{()} X_k}{\\sum w_{PBA}^{()}}\\)Define \\(s_x^{()} = \\sqrt{ \\frac{\\sum w_{PBA}^{()} (X_k - \\mu_x^{()})^2}{\\sum w_{PBA}^{()}}}\\)Generate new scale score DBA students, centered mean PBA students using \\(X_k^{\\prime()} = b^{()} + ^{()}\\theta_k\\), \\(^{()}=\\frac{s_x^{()}}{s_t^{()}}\\) \\(b^{()}=\\mu_x^{()} - ^{()} \\mu_t^{()}\\).\\(\\)th sampling variance plausible value \\(X_k^{\\prime()}\\) students took DBA \\(X_k\\) students took PBA.previously, steps need performed . statistic, sampling variance calculated follows. Using sampling variance plausible values, linking sampling variance calculated per replicate weight summed.replicate weight (\\(\\)), calculate \\(Q_{}\\) statistic question using \\(\\)th sampling variance plausible value \\(\\)th replicate weight.Calculate mean \\(Q_{\\cdot}= \\frac{1}{} \\sum_{=1}^Q_i\\), \\(\\) number replicate weights.Calculate \\(V_{samp} = \\sum_{=1}^\\left(Q_i - Q_{\\cdot}\\right)^2\\).value \\(V_{samp}\\) estimated sampling variance statistic question.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"the-edsurvey-suggestweights-function","chapter":"13 The EdSurvey suggestWeights Function","heading":"13 The EdSurvey suggestWeights Function","text":"Last edited: November 2023Suggested Citation\nHuo, H. EdSurvey suggestWeights Function. Bailey, P. Zhang, T. (eds.), Analyzing NCES Data Using EdSurvey: User’s Guide.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"introduction-3","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.1 Introduction","text":"suggestWeights function EdSurvey allows specify list variables intend use analysis suggests sample weights may appropriate analysis. Final weight variable selection, however, user based detailed understanding available analytic weights. Currently, suggestWeights function implemented Early Childhood Longitudinal Study, Kindergarten Class 2010–11 (ECLS-K:2011), sponsored National Center Education Statistics (NCES) within Institute Education Sciences U.S. Department Education.Sampling weights designed use data complex sample survey, NCES longitudinal studies, serve two primary purposes. used analyses, main sampling weight weights sample size population total interest. NCES sample surveys, weighting produces national-level estimates. Also, main sampling weight adjusts differential nonresponse patterns can lead bias estimates. ECLS-K: 2011 Data File User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019) indicate people certain characteristics systematically less likely others respond survey, collected data may accurately reflect characteristics experiences nonrespondents, can lead bias. adjust , respondents assigned weights , applied, result respondents representing characteristics experiences well nonrespondents similar attributes (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019).longitudinal studies (e.g., ECLS-K: 2011), sample weight produced use data every component study (e.g., student questionnaires, parent surveys, student assessment component, transcript component) every round data collection every combination components rounds. However, creating possible weights study many components NCES longitudinal studies impractical. Therefore, may weight adjusts nonresponse exact number components rounds included analysis.weight corresponds exactly combination components included analysis, researchers might prefer use weight adjusts nonresponse components analysis. discussed ECLS-K:2011 User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019), general guidance weight selection () although weight includes nonresponse adjustment components analysis results smaller analytic sample, helps adjust potential differential nonresponse associated components; (b) weight nonresponse adjustments fewer components used, examine missing data potential bias.Please refer study-specific documentation comprehensive information analytic weights available study analysis weight best suited. information ECLS-K:2011 data data documentation, please visit ECLS-K Data Products page.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"using-the-suggestweights-function-to-determine-the-weight","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.2 Using the suggestWeights Function to Determine the Weight","text":"discussed earlier, important weight data analyses using appropriate sampling weight. However, 100 base weights available ECLS-K:2011 data, may find difficult choose. suggestWeights function allows specify variables intend use analysis, suggests list sample weights may appropriate analysis, provides head start make informed decisions weight selection.use suggestWeights function, first step attach EdSurvey package load ECLS-K:2011 data. information, see 10. Longitudinal Datasets. following code attaches EdSurvey package reads ECLS-K:2011 Kindergarten–Fifth Grade public-use data file parameters specified follows:Next, provide variable(s) intended use analysis. suggestWeights function can suggest weight(s) variable(s) provided. create new variables rename variables, need enter source variables used creating variables suggestWeights function uses information original variable name determine component round returns suggested weight(s).following example demonstrates analysis using child assessment data spring third grade. weight w9c790 suggested variables specified. shown ECLS-K:2011 User’s Manual (Tourangeau, 2019), weight w9c790 “child base weight adjusted nonresponse associated child assessment/child questionnaire data spring third grade, spring fourth grade, spring fifth grade (C7C8C9).”weight returned suggestWeights function can used EdSurvey’s analytic functions analysis. ECLS-K:2011 study, EdSurvey uses corresponding replicate weights estimates variance coefficients Jackknife method. Additional information variance estimation ECLS-K:2011 variables available 10. Longitudinal Datasets.print additional information weight suggestion, number cases valid main sampling weight, weight description, variables(s) used weight suggestions variable(s) user specified used weight suggestion, use verbose = TRUE option:Often, trade-offs using one weight versus another among possible weights, may want compare using different weights making final decision. display applicable weights adjust nonresponse components included analysis, typically conservative smaller sample size, use showAllWeightSuggestions = TRUE option:function returns message “determine weights variables provided” returns weights conservative, try remove variable(s) variable list least amount nonresponse least analytical interest. especially helpful exploratory data analysis stage.","code":"\nlibrary(EdSurvey)\neclsk11 <- readECLS_K2011(path = file.path(edsurveyHome,\"ECLS_K/2011\"), \n                          filename = \"childK5p.dat\", \n                          layoutFilename = \"ECLSK2011_K5PUF.sps\", \n                          verbose = FALSE)\nsuggestWeights(varnames = c(\"x7mscalk5\", \"x8mscalk5\", \"x9mscalk5\"), eclsk11)\n#> Based on your specification, below is/are the suggested weight(s). But please double\n#>           check the manual to be sure to use the best weight for your analysis.\n#> [1] \"w9c790\"\nsuggestWeights(varnames = c(\"x1mscalk5\", \"x2mscalk5\", \"x3mscalk5\", \"x4mscalk5\", \"x5mscalk5\", \"x6mscalk5\", \"x7mscalk5\", \"x8mscalk5\"), eclsk11, verbose=TRUE)\n#> Based on your specification, below is/are the suggested weight(s). But please double\n#>           check the manual to be sure to use the best weight for your analysis.\n#> The following weight is suggested: \n#> Weight: w8cf8p_80\n#> Number of cases: 2,354\n#> Description: Child base weight adjusted for nonresponse associated with child\n#> assessment/child questionnaire data from all eight rounds from kindergarten\n#> through fourth grade, as well as parent data from fall kindergarten or spring\n#> kindergarten, and parent data from all rounds from fall first grade through\n#> spring fourth grade. (C1C2C3C4C5C6C7C8)(P1_P2)(P3P4P5P6P7P8)\n#> \n#> \n#> Weight selection based on the inclusion of the following variables:\n#>    varnames                                  source\n#> 1 x1mscalk5   Fall 2010 composite/derived variables\n#> 2 x2mscalk5 Spring 2011 composite/derived variables\n#> 3 x3mscalk5   Fall 2011 composite/derived variables\n#> 4 x4mscalk5 Spring 2012 composite/derived variables\n#> 5 x5mscalk5   Fall 2012 composite/derived variables\n#> 6 x6mscalk5 Spring 2013 composite/derived variables\n#> 7 x7mscalk5 Spring 2014 composite/derived variables\n#> 8 x8mscalk5 Spring 2015 composite/derived variables\n#> [1] \"w8cf8p_80\"\nsuggestWeights(varnames = c(\"x1mscalk5\", \"x2mscalk5\", \"x3mscalk5\", \"x4mscalk5\", \"x5mscalk5\", \"x6mscalk5\", \"x7mscalk5\", \"x8mscalk5\"), eclsk11, showAllWeightSuggestions = TRUE, verbose = TRUE)\n#> Based on your specification, below is/are the suggested weight(s). But please double\n#>           check the manual to be sure to use the best weight for your analysis.\n#> The following weights are suggested: \n#> Weight: w8cf8p_80\n#> Number of cases: 2,354\n#> Description: Child base weight adjusted for nonresponse associated with child\n#> assessment/child questionnaire data from all eight rounds from kindergarten\n#> through fourth grade, as well as parent data from fall kindergarten or spring\n#> kindergarten, and parent data from all rounds from fall first grade through\n#> spring fourth grade. (C1C2C3C4C5C6C7C8)(P1_P2)(P3P4P5P6P7P8)\n#> \n#> \n#> Weight: w8cf8p_2t180\n#> Number of cases: 2,715\n#> Description: Child base weight adjusted for nonresponse associated with child\n#> assessment/child questionnaire data from all eight rounds from kindergarten\n#> through fourth grade, as well as parent data from fall kindergarten or spring\n#> kindergarten, and teacher data from fall and spring kindergarten, fall and\n#> spring first grade, fall and spring second grade, spring third grade, and spring\n#> fourth grade (C1C2C3C4C5C6C7C8)(P1_P2)(T1T2T3T4T5T6T7T8) Note: This weight was\n#> created with nonresponse adjustments for the reading teacher only. There is no\n#> similar weight with nonresponse adjustments for the mathematics or science\n#> teacher.\n#> \n#> \n#> Weight selection based on the inclusion of the following variables:\n#>    varnames                                  source\n#> 1 x1mscalk5   Fall 2010 composite/derived variables\n#> 2 x2mscalk5 Spring 2011 composite/derived variables\n#> 3 x3mscalk5   Fall 2011 composite/derived variables\n#> 4 x4mscalk5 Spring 2012 composite/derived variables\n#> 5 x5mscalk5   Fall 2012 composite/derived variables\n#> 6 x6mscalk5 Spring 2013 composite/derived variables\n#> 7 x7mscalk5 Spring 2014 composite/derived variables\n#> 8 x8mscalk5 Spring 2015 composite/derived variables\n#> [1] \"w8cf8p_80\"    \"w8cf8p_2t180\""},{"path":"the-edsurvey-suggestweights-function.html","id":"general-considerations-when-selecting-weights","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.3 General Considerations When Selecting Weights","text":"Within research study, recommend using main sample weight analyses underlying sample used produce estimates across analyses. Therefore, analytic weight selected based variables included key research questions. set individuals valid weight becomes analytic sample analyses within study. may want consider removing variables weights conservative weights returned. addition, missing data examined weights returned adjust nonresponse fewer components ’s included analysis.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"inside-suggestweights","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.4 Inside suggestWeights","text":"suggestWeights function determines component round variables prefixes variable names. example, variable p8games, corresponds question often parent respondent family members play games puzzles child typical week spring 2015 parent interview, starts “P8,” stands “parent” component round “8” (spring 4th grade). new variables created variables renamed, need enter source variables used creating variables suggestWeights prefixes original variable name contain information component round function work properly. ECLS-K:2011 User’s Manuals provide exhaustive list prefixes Exhibit 7-1 manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019).individual pairs specific component given round, one weights adjust nonresponse elements. example, weights “w8c18p_80, w8c28p_8a0, w8c28p_8b0, w8cf8p_80…” adjust nonresponse parent component round 8 (variables start “P8”), varying combinations components. ECLS-K:2011 User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019) appendix vignette summarize adjustment.input variable, algorithm generate list possible weights. intersection lists provide common set weights apply input variables returned function. case intersection, error message “weight suggestions following variables:…” raised. Consider consulting ECLS-K:2011 User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019) complete descriptions analytic weights.weights adjust nonresponse exact combination components included given analysis, suggestWeights return weight(s). multiple weights adjusting nonresponse components, algorithm rank possible weights using following rule: top components included analysis, weight adjusts nonresponse smallest number additional components ranked top recommendation. ? Although weights returned list adjust potential differential nonresponse associated components, choosing weight includes nonresponse adjustments components using analysis result smaller analytic sample. example, W8C8P_2 adjusts nonresponse three components (.e., P1, P2, C8), W8C18P_2 adjusts nonresponse five components (.e., C1, P1, C2, P2, C8). “C8” variables used analysis, W8C8P_2 prioritized includes nonresponse adjustments component included analysis also fewer components included analysis. Multiple weights suggested returned tie.Lastly, suggestWeights function limits weight(s) returned round weight includes nonresponse adjustment exceed highest round input variables. example, although weights W1_2P0 W9C9P_20 can adjust nonresponse parent interview either fall kindergarten spring kindergarten, latter weight excluded weights suggested analysis involves parent data kindergarten year . ? weight W9C9P_20 also adjusts nonresponse child component round 9, found input variables particular analysis.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"limitations","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.5 Limitations","text":"First, suggestWeights function distinguish “” condition “” condition among components. applies weights italicized Yes appendix. example, may see weights W12P0 W1_2P0 returned given analysis possible one weight applicable analysis former weight adjusts nonresponse parent component fall “” spring kindergarten collections latter adjusts nonresponse parent component fall “” spring kindergarten collection. Consider referring table note Exhibit 4-2 (Tourangeau, 2015a, 2015b, 2018a, 2017) Exhibit 4-3 (Tourangeau, 2018b, 2019) ECLS-K:2011 User’s Manuals information “” “” conditions.Second, classification round-specific composite variables (.e., variables prefix X#) based variable description. example, component round-specific composite variables “teacher report” description classified “teacher,” component round-specific composite variables “parent report” description classified “parent.” suggestWeights function may yield appropriate weights input variables include composite variable created using multiple components. example, race/ethnicity composite variable x_raceth_r draws either parent-reported data child’s race field management system (FMS), FMS data used parent responses child’s race missing. variable included desired analysis, excluded weight selection process. Please review weights returned, , guidance ECLS-K:2011 User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019).Third, suggestWeights function intended single-level analysis multilevel modeling (MLM). Consider referencing ECLS-K:2011 User’s Manuals (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019) guidance conducting MLM analyses using ECLS-K:2011 data.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"appendix","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.6 APPENDIX","text":"ECLS-K:2011 longitudinal data set weighted compensate unequal probabilities selection sampling stage adjust effects nonresponse various components generated estimates, including parent interviews, teacher questionnaires, - -school care provider questionnaires (applicable), school administrator questionnaire, child questionnaires, direct child assessment (Mulligan, 2018).following exhibits (Tourangeau, 2015a, 2015b, 2018a, 2018b, 2017, 2019) developed assist researchers deciding weight use analyses. components nonresponse adjustments made weight noted “Yes.” appropriate weight given analysis “Yes” every component used analysis components.","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-base-year-data-school-year-201011","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.7 Weights Developed for Use With the ECLS-K:2011 Base-Year Data: School Year 2010–11","text":"","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-first-grade-data-school-year-201112","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.8 Weights Developed for Use With the ECLS-K:2011 First-Grade Data: School Year 2011–12","text":"","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-second-grade-data","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.9 Weights Developed for Use With the ECLS-K:2011 Second-Grade Data","text":"","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-third-grade-data","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.10 Weights Developed for Use With the ECLS-K:2011 Third-Grade Data","text":"","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-fourth-grade-data","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.11 Weights Developed for Use With the ECLS-K:2011 Fourth-Grade Data","text":"","code":""},{"path":"the-edsurvey-suggestweights-function.html","id":"weights-developed-for-use-with-the-ecls-k2011-fifth-grade-data-spring-2016","chapter":"13 The EdSurvey suggestWeights Function","heading":"13.12 Weights Developed for Use With the ECLS-K:2011 Fifth-Grade Data: Spring 2016","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
